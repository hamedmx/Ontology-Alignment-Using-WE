{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "high ram test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9wwOeGkdLvd",
        "colab_type": "code",
        "outputId": "2c0aa063-ff8f-4d09-b157-94b2e34d4adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /usr/lib/jvm/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "default-java  java-1.8.0-openjdk-amd64\tjava-8-openjdk-amd64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdRUIUZrTw2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xf /content/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Rg30oBUFDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "#!export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOQjh3-qZGDs",
        "colab_type": "code",
        "outputId": "3d1d3310-c283-45f3-a83e-cd6d36ec8077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!sudo update-alternatives --config java\n",
        "!java -version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: warning: /etc/alternatives/java is dangling; it will be updated with best choice\n",
            "There is only one alternative in link group java (providing /usr/bin/java): /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n",
            "Nothing to configure.\n",
            "/bin/bash: java: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClB1LsPAUIC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "#findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "#spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJXDX8Bjqnky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat /proc/cpuinfo\n",
        "!df -h\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsqXZwauphVV",
        "colab_type": "code",
        "outputId": "e6290d8c-c284-43bd-ef86-0d705d06aff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#GPU count and name\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-42832ab3-0210-fd2e-bc3f-62bc868f02df)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojGuEt8MpJhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use this command to see GPU activity while doing Deep Learning tasks, for this command 'nvidia-smi' and for above one to work, go to 'Runtime > change runtime type > Hardware Accelerator > GPU'\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01i75DIjKA5D",
        "colab_type": "code",
        "outputId": "135f1304-f9f9-47ab-cfaa-daa2d922df82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!lscpu |grep 'Model name'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model name:          Intel(R) Xeon(R) CPU @ 2.30GHz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJVLg_-4P-Pe",
        "colab_type": "code",
        "outputId": "c84b3d36-3492-468e-ae1f-184798f2a2d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#no.of sockets i.e available slots for physical processors\n",
        "!lscpu | grep 'Socket(s):'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Socket(s):           1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yL1tbVeuolJ",
        "colab_type": "code",
        "outputId": "065eb20e-653d-489f-84da-52544e4e1f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#no.of cores each processor is having \n",
        "!lscpu | grep 'Core(s) per socket:'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Core(s) per socket:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O09Z1aBpta_e",
        "colab_type": "code",
        "outputId": "df35ea67-5abb-44d3-e485-d9a03a17ee32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#no.of threads each core is having\n",
        "!lscpu | grep 'Thread(s) per core'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thread(s) per core:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q3wBeTmb4I9",
        "colab_type": "code",
        "outputId": "de30014c-a7b6-421a-b878-1e38356a4216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!lscpu | grep \"L3 cache\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L3 cache:            46080K\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYhXUmlNdfFa",
        "colab_type": "code",
        "outputId": "2e93a5ba-9ee8-4705-a29a-6103db3e5c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#if it had turbo boost it would've shown Min and Max MHz also but it is only showing current frequency this means it always operates at 2.3GHz\n",
        "!lscpu | grep \"MHz\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU MHz:             2300.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjqPaVrihUur",
        "colab_type": "code",
        "outputId": "47564e70-d2ea-41ae-9d43-4d6e71d5a49e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#memory that we can use\n",
        "!cat /proc/meminfo | grep 'MemAvailable'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemAvailable:   25813420 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvyB0VG4j4zx",
        "colab_type": "code",
        "outputId": "0276cb3a-6013-4063-a00f-f1af8869073d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#hard disk that we can use\n",
        "!df -h / | awk '{print $4}'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avail\n",
            "287G\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X6kRXHIbbmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing any existing cuda\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se21ngxoVm4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cuda 10.1\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt update -q\n",
        "!apt install cuda gcc-6 g++-6 -y -q\n",
        "!ln -s /usr/bin/gcc-6 /usr/local/cuda/bin/gcc\n",
        "!ln -s /usr/bin/g++-6 /usr/local/cuda/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nemU6PoGGTm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cuda 9.2\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2\n",
        "######################## for cuda 10.1\n",
        "# !apt update -q\n",
        "# !apt install cuda gcc-6 g++-6 -y -q\n",
        "# !ln -s /usr/bin/gcc-6 /usr/local/cuda/bin/gcc\n",
        "# !ln -s /usr/bin/g++-6 /usr/local/cuda/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9erIkAeFobo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute the given command to install a small extension to run nvcc from Notebook cells\n",
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "# install maxnet-cu92\n",
        "!pip install mxnet-cu92"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMNuvik-Fnc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install julia\n",
        "!curl -sSL \"https://julialang-s3.julialang.org/bin/linux/x64/1.0/julia-1.0.0-linux-x86_64.tar.gz\" -o julia.tar.gz\n",
        "!tar -xzf julia.tar.gz -C /usr --strip-components 1\n",
        "!rm -rf julia.tar.gz*\n",
        "!julia -e 'using Pkg; pkg\"add IJulia; add CuArrays; add Flux; precompile\"'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB3zXMoKFn18",
        "colab_type": "code",
        "outputId": "ae4acc2c-7ac2-4ec3-a8a8-b2af74149ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Check your version using this code\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIBUzlQ6Gqmx",
        "colab_type": "code",
        "outputId": "7c3bbb9f-ef96-4c9e-9b57-2f41b70d344e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load the extension using this code\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN7iBD5PGqxT",
        "colab_type": "code",
        "outputId": "73501841-f9c1-4e3a-ce2e-c57e45c930f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Execute the code below to check if CUDA is working. To run CUDA C/C++ code in your notebook, add the %%cu extension at the beginning of your code.\n",
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "*c = *a + *b;\n",
        "}\n",
        "int main() {\n",
        "int a, b, c;\n",
        "// host copies of variables a, b & c\n",
        "int *d_a, *d_b, *d_c;\n",
        "// device copies of variables a, b & c\n",
        "int size = sizeof(int);\n",
        "// Allocate space for device copies of a, b, c\n",
        "cudaMalloc((void **)&d_a, size);\n",
        "cudaMalloc((void **)&d_b, size);\n",
        "cudaMalloc((void **)&d_c, size);\n",
        "// Setup input values  \n",
        "c = 0;\n",
        "a = 3;\n",
        "b = 5;\n",
        "// Copy inputs to device\n",
        "cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "// Launch add() kernel on GPU\n",
        "add<<<1,1>>>(d_a, d_b, d_c);\n",
        "// Copy result back to host\n",
        "cudaError err = cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "  if(err!=cudaSuccess) {\n",
        "      printf(\"CUDA error copying to Host: %s\\n\", cudaGetErrorString(err));\n",
        "  }\n",
        "printf(\"result is %d\\n\",c);\n",
        "// Cleanup\n",
        "cudaFree(d_a);\n",
        "cudaFree(d_b);\n",
        "cudaFree(d_c);\n",
        "return 0;\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result is 8\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdywBQsOMIPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# google colab operations\n",
        "# !python3 \"/content/gdrive/My Drive/My Thesis/mnist_cnn.py\"\n",
        "\n",
        "# !git clone https://github.com/wxs/keras-mnist-tutorial.git\n",
        "\n",
        "# \"/content/gdrive/My Drive/My Thesis/\"\n",
        "!wget https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/12551780/bio_embedding_extrinsic -P '/content/gdrive/My Drive/My Thesis/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NfALqf_KcUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/gdrive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgT5AjKEflsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install --target=$nb_path --upgrade setuptools\n",
        "!pip3 install --target=$nb_path \"tensorflow>=1.7\"\n",
        "!pip3 install --target=$nb_path tensorflow-gpu\n",
        "# Install TF-Hub.\n",
        "!pip3 install --target=$nb_path tensorflow-hub\n",
        "# Install other packages.\n",
        "!pip3 install --target=$nb_path seaborn\n",
        "# Install SentencePiece package\n",
        "# SentencePiece package is needed for Universal Sentence Encoder Lite. We'll\n",
        "# use it for all the text processing and sentence feature ID lookup.\n",
        "!pip3 install --target=$nb_path sentencepiece\n",
        "!pip3 install --target=$nb_path cython\n",
        "!pip3 install --target=$nb_path numpy\n",
        "!pip3 install --target=$nb_path scipy\n",
        "!pip3 install --target=$nb_path pandas\n",
        "!pip3 install --target=$nb_path --upgrade -U gensim\n",
        "!pip3 install --target=$nb_path --upgrade spacy\n",
        "!pip3 install --target=$nb_path nltk\n",
        "!pip3 install --target=$nb_path multiprocessing\n",
        "!pip3 install --target=$nb_path tqdm\n",
        "!pip3 install --target=$nb_path sklearn\n",
        "!pip3 install --target=$nb_path shorttext\n",
        "!pip3 install --target=$nb_path matplotlib\n",
        "!pip3 install --target=$nb_path torch torchvision\n",
        "!python3 --target=$nb_path -m spacy download en\n",
        "!python3 --target=$nb_path -m spacy download en_core_web_md\n",
        "# !python -m spacy download en_core_web_lg\n",
        "!pip3 install --target=$nb_path --upgrade fse\n",
        "!pip3 install --target=$nb_path git+https://github.com/oborchers/Fast_Sentence_Embeddings\n",
        "!pip3 install --target=$nb_path pyfasttext\n",
        "!pip3 install --target=$nb_path py_stringmatching\n",
        "!pip3 install --target=$nb_path keras\n",
        "!pip3 install --target=$nb_path pyemd\n",
        "!pip3 install --target=$nb_path pycuda\n",
        "!pip3 install --target=$nb_path ray\n",
        "!pip3 install --target=$nb_path mxnet-cu92\n",
        "!pip3 install --target=$nb_path gluonnlp\n",
        "!pip3 install --target=$nb_path mxnet-mkl\n",
        "!pip3 install --target=$nb_path python-Levenshtein\n",
        "!pip3 install --target=$nb_path fuzzywuzzy\n",
        "!pip3 install --target=$nb_path shorttext\n",
        "# !pip3 install --target=$nb_path pykeops\n",
        "!pip3 install --target=$nb_path -U spacy[cuda92]\n",
        "!sh -c 'echo deb https://apt.repos.intel.com/mkl all main > /etc/apt/sources.list.d/intel-mkl.list'\n",
        "!pip3 install --target=$nb_path shorttext\n",
        "!pip3 install --target=$nb_path python-Levenshtein\n",
        "!pip3 install --target=$nb_path fuzzywuzzy\n",
        "!pip3 install --target=$nb_path --upgrade gensim\n",
        "!pip3 install --target=$nb_path --upgrade fse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53IImGaY1b8x",
        "colab_type": "code",
        "outputId": "7fdffe61-cca7-4720-fe81-8fdf9dd2af8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "#!pip3 install spacy\n",
        "#!python -m spacy download en_core_web_md\n",
        "#!python3 -m spacy download en_core_web_md\n",
        "#import spacy\n",
        "# --target=$nb_path\n",
        "#!pip3 install --target=$nb_path torch torchvision\n",
        "#!pip3 install --target=$nb_path shorttext\n",
        "#spacy.load('en_core_web_sm')\n",
        "!pip install --target=$nb_path wmd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wmd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/0d/0b4915c61163b00c87eb9f4e4ea5e96dd5bfdaf375f6571df9245ecf2c3a/wmd-1.3.1.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from wmd) (1.16.4)\n",
            "Building wheels for collected packages: wmd\n",
            "  Building wheel for wmd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wmd: filename=wmd-1.3.1-cp36-cp36m-linux_x86_64.whl size=629299 sha256=55c54eb89acde135d21c1fc9ef083a9850908677c75536cd905286d4bb05e64b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/b8/02/90eb4f593d4227b8fa2882aed18193b83a0ebe4dba191f1113\n",
            "Successfully built wmd\n",
            "Installing collected packages: wmd\n",
            "Successfully installed wmd-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j92oaCeZHUBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip3 install --target=$nb_path tensorflow-gpu\n",
        "#import tensorflow as tf\n",
        "#tf.test.gpu_device_name()\n",
        "# !pip3 install --target=$nb_path \n",
        "\n",
        "!pip3 install shorttext\n",
        "!pip3 install python-Levenshtein\n",
        "!pip3 install fuzzywuzzy\n",
        "!pip3 install gensim==3.8.0\n",
        "!pip3 install --upgrade fse\n",
        "#!pip3 install -U spacy[cuda92]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgENHCv5vGZ6",
        "colab_type": "code",
        "outputId": "e8a04850-5994-466d-a2cd-745ee1957329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/My Thesis/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrPauqV_iA24",
        "colab_type": "code",
        "outputId": "971e28c6-b737-417a-f023-3071fa4789f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import time\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from tqdm import tqdm\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import LsiModel, TfidfModel, KeyedVectors, keyedvectors, WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity, LevenshteinSimilarityIndex\n",
        "from gensim.similarities import WmdSimilarity, Similarity, SoftCosineSimilarity, TermSimilarityIndex, SparseTermSimilarityMatrix\n",
        "from gensim.models.fasttext import FastText as FT, FastTextKeyedVectors, load_facebook_model, load_facebook_vectors\n",
        "import spacy\n",
        "import torch\n",
        "import string\n",
        "import nltk\n",
        "import csv\n",
        "#from infersentmodel import InferSent\n",
        "from shorttext.utils.wordembed import load_fasttext_model, load_poincare_model, load_word2vec_model\n",
        "from shorttext.metrics.wasserstein import word_mover_distance\n",
        "from shorttext.metrics.embedfuzzy import jaccardscore_sents\n",
        "from shorttext.metrics.dynprog import damerau_levenshtein, longest_common_prefix, similarity, soft_jaccard_score\n",
        "from fuzzywuzzy import fuzz\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.matutils import softcossim\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import numpy as np\n",
        "#from ts_ss import TS_SS\n",
        "import multiprocessing\n",
        "from scipy.spatial.distance import cosine\n",
        "import logging\n",
        "#from fse.models import Sentence2Vec\n",
        "#from fse.models.sentence2vec import CY_ROUTINES\n",
        "#%load_ext Cython\n",
        "#assert CY_ROUTINES\n",
        "# form zipfile import ZipFile\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgLv772qBy6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TESTTTTT\n",
        "import gensim, logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        " \n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "path = get_tmpfile(\"word2vec.model\")\n",
        "\n",
        "model = Word2Vec(common_texts, size=100, window=5, min_count=1, workers=4)    \n",
        "sentences = [['karimi', 'hamed'], ['karimi', 'shahed','hello', 'world']]\n",
        "model.build_vocab(sentences, update=True)\n",
        "model.train(sentences, total_examples=model.corpus_count, epochs=5)\n",
        "# train word2vec on the two sentences\n",
        "#model = gensim.models.Word2Vec(sentences, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xprJb1BD2psC",
        "colab_type": "code",
        "outputId": "b2d5e61e-f2b6-4ab3-cb20-5d2bcf89fb65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# model.wv.most_similar('hamed')\n",
        "!python -m nltk.downloader omw\n",
        "!pip3 install spacy-wordnet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n",
            "Collecting spacy-wordnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/f2/4d8070df0f7a7a9eeed74eb7e9ce3cf41349eb5e06b1e088de9eeca630e2/spacy-wordnet-0.0.4.tar.gz (648kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 6.6MB/s \n",
            "\u001b[?25hCollecting nltk<3.4,>=3.3 (from spacy-wordnet)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<3.4,>=3.3->spacy-wordnet) (1.12.0)\n",
            "Building wheels for collected packages: spacy-wordnet, nltk\n",
            "  Building wheel for spacy-wordnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-wordnet: filename=spacy_wordnet-0.0.4-py2.py3-none-any.whl size=650293 sha256=616396fb28d9764e0afa969d40004a29b41a1ed21579739eae603328191f020b\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/93/1d/c86db913cd146fc9ddb26d10f56579c5d58a3e00bc8f96a3a6\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-cp36-none-any.whl size=1394468 sha256=b4441c4be778c5ed944fcab6a510b7bee2d1673a359e7d71e1bcb0cf839d2313\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ab/40/3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
            "Successfully built spacy-wordnet nltk\n",
            "Installing collected packages: nltk, spacy-wordnet\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.3 spacy-wordnet-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pQivMHuzhjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ######################################## Function Timing ##########################################\n",
        "\n",
        "# start = time.time()\n",
        "# a function\n",
        "# print('TIME:', time.time() - start)\n",
        "\n",
        "def timing(f):\n",
        "    def wrap(*args, **kwargs):\n",
        "        time1 = time.time()\n",
        "        ret = f(*args, **kwargs)\n",
        "        time2 = time.time()\n",
        "        print('{:s} function took {:.4f} (s)'.format(f.__name__, (time2-time1)))\n",
        "        return ret\n",
        "    return wrap\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS6mAQAi6OEH",
        "colab_type": "code",
        "outputId": "a9120a6c-2f82-42ae-ca31-7e3435803e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import time\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from tqdm import tqdm\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models import LsiModel, TfidfModel, KeyedVectors, keyedvectors, WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import MatrixSimilarity, SparseMatrixSimilarity, LevenshteinSimilarityIndex\n",
        "from gensim.similarities import WmdSimilarity, Similarity, SoftCosineSimilarity, TermSimilarityIndex, SparseTermSimilarityMatrix\n",
        "from gensim.models.fasttext import FastText as FT, FastTextKeyedVectors, load_facebook_model, load_facebook_vectors\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from fuzzywuzzy import fuzz\n",
        "from shorttext.utils.wordembed import load_fasttext_model, load_poincare_model, load_word2vec_model\n",
        "from shorttext.metrics.wasserstein import word_mover_distance\n",
        "from shorttext.metrics.embedfuzzy import jaccardscore_sents\n",
        "from shorttext.metrics.dynprog import damerau_levenshtein, longest_common_prefix, similarity, soft_jaccard_score\n",
        "#from infersentmodel import InferSent\n",
        "import spacy\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.matutils import softcossim\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import numpy as np\n",
        "import csv\n",
        "# from ts_ss import TS_SS\n",
        "import multiprocessing\n",
        "from scipy.spatial.distance import cosine\n",
        "# from fse.models import Sentence2Vec\n",
        "# from fse.models.sentence2vec import CY_ROUTINES\n",
        "#assert CY_ROUTINES\n",
        "import logging\n",
        "import zipfile\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "gensim.models.word2vec.FAST_VERSION = 1\n",
        "FT.FAST_VERSION = 1\n",
        "gensim.models.fasttext.FAST_VERSION = 1\n",
        "\n",
        "\n",
        "# ####################################################################################################\n",
        "@timing\n",
        "def cleanup_text(docs):  # logging=False):\n",
        "    texts = []\n",
        "#   counter = 1\n",
        "    for doc in docs:\n",
        "        # if counter % 1000 == 0 and logging:\n",
        "        #     print(\"Processed %d out of %d documents.\" % (counter, len(docs)))\n",
        "        # counter += 1\n",
        "        doc = nlp(doc)\n",
        "        tokens = [tok.lemma_.strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
        "        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
        "        #tokens = ' '.join(tokens)  # to concatenate the words of each phrase\n",
        "        texts.append(tokens)  # texts.extend(tokens)\n",
        "    return texts  # pd.Series(texts)\n",
        "\n",
        "# ########################################### PreProcessing #######################################\n",
        "\n",
        "# tokenizer = ToktokTokenizer() # for using NLTK\n",
        "\n",
        "google_pretrained_model = root_path + 'GoogleNews-vectors-negative300.bin.gz'\n",
        "glove_pretrained_model = root_path + 'glove.840B.300d.txt'\n",
        "bio_data1 = root_path + 'wikipedia-pubmed-and-PMC-w2v.bin'\n",
        "bio_data2 = root_path + 'PubMed-and-PMC-w2v.bin'\n",
        "bio_data3 = root_path + 'bio_nlp_vec.tar.gz'\n",
        "ft_data = root_path + 'crawl-300d-2M.vec.zip'\n",
        "#ft_data_vec = root_path + 'crawl-300d-2M-subword.zip'\n",
        "\n",
        "cores = 2 * multiprocessing.cpu_count()\n",
        "field_names_test=['ID','Relation','Value']\n",
        "field_names=['ID','Value']\n",
        "fields=['ID1','ID2']\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "spacy.require_gpu()\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "nlp = spacy.load('en_core_web_sm', disable = ['tagger', 'parser', 'ner'])\n",
        "stopwords = stopwords.words('english')\n",
        "punctuations = string.punctuation\n",
        "\n",
        "data = pd.read_csv(root_path + 'labels_with_genid.csv', sep=',', usecols =field_names, names=field_names)\n",
        "data1 = pd.read_csv(root_path + 'human_labels.csv', sep=',', usecols =field_names, names=field_names)\n",
        "data2 = pd.read_csv(root_path + 'mouse_labels.csv', sep=',', usecols =field_names, names=field_names)\n",
        "\n",
        "# Label_text = [text for text in data[data['Relation'] == 'label']['Value']]\n",
        "Label_text = [text for text in data['Value']]\n",
        "Label_text1 = [text for text in data1['Value']]\n",
        "Label_text2 = [text for text in data2['Value']]\n",
        "clean_labels = cleanup_text(Label_text)\n",
        "clean_labels1 = cleanup_text(Label_text1)\n",
        "clean_labels2 = cleanup_text(Label_text2)\n",
        "\n",
        "# Background Knowledge \n",
        "data['Value'] = clean_labels # [' '.join(sent) for sent in clean_labels]\n",
        "bg = pd.read_csv(root_path + 'all bg.csv', sep=',', usecols =fields, names=fields)\n",
        "clean_bg = []\n",
        "for id1, id2 in tqdm(zip(bg['ID1'], bg['ID2'])):\n",
        "    clean_bg.append(data[data['ID']==id1]['Value'].to_numpy()[0] + data[data['ID']==id2]['Value'].to_numpy()[0])\n",
        "\n",
        "\n",
        "# from numpy.random import RandomState\n",
        "# rf = pd.read_csv(root_path + 'reff.csv', sep=',', usecols =fields, names=fields)\n",
        "# rng = RandomState()\n",
        "# train = rf.sample(frac=0.6, random_state=rng)\n",
        "# test = rf.loc[~rf.index.isin(train.index)]\n",
        "\n",
        "\n",
        "#print(data['Value'])\n",
        "#print(clean_bg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleanup_text function took 3.9899 (s)\n",
            "cleanup_text function took 0.9314 (s)\n",
            "cleanup_text function took 0.7710 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15315it [00:43, 355.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_ktGVv9jGjU",
        "colab_type": "code",
        "outputId": "80778b7d-9ad1-4a02-dee3-de0ac395fe63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "gensim.models.word2vec.FAST_VERSION = 1\n",
        "FT.FAST_VERSION = 1\n",
        "gensim.models.fasttext.FAST_VERSION = 1\n",
        "\n",
        "# ####################################### Version 1 #################################################\n",
        "\n",
        "# model1.add(['quoran'],model1.get_vector('Quoran'),replace=False)\n",
        "# if 'quoran' in model1.vocab:\n",
        "new_bio1 = root_path + 'bio_embedding_intrinsic'\n",
        "new_bio2 = root_path + 'bio_embedding_extrinsic'\n",
        "\n",
        "@timing\n",
        "def load_method(clean_corpus, pretrained=google_pretrained_model, bin=True, is_kv=True,\n",
        "                is_glove=False, is_fasttext=False, loading=False):\n",
        "    if is_kv and bin and is_fasttext:\n",
        "        print('You CANNOT train when \"is_kv=True\" and \"bin=True\" and \"is_fasttext=True\" simultaneously...')\n",
        "        return\n",
        "#     if (not is_kv) and bin and (not is_fasttext):\n",
        "#         print('You CANNOT train when \"is_kv=False\" and \"bin=True\" and \"is_fasttext=False\" simultaneously...')\n",
        "#         return\n",
        "    if (not is_kv) and bin and is_glove:\n",
        "        print('You CANNOT train when \"is_glove=True\" and \"is_kv=False\" and \"bin=True\" simultaneously...')\n",
        "        return\n",
        "    start = time.time()\n",
        "    if is_glove:\n",
        "        if not loading:\n",
        "            glove_input_file = pretrained\n",
        "            word2vec_output_file = pretrained + '.word2vec'\n",
        "            glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "            trained_glove = word2vec_output_file\n",
        "        else:\n",
        "            trained_glove = pretrained\n",
        "        if is_kv:\n",
        "            save_file = root_path + 'my_kv_glove.model'\n",
        "            if not loading:\n",
        "                model = KeyedVectors.load_word2vec_format(trained_glove, binary=bin)  # time: 185s\n",
        "            else:\n",
        "                model = KeyedVectors.load(trained_glove, mmap='r')\n",
        "                model.wv.syn0norm = model.wv.syn0\n",
        "        else:\n",
        "            save_file = root_path + 'my_glove.model'\n",
        "            model = gensim.models.Word2Vec.load(trained_glove)\n",
        "            if not loading:\n",
        "                model.build_vocab(clean_corpus, update=True)\n",
        "                total_ex = model.corpus_count  # model.corpus_total_words\n",
        "                model.train(clean_corpus, total_examples=total_ex, epochs=model.iter)\n",
        "    else:\n",
        "        if is_kv:\n",
        "            if is_fasttext:\n",
        "                model = FastTextKeyedVectors.load(pretrained, mmap='r')\n",
        "                save_file = root_path + 'my_kv_fasttext.model'\n",
        "            else:\n",
        "                save_file = root_path + 'my_kv_w2v.model'\n",
        "                model = KeyedVectors.load_word2vec_format(pretrained, binary=bin, unicode_errors='ignore') # time: 185s\n",
        "                #model = KeyedVectors.load(pretrained, mmap='r')\n",
        "#                 if bin:\n",
        "#                     model = KeyedVectors.load_word2vec_format(pretrained, binary=bin) # time: 185s\n",
        "#                 else:\n",
        "#                     model = KeyedVectors.load(pretrained, mmap='r')\n",
        "        else:\n",
        "            if is_fasttext:\n",
        "                save_file = root_path + 'my_fasttext.model'\n",
        "                if bin:\n",
        "                    if not loading:\n",
        "                        model = load_facebook_model(pretrained)\n",
        "                        model.build_vocab(clean_corpus, update=True)\n",
        "                        total_ex = model.corpus_count  # model.corpus_total_words\n",
        "                        model.train(clean_corpus, total_examples=total_ex, epochs=model.iter)\n",
        "                    else:\n",
        "                        model = load_facebook_vectors(pretrained)\n",
        "                else:\n",
        "                    model = FT.load(pretrained, mmap='r')\n",
        "                    if not loading:\n",
        "                        model.build_vocab(clean_corpus, update=True)\n",
        "                        total_ex = model.corpus_count  # model.corpus_total_words\n",
        "                        model.train(clean_corpus, total_examples=total_ex, epochs=model.iter)\n",
        "            else:\n",
        "                save_file = root_path + 'my_w2v'\n",
        "                model = gensim.models.Word2Vec.load(pretrained, mmap='r')\n",
        "                if not loading:\n",
        "                    model.build_vocab(clean_corpus, update=True)\n",
        "                    total_ex = model.corpus_count   # model.corpus_total_words\n",
        "                    model.train(clean_corpus, total_examples=total_ex, epochs=model.iter)\n",
        "    print('load_method TIME:', time.time() - start)\n",
        "    if not loading:\n",
        "        if is_fasttext:\n",
        "            model.wv.init_sims(replace=True)  # L2 Normalization\n",
        "            FastTextKeyedVectors.save_word2vec_format(model.wv, fname=save_file + '.bin', binary=True)\n",
        "        else:\n",
        "            model.delete_temporary_training_data(replace_word_vectors_with_normalized=True)\n",
        "            model.wv.save_word2vec_format(save_file + '.bin', binary=True)\n",
        "        # if not bin:\n",
        "        model.wv.save(save_file + '.model')\n",
        "    return model\n",
        "\n",
        "\n",
        "#model0 = load_method(clean_labels, pretrained='gdrive/My Drive/My Thesis/my_new_bio_intersect_w2v.bin', bin=True, is_kv=True, is_glove=False, loading=True)\n",
        "\n",
        "##model0 = load_method(clean_labels, pretrained=bio_data2, bin=True, is_kv=False, is_glove=False, loading=False)\n",
        "\n",
        "# ######################### VERSION 2 ################################\n",
        "\n",
        "@timing\n",
        "def self_train_and_pretrained(clean_corpus, pretrained=google_pretrained_model, size=100,\n",
        "                              bin=True, selff=True, is_fasttext=False):\n",
        "#     if bin and is_fasttext and (not selff):\n",
        "#         print('You CANNOT train when \"selff=False\" and \"bin=True\" and \"is_fasttext=True\" simultaneously...')\n",
        "#         return\n",
        "    start = time.time()\n",
        "    if selff:\n",
        "        if is_fasttext:\n",
        "            save_file = root_path + 'my_new_self_fasttext'\n",
        "            model = FT(size=size, min_count=1, iter=10, workers=cores, sg=1, hs=0, window=5, negative=20)  # workers=1, window=10\n",
        "            model.build_vocab(clean_corpus)  # update=True if using load_facebook_model\n",
        "            total_exfast = model.corpus_count  # model2.corpus_total_words\n",
        "            model.train(clean_corpus, total_examples=total_exfast, epochs=model.epochs)\n",
        "        else:\n",
        "            save_file = root_path + 'my_new_self_w2v'\n",
        "            model = Word2Vec(size=size, min_count=1, iter=10, workers=cores, sg=1, hs=0, window=5, sample=1e-4, negative=20) #workers=1, window=10\n",
        "            model.build_vocab(clean_corpus)\n",
        "            total_examples = model.corpus_count\n",
        "            model.train(clean_corpus, total_examples=total_examples, epochs=model.iter)\n",
        "    else:\n",
        "        if is_fasttext:\n",
        "            save_file = root_path+ 'my_fb_fasttext'\n",
        "            # model = load_facebook_model(pretrained)\n",
        "            model = FT.load_fasttext_format(pretrained, encoding='utf-8')\n",
        "            model.build_vocab(clean_corpus, update=True)  # update=True if using load_facebook_model\n",
        "            total_exfast = model.corpus_count  # model.corpus_total_words\n",
        "            model.train(clean_corpus, total_examples=total_exfast, epochs=model.epochs)\n",
        "        else:\n",
        "            save_file = root_path + 'my_new_bio_intersect_w2v'\n",
        "            model = Word2Vec(size=size, min_count=1, iter=10, workers=cores, sg=1, hs=0, window=5, sample=1e-4, negative=10) # workers=1, window=10\n",
        "            model.build_vocab(clean_corpus)\n",
        "            model_pre = KeyedVectors.load_word2vec_format(pretrained, binary=bin)#, limit=3000000)\n",
        "            #model_pre = KeyedVectors.load(pretrained, mmap='r')\n",
        "            model.build_vocab([list(model_pre.vocab.keys())], update=True)\n",
        "            model.intersect_word2vec_format(pretrained, binary=bin, lockf=1.0)\n",
        "            total_examples = model.corpus_count\n",
        "            model.train(clean_corpus, total_examples=total_examples, epochs=model.iter)\n",
        "    print('self_train_and_pretrained TIME:', time.time() - start)\n",
        "    model.wv.init_sims(replace=True)\n",
        "#     if is_fasttext:\n",
        "#         model.wv.init_sims(replace=True)  # L2 Normalization\n",
        "#         FastTextKeyedVectors.save_word2vec_format(model.wv, fname=save_file + '.bin', binary=True)\n",
        "#     else:\n",
        "#         model.delete_temporary_training_data(replace_word_vectors_with_normalized=True)\n",
        "#         model.wv.save_word2vec_format(save_file + '.bin', binary=True)\n",
        "#     # if not bin:\n",
        "#     model.wv.save(save_file+'.model')\n",
        "    return model\n",
        "\n",
        "\n",
        "model0 = self_train_and_pretrained(clean_bg, pretrained=bio_data2, size=200, is_fasttext=False, selff=False, bin=True)\n",
        "model1 = self_train_and_pretrained(clean_bg, pretrained=new_bio1, size=200, is_fasttext=False, selff=False, bin=True)\n",
        "model2 = self_train_and_pretrained(clean_bg, pretrained=new_bio2, size=200, is_fasttext=False, selff=False, bin=True)\n",
        "model3 = self_train_and_pretrained(clean_bg, pretrained=new_bio1, size=20, is_fasttext=True, selff=True, bin=True)\n",
        "model4 = self_train_and_pretrained(clean_bg, pretrained=new_bio1, size=50, is_fasttext=True, selff=True, bin=True)\n",
        "model5 = self_train_and_pretrained(clean_bg, pretrained=new_bio1, size=100, is_fasttext=True, selff=True, bin=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:09:26,695 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:09:26,696 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:09:26,714 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:09:26,720 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:09:26,722 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:09:26,732 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:09:26,733 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:09:26,748 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:09:26,750 : INFO : sample=0.0001 downsamples 645 most-common words\n",
            "2019-09-13 23:09:26,752 : INFO : downsampling leaves estimated 38829 word corpus (46.0% of prior 84385)\n",
            "2019-09-13 23:09:26,764 : INFO : estimated required memory for 4317 words and 200 dimensions: 9065700 bytes\n",
            "2019-09-13 23:09:26,765 : INFO : resetting layer weights\n",
            "2019-09-13 23:09:26,815 : INFO : loading projection weights from gdrive/My Drive/My Thesis/PubMed-and-PMC-w2v.bin\n",
            "2019-09-13 23:11:23,377 : INFO : loaded (4087446, 200) matrix from gdrive/My Drive/My Thesis/PubMed-and-PMC-w2v.bin\n",
            "2019-09-13 23:11:23,518 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:11:23,520 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:11:26,234 : INFO : collected 4087446 word types from a corpus of 4087446 raw words and 1 sentences\n",
            "2019-09-13 23:11:26,235 : INFO : Updating model with new vocabulary\n",
            "2019-09-13 23:11:39,143 : INFO : New added 4087446 unique words (50% of original 8174892) and increased the count of 4087446 pre-existing words (50% of original 8174892)\n",
            "2019-09-13 23:12:05,066 : INFO : deleting the raw counts dictionary of 4087446 items\n",
            "2019-09-13 23:12:05,156 : INFO : sample=0.0001 downsamples 0 most-common words\n",
            "2019-09-13 23:12:05,158 : INFO : downsampling leaves estimated 8174892 word corpus (200.0% of prior 4087446)\n",
            "2019-09-13 23:12:14,144 : INFO : estimated required memory for 8174892 words and 200 dimensions: 17167273200 bytes\n",
            "2019-09-13 23:12:14,146 : INFO : updating layer weights\n",
            "2019-09-13 23:13:05,484 : INFO : loading projection weights from gdrive/My Drive/My Thesis/PubMed-and-PMC-w2v.bin\n",
            "2019-09-13 23:13:42,634 : INFO : merged 4087446 vectors into (4087597, 200) matrix from gdrive/My Drive/My Thesis/PubMed-and-PMC-w2v.bin\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "2019-09-13 23:13:42,636 : INFO : training model with 8 workers on 4087597 vocabulary and 200 features, using sg=1 hs=0 sample=0.0001 negative=10 window=5\n",
            "2019-09-13 23:13:43,441 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:43,502 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:43,509 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:43,519 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:43,537 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:43,573 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:43,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:43,615 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:43,617 : INFO : EPOCH - 1 : training on 84385 raw words (84385 effective words) took 1.0s, 87115 effective words/s\n",
            "2019-09-13 23:13:43,618 : WARNING : EPOCH - 1 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:44,472 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:44,484 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:44,491 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:44,493 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:44,535 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:44,548 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:44,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:44,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:44,608 : INFO : EPOCH - 2 : training on 84385 raw words (84383 effective words) took 1.0s, 85980 effective words/s\n",
            "2019-09-13 23:13:44,610 : WARNING : EPOCH - 2 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:45,402 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:45,439 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:45,470 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:45,511 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:45,525 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:45,552 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:45,572 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:45,584 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:45,585 : INFO : EPOCH - 3 : training on 84385 raw words (84384 effective words) took 1.0s, 87574 effective words/s\n",
            "2019-09-13 23:13:45,586 : WARNING : EPOCH - 3 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:46,461 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:46,470 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:46,472 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:46,479 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:46,487 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:46,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:46,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:46,559 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:46,560 : INFO : EPOCH - 4 : training on 84385 raw words (84383 effective words) took 1.0s, 87604 effective words/s\n",
            "2019-09-13 23:13:46,561 : WARNING : EPOCH - 4 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:47,345 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:47,378 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:47,385 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:47,412 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:47,487 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:47,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:47,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:47,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:47,524 : INFO : EPOCH - 5 : training on 84385 raw words (84384 effective words) took 1.0s, 88555 effective words/s\n",
            "2019-09-13 23:13:47,525 : WARNING : EPOCH - 5 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:48,347 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:48,389 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:48,404 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:48,424 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:48,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:48,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:48,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:48,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:48,509 : INFO : EPOCH - 6 : training on 84385 raw words (84385 effective words) took 1.0s, 86862 effective words/s\n",
            "2019-09-13 23:13:48,510 : WARNING : EPOCH - 6 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:49,361 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:49,367 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:49,389 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:49,416 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:49,424 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:49,464 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:49,466 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:49,471 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:49,472 : INFO : EPOCH - 7 : training on 84385 raw words (84383 effective words) took 1.0s, 88674 effective words/s\n",
            "2019-09-13 23:13:49,473 : WARNING : EPOCH - 7 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:50,347 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:50,372 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:50,388 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:50,392 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:50,414 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:50,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:50,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:50,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:50,463 : INFO : EPOCH - 8 : training on 84385 raw words (84385 effective words) took 1.0s, 86108 effective words/s\n",
            "2019-09-13 23:13:50,464 : WARNING : EPOCH - 8 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:51,244 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:51,282 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:51,307 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:51,342 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:51,370 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:51,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:51,422 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:51,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:51,435 : INFO : EPOCH - 9 : training on 84385 raw words (84384 effective words) took 1.0s, 87723 effective words/s\n",
            "2019-09-13 23:13:51,436 : WARNING : EPOCH - 9 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:52,266 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:13:52,314 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:13:52,321 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:13:52,352 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:13:52,360 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:13:52,373 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:13:52,410 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:13:52,450 : INFO : EPOCH 10 - PROGRESS: at 1531500.00% examples, 84153 words/s, in_qsize 0, out_qsize 1\n",
            "2019-09-13 23:13:52,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:13:52,453 : INFO : EPOCH - 10 : training on 84385 raw words (84385 effective words) took 1.0s, 83942 effective words/s\n",
            "2019-09-13 23:13:52,454 : WARNING : EPOCH - 10 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:13:52,456 : INFO : training on a 843850 raw words (843841 effective words) took 9.8s, 85937 effective words/s\n",
            "2019-09-13 23:13:52,458 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 265.7625322341919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:13:56,162 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:13:56,164 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:13:56,182 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:13:56,189 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:13:56,190 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:13:56,199 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:13:56,200 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:13:56,216 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:13:56,217 : INFO : sample=0.0001 downsamples 645 most-common words\n",
            "2019-09-13 23:13:56,218 : INFO : downsampling leaves estimated 38829 word corpus (46.0% of prior 84385)\n",
            "2019-09-13 23:13:56,228 : INFO : estimated required memory for 4317 words and 200 dimensions: 9065700 bytes\n",
            "2019-09-13 23:13:56,229 : INFO : resetting layer weights\n",
            "2019-09-13 23:13:56,279 : INFO : loading projection weights from gdrive/My Drive/My Thesis/bio_embedding_intrinsic\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained function took 269.4666 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:15:03,825 : INFO : loaded (2324849, 200) matrix from gdrive/My Drive/My Thesis/bio_embedding_intrinsic\n",
            "2019-09-13 23:15:03,920 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:15:03,922 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:15:05,382 : INFO : collected 2324849 word types from a corpus of 2324849 raw words and 1 sentences\n",
            "2019-09-13 23:15:05,383 : INFO : Updating model with new vocabulary\n",
            "2019-09-13 23:15:12,019 : INFO : New added 2324849 unique words (50% of original 4649698) and increased the count of 2324849 pre-existing words (50% of original 4649698)\n",
            "2019-09-13 23:15:27,426 : INFO : deleting the raw counts dictionary of 2324849 items\n",
            "2019-09-13 23:15:27,479 : INFO : sample=0.0001 downsamples 0 most-common words\n",
            "2019-09-13 23:15:27,481 : INFO : downsampling leaves estimated 4649698 word corpus (200.0% of prior 2324849)\n",
            "2019-09-13 23:15:32,667 : INFO : estimated required memory for 4649698 words and 200 dimensions: 9764365800 bytes\n",
            "2019-09-13 23:15:32,668 : INFO : updating layer weights\n",
            "2019-09-13 23:16:01,348 : INFO : loading projection weights from gdrive/My Drive/My Thesis/bio_embedding_intrinsic\n",
            "2019-09-13 23:16:21,920 : INFO : merged 2324849 vectors into (2324940, 200) matrix from gdrive/My Drive/My Thesis/bio_embedding_intrinsic\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "2019-09-13 23:16:21,921 : INFO : training model with 8 workers on 2324940 vocabulary and 200 features, using sg=1 hs=0 sample=0.0001 negative=10 window=5\n",
            "2019-09-13 23:16:22,672 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:22,703 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:22,712 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:22,737 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:22,759 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:22,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:22,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:22,837 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:22,838 : INFO : EPOCH - 1 : training on 84385 raw words (84385 effective words) took 0.9s, 93365 effective words/s\n",
            "2019-09-13 23:16:22,839 : WARNING : EPOCH - 1 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:23,610 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:23,616 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:23,641 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:23,645 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:23,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:23,669 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:23,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:23,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:23,706 : INFO : EPOCH - 2 : training on 84385 raw words (84385 effective words) took 0.9s, 98653 effective words/s\n",
            "2019-09-13 23:16:23,707 : WARNING : EPOCH - 2 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:24,471 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:24,493 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:24,532 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:24,545 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:24,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:24,565 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:24,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:24,620 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:24,622 : INFO : EPOCH - 3 : training on 84385 raw words (84385 effective words) took 0.9s, 93633 effective words/s\n",
            "2019-09-13 23:16:24,623 : WARNING : EPOCH - 3 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:25,404 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:25,409 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:25,415 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:25,431 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:25,444 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:25,461 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:25,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:25,537 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:25,538 : INFO : EPOCH - 4 : training on 84385 raw words (84385 effective words) took 0.9s, 94034 effective words/s\n",
            "2019-09-13 23:16:25,539 : WARNING : EPOCH - 4 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:26,315 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:26,337 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:26,357 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:26,389 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:26,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:26,401 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:26,413 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:26,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:26,446 : INFO : EPOCH - 5 : training on 84385 raw words (84385 effective words) took 0.9s, 94161 effective words/s\n",
            "2019-09-13 23:16:26,447 : WARNING : EPOCH - 5 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:27,091 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:27,186 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:27,282 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:27,288 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:27,309 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:27,311 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:27,328 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:27,342 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:27,343 : INFO : EPOCH - 6 : training on 84385 raw words (84385 effective words) took 0.9s, 95863 effective words/s\n",
            "2019-09-13 23:16:27,344 : WARNING : EPOCH - 6 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:27,965 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:28,135 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:28,143 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:28,168 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:28,175 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:28,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:28,219 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:28,273 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:28,274 : INFO : EPOCH - 7 : training on 84385 raw words (84385 effective words) took 0.9s, 91787 effective words/s\n",
            "2019-09-13 23:16:28,275 : WARNING : EPOCH - 7 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:29,054 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:29,070 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:29,086 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:29,092 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:29,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:29,121 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:29,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:29,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:29,180 : INFO : EPOCH - 8 : training on 84385 raw words (84385 effective words) took 0.9s, 94941 effective words/s\n",
            "2019-09-13 23:16:29,181 : WARNING : EPOCH - 8 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:29,936 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:29,949 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:29,985 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:29,998 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:30,002 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:30,035 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:30,037 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:30,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:30,103 : INFO : EPOCH - 9 : training on 84385 raw words (84385 effective words) took 0.9s, 92626 effective words/s\n",
            "2019-09-13 23:16:30,104 : WARNING : EPOCH - 9 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:30,880 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:16:30,882 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:16:30,905 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:16:30,912 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:16:30,955 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:16:30,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:16:30,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:16:30,989 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:16:30,990 : INFO : EPOCH - 10 : training on 84385 raw words (84385 effective words) took 0.9s, 96449 effective words/s\n",
            "2019-09-13 23:16:30,992 : WARNING : EPOCH - 10 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:16:30,993 : INFO : training on a 843850 raw words (843850 effective words) took 9.1s, 93033 effective words/s\n",
            "2019-09-13 23:16:30,994 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 154.831561088562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:16:32,922 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:16:32,923 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:16:32,940 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:16:32,946 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:16:32,947 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:16:32,955 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:16:32,956 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:16:32,971 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:16:32,972 : INFO : sample=0.0001 downsamples 645 most-common words\n",
            "2019-09-13 23:16:32,972 : INFO : downsampling leaves estimated 38829 word corpus (46.0% of prior 84385)\n",
            "2019-09-13 23:16:32,981 : INFO : estimated required memory for 4317 words and 200 dimensions: 9065700 bytes\n",
            "2019-09-13 23:16:32,983 : INFO : resetting layer weights\n",
            "2019-09-13 23:16:33,031 : INFO : loading projection weights from gdrive/My Drive/My Thesis/bio_embedding_extrinsic\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained function took 156.7585 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:17:46,842 : INFO : loaded (2324849, 200) matrix from gdrive/My Drive/My Thesis/bio_embedding_extrinsic\n",
            "2019-09-13 23:17:46,936 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:17:46,937 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:17:48,374 : INFO : collected 2324849 word types from a corpus of 2324849 raw words and 1 sentences\n",
            "2019-09-13 23:17:48,375 : INFO : Updating model with new vocabulary\n",
            "2019-09-13 23:17:55,432 : INFO : New added 2324849 unique words (50% of original 4649698) and increased the count of 2324849 pre-existing words (50% of original 4649698)\n",
            "2019-09-13 23:18:10,400 : INFO : deleting the raw counts dictionary of 2324849 items\n",
            "2019-09-13 23:18:10,457 : INFO : sample=0.0001 downsamples 0 most-common words\n",
            "2019-09-13 23:18:10,458 : INFO : downsampling leaves estimated 4649698 word corpus (200.0% of prior 2324849)\n",
            "2019-09-13 23:18:15,518 : INFO : estimated required memory for 4649698 words and 200 dimensions: 9764365800 bytes\n",
            "2019-09-13 23:18:15,520 : INFO : updating layer weights\n",
            "2019-09-13 23:18:52,954 : INFO : loading projection weights from gdrive/My Drive/My Thesis/bio_embedding_extrinsic\n",
            "2019-09-13 23:19:14,657 : INFO : merged 2324849 vectors into (2324940, 200) matrix from gdrive/My Drive/My Thesis/bio_embedding_extrinsic\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "2019-09-13 23:19:14,658 : INFO : training model with 8 workers on 2324940 vocabulary and 200 features, using sg=1 hs=0 sample=0.0001 negative=10 window=5\n",
            "2019-09-13 23:19:15,437 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:15,476 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:15,487 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:15,531 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:15,542 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:15,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:15,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:15,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:15,606 : INFO : EPOCH - 1 : training on 84385 raw words (84385 effective words) took 0.9s, 90462 effective words/s\n",
            "2019-09-13 23:19:15,607 : WARNING : EPOCH - 1 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:16,413 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:16,439 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:16,456 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:16,463 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:16,470 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:16,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:16,533 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:16,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:16,535 : INFO : EPOCH - 2 : training on 84385 raw words (84385 effective words) took 0.9s, 92514 effective words/s\n",
            "2019-09-13 23:19:16,536 : WARNING : EPOCH - 2 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:17,372 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:17,374 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:17,375 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:17,394 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:17,397 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:17,412 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:17,440 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:17,481 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:17,483 : INFO : EPOCH - 3 : training on 84385 raw words (84385 effective words) took 0.9s, 90390 effective words/s\n",
            "2019-09-13 23:19:17,486 : WARNING : EPOCH - 3 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:18,237 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:18,261 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:18,289 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:18,301 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:18,329 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:18,374 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:18,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:18,398 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:18,399 : INFO : EPOCH - 4 : training on 84385 raw words (84385 effective words) took 0.9s, 93502 effective words/s\n",
            "2019-09-13 23:19:18,400 : WARNING : EPOCH - 4 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:19,143 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:19,178 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:19,192 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:19,227 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:19,286 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:19,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:19,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:19,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:19,313 : INFO : EPOCH - 5 : training on 84385 raw words (84385 effective words) took 0.9s, 93561 effective words/s\n",
            "2019-09-13 23:19:19,314 : WARNING : EPOCH - 5 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:20,091 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:20,125 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:20,145 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:20,173 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:20,184 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:20,188 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:20,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:20,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:20,264 : INFO : EPOCH - 6 : training on 84385 raw words (84385 effective words) took 0.9s, 89789 effective words/s\n",
            "2019-09-13 23:19:20,265 : WARNING : EPOCH - 6 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:21,061 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:21,105 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:21,124 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:21,126 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:21,139 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:21,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:21,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:21,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:21,175 : INFO : EPOCH - 7 : training on 84385 raw words (84385 effective words) took 0.9s, 93767 effective words/s\n",
            "2019-09-13 23:19:21,176 : WARNING : EPOCH - 7 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:21,962 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:21,969 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:22,022 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:22,038 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:22,047 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:22,056 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:22,075 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:22,077 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:22,078 : INFO : EPOCH - 8 : training on 84385 raw words (84385 effective words) took 0.9s, 94687 effective words/s\n",
            "2019-09-13 23:19:22,079 : WARNING : EPOCH - 8 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:22,836 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:22,892 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:22,914 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:22,964 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:22,973 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:22,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:22,986 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:23,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:23,005 : INFO : EPOCH - 9 : training on 84385 raw words (84385 effective words) took 0.9s, 92977 effective words/s\n",
            "2019-09-13 23:19:23,006 : WARNING : EPOCH - 9 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:23,735 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:23,831 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:23,843 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:23,847 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:23,892 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:23,901 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:23,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:23,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:23,929 : INFO : EPOCH - 10 : training on 84385 raw words (84385 effective words) took 0.9s, 92525 effective words/s\n",
            "2019-09-13 23:19:23,930 : WARNING : EPOCH - 10 : supplied example count (15315) did not equal expected count (1)\n",
            "2019-09-13 23:19:23,930 : INFO : training on a 843850 raw words (843850 effective words) took 9.3s, 91017 effective words/s\n",
            "2019-09-13 23:19:23,931 : INFO : precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 171.00946426391602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:19:28,154 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained function took 175.2319 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:19:29,682 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:19:29,683 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:19:29,701 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:19:29,708 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:19:29,709 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:19:29,718 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:19:29,719 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:19:29,732 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:19:29,733 : INFO : sample=0.001 downsamples 62 most-common words\n",
            "2019-09-13 23:19:29,734 : INFO : downsampling leaves estimated 70878 word corpus (84.0% of prior 84385)\n",
            "2019-09-13 23:19:29,790 : INFO : estimated required memory for 4317 words, 38957 buckets and 20 dimensions: 7065444 bytes\n",
            "2019-09-13 23:19:29,792 : INFO : resetting layer weights\n",
            "2019-09-13 23:19:30,658 : INFO : training model with 8 workers on 4317 vocabulary and 20 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
            "2019-09-13 23:19:31,056 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:31,130 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:31,141 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:31,156 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:31,167 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:31,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:31,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:31,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:31,188 : INFO : EPOCH - 1 : training on 84385 raw words (70807 effective words) took 0.5s, 138170 effective words/s\n",
            "2019-09-13 23:19:31,560 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:31,567 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:31,645 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:31,656 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:31,669 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:31,675 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:31,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:31,694 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:31,695 : INFO : EPOCH - 2 : training on 84385 raw words (70804 effective words) took 0.5s, 143900 effective words/s\n",
            "2019-09-13 23:19:32,121 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:32,148 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:32,158 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:32,168 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:32,174 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:32,179 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:32,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:32,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:32,205 : INFO : EPOCH - 3 : training on 84385 raw words (70756 effective words) took 0.5s, 141183 effective words/s\n",
            "2019-09-13 23:19:32,634 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:32,644 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:32,668 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:32,679 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:32,688 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:32,703 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:32,708 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:32,716 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:32,717 : INFO : EPOCH - 4 : training on 84385 raw words (70816 effective words) took 0.5s, 141250 effective words/s\n",
            "2019-09-13 23:19:33,092 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:33,159 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:33,164 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:33,177 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:33,200 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:33,206 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:33,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:33,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:33,233 : INFO : EPOCH - 5 : training on 84385 raw words (70916 effective words) took 0.5s, 140317 effective words/s\n",
            "2019-09-13 23:19:33,625 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:33,672 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:33,679 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:33,694 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:33,697 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:33,707 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:33,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:33,725 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:33,726 : INFO : EPOCH - 6 : training on 84385 raw words (70953 effective words) took 0.5s, 147053 effective words/s\n",
            "2019-09-13 23:19:34,125 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:34,160 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:34,188 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:34,195 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:34,204 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:34,217 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:34,222 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:34,235 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:34,236 : INFO : EPOCH - 7 : training on 84385 raw words (70959 effective words) took 0.5s, 141756 effective words/s\n",
            "2019-09-13 23:19:34,610 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:34,657 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:34,675 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:34,685 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:34,690 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:34,715 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:34,732 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:34,744 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:34,744 : INFO : EPOCH - 8 : training on 84385 raw words (70856 effective words) took 0.5s, 142177 effective words/s\n",
            "2019-09-13 23:19:35,124 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:35,157 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:35,191 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:35,203 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:35,215 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:35,225 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:35,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:35,237 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:35,238 : INFO : EPOCH - 9 : training on 84385 raw words (70852 effective words) took 0.5s, 146831 effective words/s\n",
            "2019-09-13 23:19:35,645 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:35,670 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:35,683 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:35,698 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:35,702 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:35,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:35,712 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:35,728 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:35,729 : INFO : EPOCH - 10 : training on 84385 raw words (70847 effective words) took 0.5s, 148205 effective words/s\n",
            "2019-09-13 23:19:35,730 : INFO : training on a 843850 raw words (708566 effective words) took 5.1s, 139726 effective words/s\n",
            "2019-09-13 23:19:35,922 : INFO : precomputing L2-norms of word weight vectors\n",
            "2019-09-13 23:19:35,923 : INFO : precomputing L2-norms of ngram weight vectors\n",
            "2019-09-13 23:19:36,077 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 7.7670769691467285\n",
            "self_train_and_pretrained function took 7.9226 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:19:37,897 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2019-09-13 23:19:39,698 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:19:39,700 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:19:39,717 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:19:39,726 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:19:39,727 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:19:39,736 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:19:39,737 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:19:39,751 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:19:39,752 : INFO : sample=0.001 downsamples 62 most-common words\n",
            "2019-09-13 23:19:39,754 : INFO : downsampling leaves estimated 70878 word corpus (84.0% of prior 84385)\n",
            "2019-09-13 23:19:39,805 : INFO : estimated required memory for 4317 words, 38957 buckets and 50 dimensions: 12776364 bytes\n",
            "2019-09-13 23:19:39,807 : INFO : resetting layer weights\n",
            "2019-09-13 23:19:41,664 : INFO : training model with 8 workers on 4317 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
            "2019-09-13 23:19:42,134 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:42,175 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:42,203 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:42,225 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:42,248 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:42,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:42,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:42,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:42,271 : INFO : EPOCH - 1 : training on 84385 raw words (70899 effective words) took 0.6s, 118906 effective words/s\n",
            "2019-09-13 23:19:42,736 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:42,776 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:42,801 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:42,835 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:42,841 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:42,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:42,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:42,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:42,877 : INFO : EPOCH - 2 : training on 84385 raw words (70877 effective words) took 0.6s, 118886 effective words/s\n",
            "2019-09-13 23:19:43,226 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:43,282 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:43,391 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:43,421 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:43,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:43,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:43,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:43,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:43,505 : INFO : EPOCH - 3 : training on 84385 raw words (70853 effective words) took 0.6s, 114842 effective words/s\n",
            "2019-09-13 23:19:43,961 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:43,988 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:43,993 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:44,060 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:44,077 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:44,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:44,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:44,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:44,095 : INFO : EPOCH - 4 : training on 84385 raw words (70941 effective words) took 0.6s, 123145 effective words/s\n",
            "2019-09-13 23:19:44,596 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:44,614 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:44,619 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:44,634 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:44,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:44,658 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:44,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:44,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:44,677 : INFO : EPOCH - 5 : training on 84385 raw words (70894 effective words) took 0.6s, 123888 effective words/s\n",
            "2019-09-13 23:19:45,059 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:45,125 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:45,152 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:45,215 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:45,222 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:45,227 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:45,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:45,259 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:45,261 : INFO : EPOCH - 6 : training on 84385 raw words (70916 effective words) took 0.6s, 123789 effective words/s\n",
            "2019-09-13 23:19:45,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:45,761 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:45,764 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:45,787 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:45,805 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:45,809 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:45,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:45,849 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:45,849 : INFO : EPOCH - 7 : training on 84385 raw words (70851 effective words) took 0.6s, 123624 effective words/s\n",
            "2019-09-13 23:19:46,287 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:46,353 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:46,383 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:46,399 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:46,410 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:46,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:46,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:46,432 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:46,433 : INFO : EPOCH - 8 : training on 84385 raw words (70947 effective words) took 0.6s, 124486 effective words/s\n",
            "2019-09-13 23:19:46,878 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:46,903 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:46,926 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:46,961 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:46,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:47,002 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:47,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:47,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:47,017 : INFO : EPOCH - 9 : training on 84385 raw words (70953 effective words) took 0.6s, 123650 effective words/s\n",
            "2019-09-13 23:19:47,460 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:47,533 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:47,555 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:47,566 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:47,572 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:47,585 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:47,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:47,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:47,605 : INFO : EPOCH - 10 : training on 84385 raw words (70911 effective words) took 0.6s, 122818 effective words/s\n",
            "2019-09-13 23:19:47,606 : INFO : training on a 843850 raw words (709042 effective words) took 5.9s, 119365 effective words/s\n",
            "2019-09-13 23:19:47,803 : INFO : precomputing L2-norms of word weight vectors\n",
            "2019-09-13 23:19:47,805 : INFO : precomputing L2-norms of ngram weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 11.726252555847168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:19:48,141 : INFO : resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained function took 12.0633 (s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-09-13 23:19:55,543 : INFO : collecting all words and their counts\n",
            "2019-09-13 23:19:55,544 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-09-13 23:19:55,560 : INFO : PROGRESS: at sentence #10000, processed 57747 words, keeping 3854 word types\n",
            "2019-09-13 23:19:55,567 : INFO : collected 4317 word types from a corpus of 84385 raw words and 15315 sentences\n",
            "2019-09-13 23:19:55,568 : INFO : Loading a fresh vocabulary\n",
            "2019-09-13 23:19:55,577 : INFO : effective_min_count=1 retains 4317 unique words (100% of original 4317, drops 0)\n",
            "2019-09-13 23:19:55,579 : INFO : effective_min_count=1 leaves 84385 word corpus (100% of original 84385, drops 0)\n",
            "2019-09-13 23:19:55,593 : INFO : deleting the raw counts dictionary of 4317 items\n",
            "2019-09-13 23:19:55,594 : INFO : sample=0.001 downsamples 62 most-common words\n",
            "2019-09-13 23:19:55,596 : INFO : downsampling leaves estimated 70878 word corpus (84.0% of prior 84385)\n",
            "2019-09-13 23:19:55,647 : INFO : estimated required memory for 4317 words, 38957 buckets and 100 dimensions: 22294564 bytes\n",
            "2019-09-13 23:19:55,649 : INFO : resetting layer weights\n",
            "2019-09-13 23:19:59,256 : INFO : training model with 8 workers on 4317 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=20 window=5\n",
            "2019-09-13 23:19:59,717 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:19:59,719 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:19:59,747 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:19:59,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:19:59,785 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:19:59,803 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:19:59,804 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:19:59,814 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:19:59,815 : INFO : EPOCH - 1 : training on 84385 raw words (70871 effective words) took 0.5s, 129313 effective words/s\n",
            "2019-09-13 23:20:00,297 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:00,340 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:00,364 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:00,366 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:00,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:00,387 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:00,394 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:00,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:00,407 : INFO : EPOCH - 2 : training on 84385 raw words (70798 effective words) took 0.6s, 121711 effective words/s\n",
            "2019-09-13 23:20:00,852 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:00,896 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:00,927 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:00,933 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:00,941 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:00,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:00,951 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:00,963 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:00,964 : INFO : EPOCH - 3 : training on 84385 raw words (70861 effective words) took 0.5s, 129725 effective words/s\n",
            "2019-09-13 23:20:01,341 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:01,423 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:01,440 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:01,453 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:01,474 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:01,488 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:01,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:01,506 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:01,506 : INFO : EPOCH - 4 : training on 84385 raw words (70834 effective words) took 0.5s, 133323 effective words/s\n",
            "2019-09-13 23:20:01,900 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:01,980 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:02,012 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:02,016 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:02,028 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:02,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:02,052 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:02,054 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:02,055 : INFO : EPOCH - 5 : training on 84385 raw words (70821 effective words) took 0.5s, 131882 effective words/s\n",
            "2019-09-13 23:20:02,477 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:02,561 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:02,563 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:02,565 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:02,569 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:02,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:02,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:02,586 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:02,587 : INFO : EPOCH - 6 : training on 84385 raw words (70931 effective words) took 0.5s, 136364 effective words/s\n",
            "2019-09-13 23:20:03,044 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:03,049 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:03,080 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:03,105 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:03,109 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:03,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:03,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:03,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:03,134 : INFO : EPOCH - 7 : training on 84385 raw words (70921 effective words) took 0.5s, 131998 effective words/s\n",
            "2019-09-13 23:20:03,403 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:03,463 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:03,569 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:03,605 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:03,616 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:03,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:03,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:03,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:03,668 : INFO : EPOCH - 8 : training on 84385 raw words (70805 effective words) took 0.5s, 136450 effective words/s\n",
            "2019-09-13 23:20:04,055 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:04,141 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:04,155 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:04,160 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:04,180 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:04,182 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:04,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:04,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:04,212 : INFO : EPOCH - 9 : training on 84385 raw words (70934 effective words) took 0.5s, 132756 effective words/s\n",
            "2019-09-13 23:20:04,611 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
            "2019-09-13 23:20:04,687 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
            "2019-09-13 23:20:04,697 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
            "2019-09-13 23:20:04,708 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
            "2019-09-13 23:20:04,717 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-09-13 23:20:04,725 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-09-13 23:20:04,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-09-13 23:20:04,740 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-09-13 23:20:04,741 : INFO : EPOCH - 10 : training on 84385 raw words (70861 effective words) took 0.5s, 136707 effective words/s\n",
            "2019-09-13 23:20:04,742 : INFO : training on a 843850 raw words (708637 effective words) took 5.5s, 129207 effective words/s\n",
            "2019-09-13 23:20:04,976 : INFO : precomputing L2-norms of word weight vectors\n",
            "2019-09-13 23:20:04,979 : INFO : precomputing L2-norms of ngram weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self_train_and_pretrained TIME: 16.834580898284912\n",
            "self_train_and_pretrained function took 17.4694 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIOqGMQlgjnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import gzip\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import sys\n",
        "from copy import deepcopy\n",
        "\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# dct = Dictionary(clean_labels)\n",
        "# dic_set = set(dct.values())\n",
        "# # print(dic_set - set(['this']))\n",
        "# for i in dic_set:\n",
        "#     if i=='lip':\n",
        "#         print('True')\n",
        "#         print(model0.wv['jo'])\n",
        "#     else:\n",
        "#         print('False')\n",
        "\n",
        "isNumber = re.compile(r'\\d+.*')\n",
        "def norm_word(word):\n",
        "    if isNumber.search(word.lower()):\n",
        "        return '---num---'\n",
        "    elif re.sub(r'\\W+', '', word) == '':\n",
        "        return '---punc---'\n",
        "    else:\n",
        "        return word.lower()\n",
        "\n",
        "''' Read all the word vectors and normalize them '''\n",
        "def read_word_vecs(model, clean_corpus):\n",
        "    wordVectors = {}\n",
        "    dct = Dictionary(clean_corpus)\n",
        "    dic_set = set(dct.values())\n",
        "    for line in dic_set:\n",
        "        if line in model.wv.vocab:\n",
        "            word = line\n",
        "            wordVectors[word] = np.array(model.wv[word]) # numpy.zeros(model.vector_size, dtype=float)\n",
        "    #         for index, vecVal in enumerate(line.split()[1:]):\n",
        "    #             wordVectors[word][index] = float(vecVal)\n",
        "            ''' normalize weight vector '''\n",
        "            wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)  \n",
        "    sys.stderr.write(\"Reading vectors...\\n\")\n",
        "    return wordVectors\n",
        "\n",
        "''' Write word vectors to file '''\n",
        "def print_word_vecs(wordVectors, outFileName):\n",
        "    sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
        "    outFile = open(outFileName, 'w')  \n",
        "    for word, values in wordVectors.iteritems():\n",
        "        outFile.write(word+' ')\n",
        "        for val in wordVectors[word]:\n",
        "            outFile.write('%.4f' %(val)+' ')\n",
        "        outFile.write('\\n')      \n",
        "    outFile.close()\n",
        "    return\n",
        "\n",
        "''' Read the PPDB word relations as a dictionary '''\n",
        "def read_lexicon(filename):\n",
        "    lexicon = {}\n",
        "    for line in open(filename, 'r'):\n",
        "        words = line.lower().strip().split()\n",
        "        lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
        "    return lexicon\n",
        "\n",
        "''' Retrofit word vectors to a lexicon '''\n",
        "def retrofit(wordVecs, lexicon, numIters):\n",
        "    newWordVecs = deepcopy(wordVecs)\n",
        "    wvVocab = set(newWordVecs.keys())\n",
        "    loopVocab = wvVocab.intersection(set(lexicon.keys()))\n",
        "    for it in range(numIters):\n",
        "        # loop through every node also in ontology (else just use data estimate)\n",
        "        for word in loopVocab:\n",
        "            wordNeighbours = set(lexicon[word]).intersection(wvVocab)\n",
        "            numNeighbours = len(wordNeighbours)\n",
        "            #no neighbours, pass - use data estimate\n",
        "            if numNeighbours == 0:\n",
        "                continue\n",
        "            # the weight of the data estimate if the number of neighbours\n",
        "            newVec = numNeighbours * wordVecs[word]\n",
        "            # loop over neighbours and add to new vector (currently with weight 1)\n",
        "            for ppWord in wordNeighbours:\n",
        "                newVec += newWordVecs[ppWord]\n",
        "            newWordVecs[word] = newVec/(2*numNeighbours)\n",
        "    return newWordVecs\n",
        "  \n",
        "# if __name__=='__main__':\n",
        "\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument(\"-i\", \"--input\", type=str, default=None, help=\"Input word vecs\")\n",
        "#     parser.add_argument(\"-l\", \"--lexicon\", type=str, default=None, help=\"Lexicon file name\")\n",
        "#     parser.add_argument(\"-o\", \"--output\", type=str, help=\"Output word vecs\")\n",
        "#     parser.add_argument(\"-n\", \"--numiter\", type=int, default=10, help=\"Num iterations\")\n",
        "#     args = parser.parse_args()\n",
        "\n",
        "#     wordVecs = read_word_vecs(args.input)\n",
        "#     lexicon = read_lexicon(args.lexicon)\n",
        "#     numIter = int(args.numiter)\n",
        "#     outFileName = args.output\n",
        "    \n",
        "#     ''' Enrich the word vectors using ppdb and print the enriched vectors '''\n",
        "#     print_word_vecs(retrofit(wordVecs, lexicon, numIter), outFileName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNJTk3hPlIRi",
        "colab_type": "code",
        "outputId": "b369aa0b-88c8-4052-b9b6-cd34146b2f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "wordVecs = read_word_vecs(model4, clean_labels)\n",
        "lexicon = read_lexicon(root_path + 'wn-syn.txt')  # my_wn_syn.txt\n",
        "numIter = 10 # int(args.numiter)\n",
        "outFileName = root_path + 'out-vec.txt'\n",
        "\n",
        "''' Enrich the word vectors using wordnet and print the enriched vectors '''\n",
        "# print_word_vecs(retrofit(wordVecs, lexicon, numIter), outFileName)\n",
        "new_vec4 = retrofit(wordVecs, lexicon, numIter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-14 00:31:47,885 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2019-09-14 00:31:47,981 : INFO : adding document #10000 to Dictionary(4104 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...)\n",
            "2019-09-14 00:31:48,002 : INFO : built Dictionary(4366 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...) from 12484 documents (total 43435 corpus positions)\n",
            "Reading vectors...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoVs3GBaXAMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### TESTTTTTTTT\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X, y = np.arange(10).reshape((5, 2)), range(5)\n",
        "print(train_test_split(X, None, test_size=0.33, random_state=42))\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2eWDOFFud8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infersent_v1(clean_corpus, clean_file1, clean_file2, ver=2, model_path=root_path + 'encoder/', glove_path=glove_pretrained_model,\n",
        "                 fasttext_path=ft_data, size=300, use_cuda=True, update_vocab=False,\n",
        "                 tokenizer=True, update_corpus=None):\n",
        "    #import infersentmodel\n",
        "    from infersentmodel import InferSent\n",
        "    #ver = 2 #fasttext and ver = 1 #GloVe\n",
        "    MODEL_PATH = model_path + 'infersent%s.pkl' % ver\n",
        "    params_model = {'bsize': 128, 'word_emb_dim': size, 'enc_lstm_dim': 2048,\n",
        "                    'pool_type': 'max', 'dpout_model': 0.0, 'version': ver}  # 'bsize': 64\n",
        "    infersent = InferSent(params_model)\n",
        "    infersent.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "    # 2) Set word vector path for the model:\n",
        "    # If infersent1 -> use GloVe embeddings. If infersent2 -> use InferSent embeddings.\n",
        "    if ver == 1:\n",
        "        emb_path = glove_path\n",
        "    else:\n",
        "        emb_path = fasttext_path\n",
        "    infersent.set_w2v_path(emb_path)\n",
        "\n",
        "    # 3) Build the vocabulary of word vectors (i.e keep only those needed):\n",
        "    infersent.build_vocab(clean_corpus, tokenize=tokenizer)\n",
        "    #, or directly load the K most common English words with\n",
        "    # infersent.build_vocab_k_words(K=100000) # or K=500000\n",
        "\n",
        "    # Keep it on CPU or put it on GPU\n",
        "    model = infersent.cuda() if use_cuda else infersent\n",
        "\n",
        "    # where sentences is your list of n sentences. You can update your vocabulary using\n",
        "    if update_vocab:\n",
        "        model.update_vocab(update_corpus)\n",
        "\n",
        "    # If tokenize is True (by default), sentences will be tokenized using NTLK.\n",
        "    # 4) Encode your sentences (list of n sentences):\n",
        "    embeddings1 = model.encode(clean_file1, tokenize=tokenizer, bsize=128, verbose=True)\n",
        "    embeddings2 = model.encode(clean_file2, tokenize=tokenizer, bsize=128, verbose=True)\n",
        "\n",
        "    return model, embeddings1, embeddings2\n",
        "##########################################################################################\n",
        "\n",
        "def simple_average(sents, word2vec_model):\n",
        "    sents_emd = []\n",
        "    for s in sents:\n",
        "        sent_emd = []\n",
        "        for w in s:\n",
        "            if w in word2vec_model:\n",
        "                sent_emd.append(word2vec_model[w])\n",
        "        sent_emd_ar = np.array(sent_emd)\n",
        "        sum_ = sent_emd_ar.sum(axis=0)\n",
        "        result = sum_/np.sqrt((sum_**2).sum())\n",
        "        sents_emd.append(result)\n",
        "    return sents_emd\n",
        "\n",
        "############################### TF-IDF\n",
        "\n",
        "def tfidf_v1(clean_corpus, model, clean_file):\n",
        "    #TF-IDF\n",
        "    text = []\n",
        "    for i in tqdm(clean_corpus):\n",
        "        string = ' '.join(i)\n",
        "        text.append(string)\n",
        "    tf_idf_vect = TfidfVectorizer(stop_words=None)\n",
        "    final_tf_idf = tf_idf_vect.fit_transform(text)\n",
        "    tfidf_feat = tf_idf_vect.get_feature_names()\n",
        "    #Applying TF-IDF scores to the model vectors\n",
        "    tfidf_sent_vectors = [] # the tfidf-w2v for each sentence/review is stored in this list\n",
        "    row=0\n",
        "    for sent in tqdm(clean_file): # for each review/sentence\n",
        "        sent_vec = np.zeros(300) # as word vectors are of zero length\n",
        "        weight_sum =0 # num of words with a valid vector in the sentence/review\n",
        "        for word in sent: # for each word in a review/sentence\n",
        "            if word in model:\n",
        "                vec = model.wv[word]\n",
        "                # obtain the tf_idfidf of a word in a sentence/review\n",
        "                tfidf = final_tf_idf [row, tfidf_feat.index(word)]\n",
        "                sent_vec += (vec * tfidf)\n",
        "                weight_sum += tfidf\n",
        "        sent_vec /= weight_sum\n",
        "        #print(np.isnan(np.sum(sent_vec)))\n",
        "        tfidf_sent_vectors.append(sent_vec)\n",
        "        row += 1\n",
        "    return tfidf_sent_vectors\n",
        "\n",
        "\n",
        "def tf_idf_v2(clean_corpus, word2vec_model, clean_file):\n",
        "    dct = Dictionary(clean_corpus)\n",
        "    corpus = [dct.doc2bow(line) for line in clean_corpus]\n",
        "    tf_idf_model = TfidfModel(corpus)\n",
        "    vector = tf_idf_model[corpus]\n",
        "    d = {dct.get(id): value for doc in vector for id, value in doc}\n",
        "    sents_emd = []\n",
        "    no_of_sent = sum(1 for i in clean_file)\n",
        "    for i in range(no_of_sent):\n",
        "        sent_emd = []\n",
        "        for j in range(len(clean_file[i])):\n",
        "            word = clean_file[i][j]\n",
        "            if word in word2vec_model:\n",
        "                emd = d[word] * word2vec_model[word]\n",
        "                sent_emd.append(emd)\n",
        "        sent_emd_np = np.array(sent_emd)\n",
        "        sum_ = sent_emd_np.sum(axis=0)\n",
        "        result = sum_ / np.sqrt((sum_ ** 2).sum())\n",
        "        sents_emd.append(result)\n",
        "    return sents_emd\n",
        "\n",
        "########################### SIF\n",
        "\n",
        "def smooth_inverse_frequency(sent, word2vec_model, a=0.001):\n",
        "    word_counter = {}\n",
        "    sentences = []\n",
        "    total_count = 0\n",
        "    no_of_sentences = 0\n",
        "    for s in sent:\n",
        "        for w in s:\n",
        "            if w in word_counter:\n",
        "                word_counter[w] = word_counter[w] + 1\n",
        "            else:\n",
        "                word_counter[w] = 1\n",
        "        total_count = total_count + len(s)\n",
        "        no_of_sentences = no_of_sentences + 1\n",
        "    sents_emd = []\n",
        "    for s in sent:\n",
        "        sent_emd = []\n",
        "        for word in s:\n",
        "            if word in word2vec_model:\n",
        "                emd = (a/(a + (word_counter[word]/total_count))) * word2vec_model[word]\n",
        "                sent_emd.append(emd)\n",
        "        sum_ = np.array(sent_emd).sum(axis=0)\n",
        "        sentence_emd = sum_/float(no_of_sentences)\n",
        "        sents_emd.append(sentence_emd)\n",
        "    # sents_emd = LinearOperator(sents_emd)\n",
        "    [_, _, u]  = np.array(np.linalg.svd(sents_emd)) # [_, _, u]  = np.array(svds(sents_emd, k=1))\n",
        "    #[_, _, u] = np.array(scipy.linalg.svd(sents_emd))\n",
        "    new_sents_emd = []\n",
        "    for s in sents_emd:\n",
        "        s = s - s.dot(u*u.transpose())\n",
        "        new_sents_emd.append(s)\n",
        "    return new_sents_emd\n",
        "\n",
        "\n",
        "def sif_embeddings1(sentences, model, alpha=1e-3):\n",
        "    REAL = np.float32\n",
        "    \"\"\"Compute the SIF embeddings for a list of sentences\n",
        "    Parameters\n",
        "    ----------\n",
        "        alpha : float, optional\n",
        "        Parameter which is used to weigh each individual word based on its probability p(w).\n",
        "    Returns\n",
        "    -------\n",
        "    numpy.ndarray\n",
        "        SIF sentence embedding matrix of dim len(sentences) * dimension\n",
        "    \"\"\"\n",
        "\n",
        "    vlookup = model1.wv.vocab  # Gives us access to word index and count\n",
        "    vectors = model  # Gives us access to word vectors\n",
        "    size = model1.vector_size  # Embedding size\n",
        "\n",
        "    Z = 0\n",
        "    for k in vlookup:\n",
        "        Z += vlookup[k].count  # Compute the normalization constant Z\n",
        "\n",
        "    output = []\n",
        "\n",
        "    # Iterate all sentences\n",
        "    for s in sentences:\n",
        "        count = 0\n",
        "        v = np.zeros(size, dtype=REAL)  # Summary vector\n",
        "        # Iterare all words\n",
        "        for w in s:\n",
        "            # A word must be present in the vocabulary\n",
        "            if w in vlookup:\n",
        "                # for i in range(size):\n",
        "                #     v[i] += (alpha / (alpha + (vlookup[w].count / Z))) * vectors[w][i]\n",
        "\n",
        "                # The loop over the the vector dimensions is completely unecessary and extremely slow\n",
        "                v += (alpha / (alpha + (vlookup[w].count / Z))) * vectors[w]\n",
        "                count += 1\n",
        "\n",
        "        if count > 0:\n",
        "            for i in range(size):\n",
        "                v[i] *= 1 / count\n",
        "        output.append(v)\n",
        "    return output # np.vstack(output).astype(REAL)\n",
        "\n",
        "def map_word_frequency(document):\n",
        "    from collections import Counter\n",
        "    import itertools\n",
        "    return Counter(itertools.chain(*document))\n",
        "\n",
        "def sif_embeddings2(tokenised_sentence_list, embedding_size, word_emb_model, a = 1e-3):\n",
        "    sentence_set = []\n",
        "    word_counts = map_word_frequency(tokenised_sentence_list)\n",
        "    for sentence in tokenised_sentence_list:\n",
        "        vs = np.zeros(embedding_size)\n",
        "        sentence_length = len(sentence)\n",
        "        for word in sentence:\n",
        "            a_value = a / (a + word_counts[word]) # smooth inverse frequency, SIF\n",
        "            vs = np.add(vs, np.multiply(a_value, word_emb_model[word])) # vs += sif * word_vector\n",
        "        vs = np.divide(vs, sentence_length) # weighted average\n",
        "        sentence_set.append(vs)\n",
        "    return sentence_set\n",
        "#######################################################################\n",
        "\n",
        "def softcossimilarity(model, clean_query, clean_corpus, clean_file):\n",
        "    # Compute Soft Cosine Measure between the query and the documents.\n",
        "    termsim_index = WordEmbeddingSimilarityIndex(model.wv)  # Any trained model\n",
        "    dictionary = Dictionary(clean_corpus)\n",
        "    tf_idf = TfidfModel(dictionary=dictionary)\n",
        "    query = tf_idf[dictionary.doc2bow(clean_query)]\n",
        "    similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tf_idf)\n",
        "    index = SoftCosineSimilarity(tf_idf[[dictionary.doc2bow(document) for document in clean_file]], similarity_matrix)\n",
        "    similarities = index[query]\n",
        "    return similarities\n",
        "\n",
        "\n",
        "def soft_cosine_sim(model, clean_query, clean_corpus, clean_file, tfidf=False):\n",
        "    if not tfidf:\n",
        "        termsim_index = WordEmbeddingSimilarityIndex(model.wv) # Any trained model\n",
        "        dictionary = Dictionary(clean_corpus)\n",
        "        bow_corpus = [dictionary.doc2bow(document) for document in clean_file]\n",
        "        similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary)  # construct similarity matrix\n",
        "        docsim_index = SoftCosineSimilarity(bow_corpus, similarity_matrix, num_best=10)\n",
        "        # clean_query = 'graph trees computer'.split()  # make a query\n",
        "        sims = docsim_index[dictionary.doc2bow(clean_query)]  # calculate similarity of query to each doc from bow_corpus\n",
        "    else:\n",
        "        termsim_index = WordEmbeddingSimilarityIndex(model.wv) # Any trained model\n",
        "        dictionary = Dictionary(clean_corpus)\n",
        "        tfidf_model = TfidfModel(dictionary=dictionary)\n",
        "        similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tfidf_model)  # construct similarity matrix\n",
        "        bow_corpus = [dictionary.doc2bow(document) for document in clean_file]\n",
        "        # similarity_matrix.inner_product(bow_corpus[2], bow_corpus[3], normalized=True)\n",
        "        docsim_index = SoftCosineSimilarity(bow_corpus, similarity_matrix)\n",
        "        # clean_query = 'graph trees computer'.split()  # make a query\n",
        "        sims = docsim_index[dictionary.doc2bow(clean_query)]  # calculate similarity of query to each doc from bow_corpus\n",
        "    return sims\n",
        "\n",
        "# def create_soft_cossim_matrix(clean_corpus, model, clean_file1, clean_file2):\n",
        "#     dictionary = Dictionary(clean_corpus)\n",
        "#     tf_idf = TfidfModel(dictionary=dictionary)\n",
        "#     similarity_matrix = model.similarity_matrix(dictionary, tfidf=tf_idf, threshold=0.0, exponent=2.0,\n",
        "#                                                  nonzero_limit=100)  # tfidf=None\n",
        "#     bow_corpus1 = [dictionary.doc2bow(document) for document in clean_file1]\n",
        "#     bow_corpus2 = [dictionary.doc2bow(document) for document in clean_file2]\n",
        "#     len_array1 = np.arange(len(bow_corpus1))\n",
        "#     len_array2 = np.arange(len(bow_corpus2))\n",
        "#     xx, yy = np.meshgrid(len_array1, len_array2)\n",
        "#     # Deprecated\n",
        "#     cossim_mat = pd.DataFrame([[round(softcossim(bow_corpus1[i],bow_corpus2[j], similarity_matrix) ,2)\n",
        "#                                 for i, j in zip(x,y)] for y, x in zip(xx, yy)],\n",
        "#                               index=[text for text in data1['ID']], columns=[text for text in data2['ID']]) # [text for text in data['ID']]\n",
        "#     return cossim_mat\n",
        "\n",
        "# ################################# Cosine and Soft Cosine v3 #########################################\n",
        "\n",
        "def tfidf_soft_cosine_TSSS(clean_corpus, clean_file1, clean_file2, model, show_freq=False, is_cosine=False, is_soft=False):\n",
        "    # Create the Document Term Matrix\n",
        "    # count_vectorizer = CountVectorizer(stop_words='english')\n",
        "    # count_vectorizer = CountVectorizer()\n",
        "    count_vectorizer1 = TfidfVectorizer() # Even Better Choice\n",
        "    sparse_matrix1 = count_vectorizer1.fit_transform([' '.join(ss) for ss in clean_file1])\n",
        "    # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe to see the word frequencies.\n",
        "    doc_term_matrix1 = sparse_matrix1.todense()\n",
        "    df1 = pd.DataFrame(doc_term_matrix1, columns=count_vectorizer1.get_feature_names(),\n",
        "                      index=[text for text in data[data['Relation'] == 'label']['ID']]) # [text for text in data['ID']]\n",
        "    count_vectorizer2 = TfidfVectorizer()  # Even Better Choice\n",
        "    sparse_matrix2 = count_vectorizer2.fit_transform([' '.join(ss) for ss in clean_file2])\n",
        "    # OPTIONAL: Convert Sparse Matrix to Pandas Dataframe to see the word frequencies.\n",
        "    doc_term_matrix2 = sparse_matrix2.todense()\n",
        "    df2 = pd.DataFrame(doc_term_matrix2, columns=count_vectorizer2.get_feature_names(),\n",
        "                      index=[text for text in data[data['Relation'] == 'label']['ID']])  # [text for text in data['ID']]\n",
        "    if show_freq:\n",
        "        print(df1)\n",
        "        print()\n",
        "        print(df2)\n",
        "    # Compute Similarity\n",
        "    if is_cosine:\n",
        "        if is_soft:\n",
        "            # Prepare a dictionary and a corpus.\n",
        "            dictionary = Dictionary(clean_corpus)\n",
        "            tf_idf = TfidfModel(dictionary=dictionary)\n",
        "            # Prepare the similarity matrix\n",
        "            similarity_matrix = model.similarity_matrix(dictionary, tfidf=tf_idf, threshold=0.0,\n",
        "                                                        exponent=2.0, nonzero_limit=100)  # tfidf=None\n",
        "            # bow_corpus = [dictionary.doc2bow(document) for document in clean_corpus]\n",
        "            bow_corpus1 = [dictionary.doc2bow(document) for document in clean_file1]\n",
        "            bow_corpus2 = [dictionary.doc2bow(document) for document in clean_file2]\n",
        "            # Compute soft cosine similarity\n",
        "            # print('Soft Cosine Sim: ')\n",
        "            # print(softcossim(bow_corpus[2],bow_corpus[3],similarity_matrix))\n",
        "            sim = [[] for i in range(len(bow_corpus1))]\n",
        "            len1 = len(bow_corpus1)\n",
        "            len2 = len(bow_corpus2)\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim[i].append(softcossim(bow_corpus1[i], bow_corpus2[j], similarity_matrix)) # Deprecated\n",
        "        else:\n",
        "            # print('Cosine Sim: ')\n",
        "            sim = cosine_similarity(df1, df2)\n",
        "    else:\n",
        "        # print('TS-SS Sim: ')\n",
        "        sim = [[] for i in range(len(df1))]\n",
        "        len1 = len(df1)\n",
        "        len2 = len(df2)\n",
        "        for i in tqdm(range(len1)):\n",
        "            for j in range(len2):\n",
        "                sim[i].append(TS_SS(df1.iloc[i], df2.iloc[j]))\n",
        "        # for i in df1.index:\n",
        "        #     for j in df2.index:\n",
        "        #         TS_SS(df1.loc[i], df2.loc[j])\n",
        "    return sim\n",
        "\n",
        "###################### WMD\n",
        "\n",
        "\n",
        "def wmd_gensim(clean_query, clean_corpus, w2v_model):\n",
        "    # between the query and the documents.\n",
        "    index = WmdSimilarity(clean_corpus, w2v_model)\n",
        "    similarities = index[clean_query]\n",
        "    return similarities\n",
        "\n",
        "##########################################################\n",
        "\n",
        "\n",
        "def fse_emb(clean_file1, clean_file2, model, is_cosine=False):\n",
        "    from fse.models import Sentence2Vec\n",
        "    from fse.models.sentence2vec import CY_ROUTINES\n",
        "    # assert CY_ROUTINES\n",
        "    fse_model = Sentence2Vec(model)\n",
        "    # fse_embed1 = fse_model.train(clean_corpus)\n",
        "    fse_embed1 = fse_model.train(clean_file1)\n",
        "    fse_embed2 = fse_model.train(clean_file2)\n",
        "    fse_model.normalize(fse_embed1)\n",
        "    fse_model.normalize(fse_embed2)\n",
        "    fse_embed1 = list(fse_embed1)\n",
        "    fse_embed2 = list(fse_embed2)\n",
        "    # Compute Similarity\n",
        "    if is_cosine:\n",
        "        # sim = cosine_similarity(fse_embed1, fse_embed2)\n",
        "        sim = [[] for i in range(len(fse_embed1))]\n",
        "        len1 = len(fse_embed1)\n",
        "        len2 = len(fse_embed2)\n",
        "        for i in range(len1):\n",
        "            for j in range(len2):\n",
        "                sim[i].append(1 - cosine(fse_embed1[i], fse_embed2[j]))\n",
        "    else:\n",
        "        sim = [[] for i in range(len(fse_embed1))]\n",
        "        len1 = len(fse_embed1)\n",
        "        len2 = len(fse_embed2)\n",
        "        for i in range(len1):\n",
        "            for j in range(len2):\n",
        "                sim[i].append(TS_SS(fse_embed1[i],fse_embed2[j]))\n",
        "    return sim\n",
        "\n",
        "# #########################################################################################\n",
        "\n",
        "def sentence_mean(nlp, clean_sents):\n",
        "    # if s == \"\":\n",
        "    #     s = \" \"\n",
        "    embb = []\n",
        "    for sent in tqdm(clean_sents):\n",
        "        doc = nlp(' '.join(sent), disable=['tagger', 'parser'])\n",
        "        embb.append(np.mean(np.array([w.vector for w in doc]), axis=0))\n",
        "    return embb\n",
        "\n",
        "# another operations...\n",
        "\n",
        "############### spacy sim\n",
        "def spacy_sim(clean_file1, clean_file2, pretrained='en_core_web_sm'):\n",
        "    nlpp = spacy.load(pretrained)\n",
        "    # nlp.vocab.vectors.from_glove(\"/path/to/vectors\")\n",
        "    # sim = doc1.similarity(doc2)\n",
        "    sim = [[] for i in range(len(clean_file1))]\n",
        "    len1 = len(clean_file1)\n",
        "    len2 = len(clean_file2)\n",
        "    for i in range(len1):\n",
        "        doc1 = nlpp(' '.join(clean_file1[i]))\n",
        "        for j in range(len2):\n",
        "            doc2 = nlpp(' '.join(clean_file2[j]))\n",
        "            sim[i].append(doc1.similarity(doc2))\n",
        "    return sim\n",
        "\n",
        "############################################################\n",
        "def d2v_method(clean_corpus, tags, vec_size=300, max_epochs=50, fpath=root_path,\n",
        "               loading=False, update_vocab=False, update_corpus=None):\n",
        "    # fname = get_tmpfile('my_doc2vec_model')\n",
        "    start = time.time()\n",
        "    if not update_vocab:\n",
        "        if not tags:\n",
        "            documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(clean_corpus)]\n",
        "            # documents = TaggedLineDocument(clean_corpus)\n",
        "        else:\n",
        "            documents = [TaggedDocument(words=doc, tags=[tg]) for doc, tg in zip(clean_corpus, tags)]\n",
        "    else:\n",
        "        if not tags:\n",
        "            documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(update_corpus)]\n",
        "            # documents = TaggedLineDocument(clean_corpus)\n",
        "        else:\n",
        "            documents = [TaggedDocument(words=doc, tags=[tg]) for doc, tg in zip(update_corpus, tags)]\n",
        "    if loading:\n",
        "        model = Doc2Vec.load(fpath + 'my_doc2vec_model.doc2vec', mmap='r')  # you can continue training with the loaded model!\n",
        "        if update_vocab:\n",
        "            model.build_vocab(documents, update=True)\n",
        "            total_examples = model.corpus_count\n",
        "            model.train(documents, total_examples=total_examples, epochs=model.iter)\n",
        "            # for epoch in tqdm(range(max_epochs)):\n",
        "            #     model.train(documents, total_examples=total_examples, epochs=model.iter)\n",
        "            #     model.alpha -= 0.002  # decrease the learning rate\n",
        "            #     model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
        "    else:\n",
        "        # model = Doc2Vec(documents, vector_size=200, window=10, min_count=1, workers=cores) # Deprecated\n",
        "        model = Doc2Vec(vector_size=vec_size, window=10, min_count=1, workers=cores, alpha=0.025, min_alpha=0.025) # vector_size=100 or alpha=0.025, min_alpha=0.025 for using fixed learning rate\n",
        "        model.build_vocab(documents)\n",
        "        total_examples = model.corpus_count\n",
        "        for epoch in tqdm(range(max_epochs)):\n",
        "            model.train(documents, total_examples=total_examples, epochs=model.iter)\n",
        "            model.alpha -= 0.002  # decrease the learning rate\n",
        "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
        "    print('d2v_method TIME:', time.time() - start)\n",
        "    if not loading:\n",
        "        model.init_sims(replace=True)\n",
        "        # Persist a model to disk:\n",
        "        model.save(fpath + 'my_doc2vec_model.doc2vec')\n",
        "        # If you’re finished training a model (=no more updates, only querying, reduce memory usage):\n",
        "        model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
        "    else:\n",
        "        if update_vocab:\n",
        "            model.init_sims(replace=True)\n",
        "            # Persist a model to disk:\n",
        "            model.save(fpath + 'my_updated_doc2vec_model.doc2vec')\n",
        "            # If you’re finished training a model (=no more updates, only querying, reduce memory usage):\n",
        "            model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
        "    return model\n",
        "\n",
        "################################################### String Similarity\n",
        "def trigram_sim(clean_sent1, clean_sent2, n=3):\n",
        "    trigram_set1 = set()\n",
        "    trigram_set2 = set()\n",
        "    for w in clean_sent1:\n",
        "        trigram_set1.update([w[i:i+n] for i in range(len(w)-n+1)])\n",
        "    for w in clean_sent2:\n",
        "        trigram_set2.update([w[i:i+n] for i in range(len(w)-n+1)])\n",
        "    intersect_set_size = len(trigram_set1.intersection(trigram_set2))\n",
        "    set1_size = len(trigram_set1)\n",
        "    set2_size = len(trigram_set2)\n",
        "    sim = (3 * intersect_set_size) / (intersect_set_size + set1_size + set2_size)\n",
        "    return sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcQO-2KdNa16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import product\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "import pulp\n",
        "\n",
        "\n",
        "singleindexing = lambda m, i, j: m*i+j\n",
        "unpackindexing = lambda m, k: (k/m, k % m)\n",
        "\n",
        "\n",
        "def tokens_to_fracdict(tokens):\n",
        "    cntdict = defaultdict(lambda : 0)\n",
        "    for token in tokens:\n",
        "        cntdict[token] += 1\n",
        "    totalcnt = sum(cntdict.values())\n",
        "    return {token: float(cnt)/totalcnt for token, cnt in cntdict.items()}\n",
        "\n",
        "\n",
        "# use PuLP\n",
        "def word_mover_distance_probspec(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=None):\n",
        "    all_tokens = list(set(first_sent_tokens+second_sent_tokens))\n",
        "    for token in all_tokens:\n",
        "        if token in wvmodel.wv.vocab:\n",
        "            wordvecs = {token: wvmodel[token]}\n",
        "\n",
        "    first_sent_buckets = tokens_to_fracdict(first_sent_tokens)\n",
        "    second_sent_buckets = tokens_to_fracdict(second_sent_tokens)\n",
        "\n",
        "    T = pulp.LpVariable.dicts('T_matrix', list(product(all_tokens, all_tokens)), lowBound=0)\n",
        "\n",
        "    prob = pulp.LpProblem('WMD', sense=pulp.LpMinimize)\n",
        "    prob += pulp.lpSum([T[token1, token2]*euclidean(wordvecs[token1], wordvecs[token2])\n",
        "                        for token1, token2 in product(all_tokens, all_tokens)])\n",
        "    for token2 in second_sent_buckets:\n",
        "        prob += pulp.lpSum([T[token1, token2] for token1 in first_sent_buckets])==second_sent_buckets[token2]\n",
        "    for token1 in first_sent_buckets:\n",
        "        prob += pulp.lpSum([T[token1, token2] for token2 in second_sent_buckets])==first_sent_buckets[token1]\n",
        "\n",
        "    if lpFile!=None:\n",
        "        prob.writeLP(lpFile)\n",
        "\n",
        "    prob.solve()\n",
        "\n",
        "    return prob\n",
        "\n",
        "def word_mover_distance(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=None):\n",
        "    prob = word_mover_distance_probspec(first_sent_tokens, second_sent_tokens, wvmodel, lpFile=lpFile)\n",
        "    return pulp.value(prob.objective)\n",
        "\n",
        "\n",
        "# for matching word by word\n",
        "# for v in prob.variables():\n",
        "#     if v.varValue!=0:\n",
        "#         print(v.name, '=', v.varValue)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-C8LUxlNkbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sss = word_mover_distance(['sublingual','gland'], ['sublingual','salivary','gland'], model0)\n",
        "if 'salivary' in my_new_vec0:\n",
        "    print(my_new_vec0['salivarssy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG6Fxiu3m73y",
        "colab_type": "code",
        "outputId": "79d702bf-abc3-41e6-9f30-1ee59a242869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!pip3 install parmap"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting parmap\n",
            "  Downloading https://files.pythonhosted.org/packages/39/2d/6754856b5d0fdff6651c1230f0a971d4d5c08a2b91361d4e7c91303c2f60/parmap-1.5.2-py2.py3-none-any.whl\n",
            "Installing collected packages: parmap\n",
            "Successfully installed parmap-1.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O4DRUKgD4lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import threading\n",
        "threadLock = threading.Lock()\n",
        "import multiprocessing as mp\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "#!pip3 install parmap\n",
        "import parmap\n",
        "len1 = len(clean_labels1)\n",
        "len2 = len(clean_labels2)\n",
        "clean_nontok_file1 = [' '.join(sent) for sent in clean_labels1]\n",
        "clean_nontok_file2 = [' '.join(sent) for sent in clean_labels2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sM4LPgnIp3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str_sim = [[] for k in range(len1)]\n",
        "sem_sim = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0EeF7MF9TG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import threading\n",
        "def call_back(result):\n",
        "    if result:\n",
        "        print(\"Solution found! Yay!\")\n",
        "        pool.terminate()\n",
        "#@timing\n",
        "def par_sim(l, h, file1_emb, file2_emb):\n",
        "    for i in tqdm(range(l, h)):\n",
        "        max_sim = 0\n",
        "        j_index = 0\n",
        "        for j in range(len2):\n",
        "            # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "            strsim = 1 - cosine(file1_emb[i], file2_emb[j])\n",
        "            # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "            if strsim >= max_sim:\n",
        "                j_index = j\n",
        "                max_sim = strsim        \n",
        "#         with threadLock:\n",
        "        str_sim[i].append(j_index)\n",
        "        str_sim[i].append(max_sim)\n",
        "        sem_sim.append(fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100)\n",
        "    return\n",
        "\n",
        "@timing\n",
        "def pre_similarity(clean_corpus, clean_file1, clean_file2, model, weigh_method='avg', sim_method='cosine'):\n",
        "    \n",
        "    len1 = len(clean_file1)\n",
        "    len2 = len(clean_file2)\n",
        "    clean_nontok_file1 = [' '.join(sent) for sent in clean_file1]\n",
        "    clean_nontok_file2 = [' '.join(sent) for sent in clean_file2]\n",
        "    \n",
        "    sem_sim = [[] for k in range(len1)]\n",
        "    str_sim = []\n",
        "    if weigh_method == 'avg':\n",
        "        file1_emb = simple_average(clean_file1, model)\n",
        "        file2_emb = simple_average(clean_file2, model)\n",
        "        if sim_method == 'cosine':\n",
        "#             t1 = threading.Thread(target=par_sim, args=(0, len1 // 4, file1_emb, file2_emb,))\n",
        "#             t2 = threading.Thread(target=par_sim, args=(len1 // 4, len1 // 2, file1_emb, file2_emb,))\n",
        "#             t3 = threading.Thread(target=par_sim, args=(len1 // 2, (3 * len1) // 4, file1_emb, file2_emb,))\n",
        "#             t4 = threading.Thread(target=par_sim, args=((3 * len1) // 4, len1, file1_emb, file2_emb,))\n",
        "            \n",
        "#             t1.start()\n",
        "#             t2.start()\n",
        "#             t3.start()\n",
        "#             t4.start()\n",
        "            \n",
        "#             t1.join()\n",
        "#             t2.join()\n",
        "#             t3.join()\n",
        "#             t4.join()\n",
        "####################\n",
        "#             import functools\n",
        "#             import futures\n",
        "#             with futures.ThreadPoolExecutor(50) as executor:\n",
        "#                 future_list = executor.run_to_futures([functools.partial(par_sim, 0, len1 // 4, file1_emb, file2_emb), \n",
        "#                                                        functools.partial(par_sim, len1 // 4, len1 // 2, file1_emb, file2_emb), \n",
        "#                                                        functools.partial(par_sim, len1 // 2, (3 * len1) // 4, file1_emb, file2_emb), \n",
        "#                                                        functools.partial(par_sim, (3 * len1) // 4, len1, file1_emb, file2_emb)])\n",
        "\n",
        "########################\n",
        "#             arg_list = [(0, len1 // 4, file1_emb, file2_emb), \n",
        "#                         (len1 // 4, len1 // 2, file1_emb, file2_emb), \n",
        "#                         (len1 // 2, (3 * len1) // 4, file1_emb, file2_emb), \n",
        "#                         ((3 * len1) // 4, len1, file1_emb, file2_emb)]\n",
        "#             p = parmap.starmap(par_sim, arg_list, pm_pbar=True)\n",
        "\n",
        "#########################\n",
        "#             pool.close()\n",
        "#             pool.join()\n",
        "### Spark\n",
        "#             from pyspark.sql import SparkSession\n",
        "#             from pyspark import Row\n",
        "\n",
        "#             spark = SparkSession.builder.appName(\"jj\").getOrCreate()\n",
        "#             sc = spark.sparkContext\n",
        "#             scc = SparkSession(sc)\n",
        "#             sc._conf.set('spark.executor.memory','20g').set('spark.driver.memory','20g').set('spark.driver.maxResultSize' , '10g')\n",
        "            \n",
        "#             import pandas as pd\n",
        "#             import itertools\n",
        "#             temp = list(itertools.product(clean_nontok_file1, clean_nontok_file2 ))\n",
        "\n",
        "#             temp2 = scc.createDataFrame(temp).rdd\n",
        "#             # scc.parallelize(temp)\n",
        "#             val = temp2.map(lambda x: (x[1] , x[2], fuzz.token_sort_ratio(x[1], x[2]) / 100))\n",
        "#             threshold=0.8\n",
        "#             str_threshold=0.8\n",
        "#             val2 = val.reduce(lambda x,y: x if(x[1] == y[1] & x[3] >y[3]) else y )\\\n",
        "#                 .map(lambda x: (x[1],x[2],x[3] , 1 - cosine(x[1], x[2])))\\\n",
        "#                 .filter(lambda x: x[3]> str_threshold).filter(lambda x: x[4]>threshold)\n",
        "#             df = scc.createDataFrame(val2 )\n",
        "#             # print(df.head(100))\n",
        "#             df.coalesce(1).write.format('com.databricks.spark.csv').options(header='true').save(root_path + 'ress')      \n",
        "            \n",
        "            \n",
        "#             spark = SparkSession.builder.appName(\"gk\").getOrCreate()\n",
        "#             sc = spark.sparkContext\n",
        "#             scc = SparkSession(sc)\n",
        "#             sc._conf.set('spark.executor.memory','20g').set('spark.driver.memory','20g')\n",
        "#             # sc._conf.set(\"spark.executor.heartbeatInterval\",\"3600s\")\n",
        "#             import pandas as pd\n",
        "#             import itertools\n",
        "#             temp = list(itertools.product(clean_nontok_file1, clean_nontok_file2 ))\n",
        "\n",
        "#             temp2 = scc.createDataFrame(temp).rdd\n",
        "\n",
        "#             # scc.parallelize(temp)\n",
        "#             val = temp2.map(lambda x: (x[0] , x[1], fuzz.token_sort_ratio(x[0], x[1]) / 100))\n",
        "#             # print(val.take(10))\n",
        "#             threshold=0.8\n",
        "#             str_threshold=0.8\n",
        "# #             val2 = val.reduce(lambda x,y: x if(x[2] >y[2] ) else y )\\\n",
        "# #                 .map(lambda x: (x[0],x[1],x[2] , 1 - cosine(x[0], x[1])))\\\n",
        "# #                 .filter(lambda x: x[2]> str_threshold).filter(lambda x: x[3]>threshold)\n",
        "\n",
        "#             df = scc.createDataFrame(val)\n",
        "#             # print(df.head(100))\n",
        "#             df.coalesce(1).write.format('com.databricks.spark.csv').options(header='true').save(root_path + 'resss')\n",
        "#### Default\n",
        "            import parmap\n",
        "            from itertools import product\n",
        "#             with parmap.starmap_async(cosine, list(product(file1_emb, file2_emb)), pm_processes=5) as result1:\n",
        "#                 with parmap.starmap_async(fuzz.token_sort_ratio, list(product(clean_nontok_file1, clean_nontok_file2)), pm_processes=3) as result2:\n",
        "#                     data_task1 = None\n",
        "#                     data_task2 = None\n",
        "#                     task1_working = True\n",
        "#                     task2_working = True\n",
        "#                     while task1_working or task2_working:\n",
        "#                         result1.wait(0.1)\n",
        "#                         if task1_working and result1.ready():\n",
        "#                             print(\"Task 1 has finished!\")\n",
        "#                             data_task1 = result1.get()\n",
        "#                             task1_working = False\n",
        "#                         result2.wait(0.1)\n",
        "#                         if task2_working and result2.ready():\n",
        "#                             print(\"Task 2 has finished!\")\n",
        "#                             data_task2 = result2.get()\n",
        "#                             task2_working = False\n",
        "            \n",
        "            \n",
        "            cosine_dist = parmap.starmap(cosine, list(product(file1_emb, file2_emb)), pm_pbar=True)\n",
        "            #str_tsr = parmap.starmap(fuzz.token_sort_ratio, list(product(clean_nontok_file1, clean_nontok_file2)), pm_pbar=True)\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = 1 - cosine_dist[(i*len2)+j]      # 1 - cosine(file1_emb[i], file2_emb[j]) \n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                sem_sim[i].append(j_index)\n",
        "                sem_sim[i].append(max_sim)\n",
        "                str_sim.append(fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100) # (str_tsr[(i*len2)+j_index])  # (fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100)\n",
        "\n",
        "######### Multithread\n",
        "#             for i in tqdm(range(len1)):\n",
        "# #                 par_thread = threading.Thread(target=par_sim, args=(i, file1_emb, file2_emb,))\n",
        "# #                 par_thread.start()\n",
        "# #                 par_thread.join()\n",
        "\n",
        "# #                 par_sim(i, file1_emb, file2_emb)\n",
        "#                 p = pool.apply_async(par_sim, args=(i, file1_emb, file2_emb), callback=call_back)\n",
        "#             pool.close()\n",
        "#             pool.join()\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_emb[i],file2_emb[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'tfidf-emb':\n",
        "        file1_tf = tf_idf_v2(clean_corpus, model, clean_file1)\n",
        "        file2_tf = tf_idf_v2(clean_corpus, model, clean_file2)\n",
        "        if sim_method == 'cosine':\n",
        "            \n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                sem_sim.append(1 - cosine(file1_tf[i], file2_tf[j_index]))\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_tf[i], file2_tf[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'tfidf':\n",
        "        clean_nontok_file1 = [' '.join(sent) for sent in clean_file1]\n",
        "        clean_nontok_file2 = [' '.join(sent) for sent in clean_file2]\n",
        "        vectorizer = TfidfVectorizer()  # (preprocessor=nlp.clean_tf_idf_text)\n",
        "        docs_tfidf1 = vectorizer.fit_transform(clean_nontok_file1)\n",
        "        docs_tfidf2 = vectorizer.fit_transform(clean_nontok_file2)\n",
        "        # query_tfidf = vectorizer.transform([query])\n",
        "        if sim_method == 'cosine':\n",
        "            \n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(docs_tfidf1[i], docs_tfidf2[j])\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(docs_tfidf1[i], docs_tfidf2[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'sif':\n",
        "        file1_sif = sif_embeddings1(clean_file1, model)\n",
        "        file2_sif = sif_embeddings1(clean_file2, model)\n",
        "        if sim_method == 'cosine':\n",
        "            \n",
        "            cosine_dist = parmap.starmap(cosine, list(product(file1_sif, file2_sif)), pm_pbar=True)\n",
        "            #str_tsr = parmap.starmap(fuzz.token_sort_ratio, list(product(clean_nontok_file1, clean_nontok_file2)), pm_pbar=True)\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = 1 - cosine_dist[(i*len2)+j]      # 1 - cosine(file1_emb[i], file2_emb[j]) \n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                sem_sim[i].append(j_index)\n",
        "                sem_sim[i].append(max_sim)\n",
        "                str_sim.append(fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100) # (str_tsr[(i*len2)+j_index])  # (fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100)\n",
        "\n",
        "            \n",
        "#             # by Cosine Distance\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 max_sim = 0\n",
        "#                 j_index = 0\n",
        "#                 for j in range(len2):\n",
        "#                     # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "#                     strsim = 1 - cosine(file1_sif[i], file2_sif[j])\n",
        "#                     # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "#                     if strsim >= max_sim:\n",
        "#                         j_index = j\n",
        "#                         max_sim = strsim        \n",
        "#                 str_sim[i].append(j_index)\n",
        "#                 str_sim[i].append(max_sim)\n",
        "#                 sem_sim.append(fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j_index]) / 100)\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_sif[i], file2_sif[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    \n",
        "    elif weigh_method == 'non-vector':\n",
        "        if sim_method == 'n-sim':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = model.wv.n_similarity(clean_file1[i], clean_file2[j])\n",
        "        elif sim_method == 'wmd':\n",
        "#             # by wmdDistance\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 for j in range(len2):\n",
        "#                     dis = model.wv.wmdistance(clean_file1[i], clean_file2[j])\n",
        "#                     sim = 1 / (1 + dis)\n",
        "\n",
        "#             # by WmdSimilarity\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 sims = wmd_gensim(clean_file1[i], clean_file2, model)\n",
        "#                 for j in range(len2):\n",
        "#                     if sims[j] >= threshold:\n",
        "\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                wmdsim = float(word_mover_distance(clean_file1[i], clean_file2[j_index], model))\n",
        "                wmdsim = 1 / (1 + wmdsim)\n",
        "                sem_sim.append(wmdsim)\n",
        "            \n",
        "        elif sim_method == 'soft':\n",
        "            # by inner_product\n",
        "            termsim_index = WordEmbeddingSimilarityIndex(model.wv)  # Any trained model\n",
        "            dictionary = Dictionary(clean_corpus)\n",
        "            tfidf_model = TfidfModel(dictionary=dictionary)\n",
        "            similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary,\n",
        "                                                           tfidf_model)  # construct similarity matrix\n",
        "            bow_corpus1 = [dictionary.doc2bow(document) for document in clean_file1]\n",
        "            bow_corpus2 = [dictionary.doc2bow(document) for document in clean_file2]\n",
        "            # Compute soft cosine similarity\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                sem_sim.append(similarity_matrix.inner_product(bow_corpus1[i], bow_corpus2[j_index], normalized=True))\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'fse':\n",
        "        from fse.models import Sentence2Vec\n",
        "        from fse.models.sentence2vec import CY_ROUTINES\n",
        "        # assert CY_ROUTINES\n",
        "        fse_model = Sentence2Vec(model)\n",
        "        # fse_embed1 = fse_model.train(clean_corpus)\n",
        "        fse_embed1 = fse_model.train(clean_file1)\n",
        "        fse_embed2 = fse_model.train(clean_file2)\n",
        "        fse_model.normalize(fse_embed1)\n",
        "        fse_model.normalize(fse_embed2)\n",
        "        # fse_embed1 = list(fse_embed1)\n",
        "        # fse_embed2 = list(fse_embed2)\n",
        "        if sim_method == 'cosine':\n",
        "            \n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(fse_embed1[i], fse_embed2[j])\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(fse_embed1[i], fse_embed2[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "\n",
        "    elif weigh_method == 'spacy':\n",
        "        if sim_method == 'cosine':\n",
        "            spacy_emb1 = sentence_mean(nlp, clean_file1)\n",
        "            spacy_emb2 = sentence_mean(nlp, clean_file2)\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(spacy_emb1[i], spacy_emb2[j])\n",
        "        elif sim_method == 'ts-ss':\n",
        "            spacy_emb1 = sentence_mean(nlp, clean_file1)\n",
        "            spacy_emb2 = sentence_mean(nlp, clean_file2)\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(spacy_emb1[i], spacy_emb2[j])\n",
        "        elif sim_method == 'spacy':\n",
        "            nlpp = spacy.load('en_core_web_sm')\n",
        "            doc1 = []\n",
        "            doc2 = []\n",
        "            for i in tqdm(range(len1)):\n",
        "                doc1.append(nlpp(' '.join(clean_file1[i])))\n",
        "            for j in tqdm(range(len2)):\n",
        "                doc2.append(nlpp(' '.join(clean_file2[j])))\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = doc1[i].similarity(doc2[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'wordnet':\n",
        "        from wnet import similarity\n",
        "        for i in tqdm(range(len1)):\n",
        "            sent1 = clean_file1[i]\n",
        "            for j in range(len2):\n",
        "                sim = similarity(sent1, clean_file2[j], True)\n",
        "    elif weigh_method == 'infersent-glove':\n",
        "        from infersentmodel import InferSent\n",
        "        clean_nontok_corpus = [' '.join(sent) for sent in clean_corpus]\n",
        "        infer_model, emb1, emb2 = infersent_v1(clean_nontok_corpus, clean_nontok_file1, clean_nontok_file2, ver=1,\n",
        "                                               model_path=root_path + 'encoder/', glove_path=glove_pretrained_model)\n",
        "        if sim_method == 'cosine':\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                sem_sim.append(1 - cosine(emb1[i], emb2[j_index]))\n",
        "        elif sim_method == 'ts-ss':\n",
        "            # sim = TS_SS(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(emb1[i], emb2[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'infersent-fasttext':\n",
        "        from infersentmodel import InferSent\n",
        "        clean_nontok_corpus = [' '.join(sent) for sent in clean_corpus]\n",
        "        infer_model, emb1, emb2 = infersent_v1(clean_nontok_corpus, clean_nontok_file1, clean_nontok_file2, ver=2, model_path=root_path + 'encoder/', fasttext_path=google_pretrained_model)\n",
        "        if sim_method == 'cosine':\n",
        "            # sim = 1 - cosine(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                sem_sim.append(1 - cosine(emb1[i], emb2[j_index]))\n",
        "        elif sim_method == 'ts-ss':\n",
        "            # sim = TS_SS(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(emb1[i], emb2[j])\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'doc2vec':\n",
        "        #from d2v import d2v_method\n",
        "        d2v_tags = [text for text in data['ID']]\n",
        "        d2v_model = d2v_method(clean_corpus, d2v_tags, max_epochs=100, loading=True)\n",
        "        if sim_method == 'cosine':\n",
        "            for i, id1 in tqdm(enumerate(data1['ID'])):\n",
        "                id1_vec = d2v_model.docvecs[id1]\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                id2_new = ''\n",
        "                for j, id2 in enumerate(data2['ID']):\n",
        "                    # strsim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    # strsim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "                    if strsim >= max_sim:\n",
        "                        id2_new = id2\n",
        "                        j_index = j\n",
        "                        max_sim = strsim        \n",
        "                str_sim[i].append(j_index)\n",
        "                str_sim[i].append(max_sim)\n",
        "                sem_sim.append(1 - cosine(id1_vec, d2v_model.docvecs[id2_new]))\n",
        "                                           \n",
        "        elif sim_method == 'ts-ss':\n",
        "            for id1 in tqdm(data1['ID']):\n",
        "                id1_vec = d2v_model.docvecs[id1]\n",
        "                for id2 in data2['ID']:\n",
        "                    sim = TS_SS(id1_vec, d2v_model.docvecs[id2])\n",
        "                    \n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    else:\n",
        "        print('Weighing Method Error: Unfortunately, the entered weighing method \"' + weigh_method +\n",
        "              '\" is not defined in this function')\n",
        "    \n",
        "    return str_sim, sem_sim\n",
        "\n",
        "\n",
        "def semantic_similarity2(str_sim, sem_sim, weigh_method='avg', sim_method='cosine', threshold=0.8, str_threshold=0.8, alpha=0.5, f_threshold=0.6):\n",
        "    import csv\n",
        "    fields = ['ID1', 'ID2', 'sem_sim']  # 'str_sim', 'struc_sim'\n",
        "    outfile = open(root_path + weigh_method + '_' + sim_method + '_new_results.csv', 'w+', newline='') # or 'a+'\n",
        "    out_writer = csv.writer(outfile, delimiter=',')\n",
        "    out_writer.writerow(fields)\n",
        "    \n",
        "    for i, id1 in tqdm(enumerate(data1['ID'])):\n",
        "        if sem_sim[i][1] >= threshold:                    \n",
        "            if str_sim[i] >= str_threshold:\n",
        "                row = []\n",
        "                row.append(id1) # data1.at[i, 'ID'] or data1.loc[i, 'ID']\n",
        "                row.append(data2.loc[sem_sim[i][0], 'ID'])\n",
        "                row.append(sem_sim[i][1])\n",
        "                out_writer.writerow(row)\n",
        "\n",
        "    outfile.close()\n",
        "    return\n",
        "\n",
        "def evaluation(ref_path, sim_path, file1_num, file2_num, b=1, pr=False):\n",
        "    import mmap\n",
        "    from math import sqrt\n",
        "    total_pairs = file1_num * file2_num\n",
        "    result_row_count = 0\n",
        "    tp = 0\n",
        "    with open(sim_path, \"r\") as result_file:\n",
        "        with open(ref_path, \"r\") as ref_file:\n",
        "            result_reader = csv.DictReader(result_file)\n",
        "            ref_reader = csv.DictReader(ref_file)\n",
        "            ref_row_count = sum(1 for row in ref_reader) # Positives\n",
        "            s = mmap.mmap(ref_file.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "            for row in result_reader:\n",
        "                result_row_count += 1\n",
        "                query = row['ID1'] + ',' + row['ID2']\n",
        "                if s.find(bytes(query, 'utf-8')) != -1:\n",
        "                    tp += 1\n",
        "    negatives = total_pairs - ref_row_count\n",
        "    fp = result_row_count - tp\n",
        "    tn = negatives - fp\n",
        "    fn = ref_row_count - tp\n",
        "    \n",
        "    if pr:\n",
        "        TNR = (tn / negatives) * 100  # True Negative Rate\n",
        "\n",
        "        FPR = (fp / negatives) * 100  # False Positive Rate\n",
        "        print('False Positive Rate: %.2f %%' % FPR)\n",
        "\n",
        "        if tp + fp == 0:\n",
        "            precision = 0\n",
        "        else:\n",
        "            precision = tp / (tp + fp) # PPV: Positive Predictive Value\n",
        "            precision = round(precision,7)\n",
        "            print('Precision: %.2f %%' % precision)\n",
        "\n",
        "        if tp + fn == 0:\n",
        "            recall = 0\n",
        "        else:\n",
        "            recall = tp / ref_row_count # TPR: True Positive Rate or sensitivity\n",
        "            recall = round(recall,7)\n",
        "            print('Recall: %.2f %%' % recall)\n",
        "\n",
        "        if precision + recall == 0: \n",
        "            f1_measure = 0\n",
        "        else:\n",
        "            f1_measure = 2 * ((precision * recall) / (precision + recall))\n",
        "            f1_measure = round(f1_measure,2)\n",
        "            print('F1-Measure: %.2f %%' % f1_measure)\n",
        "        \n",
        "        PPCR = ((tp + fp) / total_pairs) * 100  # Predicted Positive Condition Rate\n",
        "        print('Predicted Positive Condition Rate (PPCR): %.2f %%' % PPCR)\n",
        "\n",
        "        Balanced_Accuracy = (recall + TNR) / 2\n",
        "        print('Balanced Accuracy: %.2f %%' % Balanced_Accuracy)\n",
        "\n",
        "        # Accuracy = ((tp + tn) / total_pairs) * 100   # It is not correct since the data is imbalanced\n",
        "        # print('Accuracy: %.2f %%' % Accuracy)\n",
        "\n",
        "        MCC = (((tp * tn) - (fp * fn)) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))) * 100  # Matthews Correlation Coefficient -1<=MCC<=+1\n",
        "        print('Matthews Correlation Coefficient (MCC): %.2f %%' % MCC)\n",
        "\n",
        "    return tp, fp, tn, fn, ref_row_count, negatives, total_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xas9vJWi4Gm",
        "colab_type": "code",
        "outputId": "8a0ebab9-ff90-4694-9eb9-4d8ef3c6aa6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "strsim, semsim = pre_similarity(clean_bg, clean_labels1, clean_labels2, new_vec4, weigh_method='avg', sim_method='cosine')\n",
        "#semantic_similarity2(strsim, semsim, weigh_method='avg', sim_method='cosine')\n",
        "# print(strsim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9026640it [03:33, 48297.16it/s]                             \n",
            "100%|██████████| 3298/3298 [00:03<00:00, 888.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "pre_similarity function took 229.6885 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZGSzV3bpL4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_evaluate(3298, 2737, new_vec4, w_method='avg', s_method='cosine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lh9F_6xN59n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import spacy\n",
        "import csv\n",
        "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
        "\n",
        "def wordnet_lexicon(clean_corpus):\n",
        "    outfile = open(root_path + 'my_wn_syn.txt', 'w+', newline='') # or 'a+'\n",
        "    out_writer = csv.writer(outfile, delimiter=' ')\n",
        "    dct = Dictionary(clean_corpus)\n",
        "    dic = set(dct.values())    \n",
        "    nlp = spacy.load('en')\n",
        "    text_stats_component = TextStatsComponent(attrs='wordnet')\n",
        "    nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')\n",
        "    domains = ['biology', 'anatomy', 'physiology', 'genetics']\n",
        "    enriched_sentence = []\n",
        "\n",
        "    # For each word in the vocabulary\n",
        "    for token in dic:\n",
        "        tokenn = nlp(token)\n",
        "        # We get those synsets within the desired domains\n",
        "        enriched_sentence.append(tokenn.text)\n",
        "        synsets = tokenn._.wordnet.wordnet_synsets_for_domain(domains)\n",
        "        if synsets:\n",
        "            lemmas_for_synset = []\n",
        "            for s in synsets:\n",
        "                # If we found a synset in the economy domains\n",
        "                # we get the variants and add them to the enriched sentence\n",
        "    #             lemmas_for_synset.extend(s.hypernyms())\n",
        "                lemmas_for_synset.extend(s.lemma_names())\n",
        "    #             if s.hypernyms():\n",
        "                for hyper in s.hypernyms():\n",
        "                    lemmas_for_synset.extend(hyper.lemma_names())\n",
        "                for hypo in s.hyponyms():\n",
        "                    lemmas_for_synset.extend(hypo.lemma_names())\n",
        "                for ww in lemmas_for_synset:\n",
        "                    enriched_sentence.extend([w for w in ww.split('_')])\n",
        "                #enriched_sentence.append('{}'.format(' '.join(set(lemmas_for_synset))))          \n",
        "#     print(list(set(enriched_sentence)))\n",
        "        out_writer.writerow(list(set(enriched_sentence)))\n",
        "    outfile.close()\n",
        "    return\n",
        "\n",
        "# wordnet_lexicon(clean_labels)\n",
        "# fields = ['ID1', 'ID2', 'sem_sim']  # 'str_sim', 'struc_sim'\n",
        "# out_writer.writerow(fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1xJnYzxv2-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def confusion_matrix(cm, classes, file_name, normalize=False, cmap='jet'): # cmap=plt.cm.Blues\n",
        "                          \n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    import itertools\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        # print(\"Normalized confusion matrix\")\n",
        "#     else:\n",
        "#         print('Confusion matrix, without normalization')\n",
        "\n",
        "#     print(cm)\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title('Confusion Matrix (' + file_name + ')', size=18)\n",
        "    cb = plt.colorbar()\n",
        "    cb.set_label(label='Quantity', size=15) # weight='bold'\n",
        "    cb.ax.tick_params(labelsize=12)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, size=14)  # rotation=45\n",
        "    plt.yticks(tick_marks, classes, size=14)\n",
        "\n",
        "    fmt = '.2f' if normalize else '.0f'\n",
        "    thresh = (cm.max() - cm.min()) / 6.\n",
        "    label_list = ['TN: ', 'FP: ', 'FN: ', 'TP: ']\n",
        "    k = 0\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, label_list[k] + format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color='white' if (cm[i, j] >= ((5 * thresh) + cm.min())) or (cm[i, j] <= (cm.min() + thresh)) else 'black', fontdict={'size': 16}, weight='bold')\n",
        "        k +=1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Reference (Real) Label', size=16)\n",
        "    plt.xlabel('Predicted Label', size=16)\n",
        "    plt.savefig(root_path + file_name + '_cm.png', bbox_inches='tight')\n",
        "    plt.clf()\n",
        "    return\n",
        "\n",
        "def make_table(data, file_name, col_width=2.2, row_height=0.625, font_size=14,\n",
        "                     header_color='#40466e', row_colors=['#f1f1f2', 'w'], edge_color='black',\n",
        "                     bbox=[0, 0, 1, 1], header_columns=1,\n",
        "                     ax=None, **kwargs):\n",
        "    import six\n",
        "    if ax is None:\n",
        "        size = (np.array(data.shape[::-1]) + np.array([0, 1])) * np.array([col_width, row_height])\n",
        "        fig, ax = plt.subplots(figsize=size)\n",
        "        ax.axis('off')\n",
        "\n",
        "    mpl_table = ax.table(cellText=data.values, bbox=bbox, colLabels=data.columns, cellLoc='center', **kwargs)\n",
        "\n",
        "    mpl_table.auto_set_font_size(False)\n",
        "    mpl_table.set_fontsize(font_size)\n",
        "\n",
        "    for k, cell in  six.iteritems(mpl_table._cells):\n",
        "        cell.set_edgecolor(edge_color)\n",
        "        if k[0] == 0 or k[1] < header_columns:\n",
        "            cell.set_text_props(weight='bold', color='w', fontsize=15)\n",
        "            cell.set_facecolor(header_color)\n",
        "        else:\n",
        "            cell.set_facecolor(row_colors[k[0]%len(row_colors) ])\n",
        "    fig.savefig(root_path + file_name + '.png', bbox_inches='tight')\n",
        "    plt.clf()\n",
        "    return ax\n",
        "\n",
        "def full_evaluate(file1_n, file2_n, w2v_model, w_method='avg', s_method='cosine'):\n",
        "    import mmap\n",
        "    from math import sqrt\n",
        "    %matplotlib inline\n",
        "    import seaborn as sns\n",
        "    from IPython.core.pylabtools import figsize\n",
        "    from sklearn.metrics import auc\n",
        "    max_roc_auc = 0\n",
        "    max_pr_auc = 0\n",
        "#     max_pr_gain_auc = 0\n",
        "    sem_thr_max = 0.0\n",
        "    sem_thr_pr_max = 0.0\n",
        "#     str_thr_gain_max = 0.0\n",
        "    sem_max_index = 0\n",
        "    \n",
        "    # thresholds = [str(t) for t in result['Threshold']]\n",
        "    num_thresholds = [round(t,1) for t in np.arange(0, 1.1, 0.1)]\n",
        "    thresholds = [str(s) for s in num_thresholds]\n",
        "    \n",
        "    full_result = pd.DataFrame({'Sem-Thr': [], 'Str-Thr': [], 'TP': [], 'FP': [], 'TN': [], 'FN': [], \n",
        "                               'Precision': [], 'Recall': [], 'F1': [], \n",
        "                               'TPR': [], 'FPR': [], 'TNR (Spec)': [], \n",
        "                               'B-Accuracy': [], 'Accuracy': [], 'Kappa': [], 'MCC': []})\n",
        "    \n",
        "    top_result = pd.DataFrame({'Sem-Thr': [], 'Str-Thr': [], 'TP': [], 'FP': [], 'TN': [], 'FN': [], \n",
        "                               'Precision': [], 'Recall': [], 'F1': [], \n",
        "                               'TPR': [], 'FPR': [], 'TNR (Spec)': [],\n",
        "                               'B-Accuracy': [], 'Accuracy': [], 'Kappa': [], 'MCC': [], 'PR-AUC': [], 'ROC-AUC': []})\n",
        "    \n",
        "    # strsimm, semsimm = pre_similarity(clean_labels, clean_labels1, clean_labels2, w2v_model, weigh_method=w_method, sim_method=s_method)\n",
        "    \n",
        "    for index_i, i in enumerate(num_thresholds):        \n",
        "        for index_j, j in enumerate(num_thresholds):\n",
        "        \n",
        "            semantic_similarity2(strsim, semsim, weigh_method=w_method, sim_method=s_method, threshold=i, str_threshold=j)\n",
        "            tp, fp, tn, fn, positives, negatives, total = evaluation(root_path + 'reff.csv', root_path + w_method + '_' + s_method + '_new_results.csv', \n",
        "                                                                     file1_num=file1_n, file2_num=file2_n)\n",
        "\n",
        "            tnr = tn / negatives  # True Negative Rate or specificity\n",
        "            tnr = round(tnr,7)\n",
        "            fpr = fp / negatives  # False Positive Rate\n",
        "            fpr = round(fpr,7)\n",
        "            \n",
        "            if tp + fp == 0:\n",
        "                precision = 0\n",
        "            else:\n",
        "                precision = tp / (tp + fp) # PPV: Positive Predictive Value\n",
        "                precision = round(precision,7)\n",
        "                #print('Precision: %.2f %%' % precision)\n",
        "            \n",
        "            if tp + fn == 0:\n",
        "                recall = 0\n",
        "            else:\n",
        "                recall = tp / positives # TPR: True Positive Rate or sensitivity\n",
        "                recall = round(recall,7)\n",
        "                #print('Recall: %.2f %%' % recall)\n",
        "            \n",
        "            if precision + recall == 0: \n",
        "                f1_measure = 0\n",
        "            else:\n",
        "                f1_measure = 2 * ((precision * recall) / (precision + recall))\n",
        "                f1_measure = round(f1_measure,2)\n",
        "                #print('F1-Measure: %.2f %%' % f1_measure)\n",
        "            \n",
        "#             if (tp == 0) or (negatives == 0):\n",
        "#                 prec_gain = 0\n",
        "#                 rec_gain = 0\n",
        "#             else:\n",
        "#                 prec_gain = 1 - ((positives / negatives) * (fp / tp))\n",
        "#                 prec_gain = round(prec_gain,2)\n",
        "#                 rec_gain = 1 - ((positives / negatives) * (fn / tp))\n",
        "#                 rec_gain = round(rec_gain,2)\n",
        "            \n",
        "#             f_gain = (prec_gain + rec_gain) / 2\n",
        "#             f_gain = round(f_gain,2)\n",
        "            \n",
        "#             fm = sqrt(precision * recall)  # G-Measure or Fowlkes-Mallows index\n",
        "#             fm = round(fm,2)\n",
        "            \n",
        "            obs_acc = (tn + tp) / total\n",
        "            # obs_acc = round(obs_acc,2)\n",
        "            exp_acc = ((((tn + fn) * (tn + fp)) / total) + (((fp + tp) * (fn + tp)) / total)) / total\n",
        "            # exp_acc = round(exp_acc,2)\n",
        "            kappa = (obs_acc - exp_acc) / (1 - exp_acc)\n",
        "            kappa = round(kappa,5)\n",
        "            \n",
        "#             ppcr = (tp + fp) / total  # Predicted Positive Condition Rate\n",
        "#             ppcr = round(ppcr,2)\n",
        "#             #print('Predicted Positive Condition Rate (PPCR): %.2f %%' % ppcr)\n",
        "\n",
        "            balanced_accuracy = (recall + tnr) / 2\n",
        "            balanced_accuracy = round(balanced_accuracy,5)\n",
        "            #print('Balanced Accuracy: %.2f %%' % balanced_accuracy)\n",
        "\n",
        "            accuracy = (tp + tn) / total  # It is not correct since the data is imbalanced\n",
        "            accuracy = round(accuracy,5)\n",
        "            # print('Accuracy: %.2f %%' % accuracy)\n",
        "            \n",
        "#             jaccard = tp / (tp + fn + fp)\n",
        "#             jaccard = round(jaccard,5)\n",
        "            \n",
        "            if ((tp + fp) == 0) or ((tp + fn) == 0) or ((tn + fp) == 0) or ((tn + fn) == 0):\n",
        "                mcc = 0\n",
        "            else:\n",
        "                mcc = ((tp * tn) - (fp * fn)) / sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))  # Matthews Correlation Coefficient -1<=MCC<=+1\n",
        "                mcc = round(mcc,5)\n",
        "                #print('Matthews Correlation Coefficient (MCC): %.2f %%' % mcc)\n",
        "            \n",
        "            full_result.at[(11 * index_i) + index_j] = [i, j, tp, fp, tn, fn, precision, recall, f1_measure, recall, fpr, tnr, balanced_accuracy, accuracy, kappa, mcc]\n",
        "                           \n",
        "        roc_col = pd.DataFrame({'FPR': [], 'TPR': []})\n",
        "        roc_col = roc_col.append({'FPR': 0, 'TPR': 0}, ignore_index=True)\n",
        "        for item1, item2 in zip(full_result[full_result['Sem-Thr']==i]['FPR'], full_result[full_result['Sem-Thr']==i]['TPR']):\n",
        "            roc_col = roc_col.append({'FPR': item1, 'TPR': item2}, ignore_index=True)\n",
        "        roc_col = roc_col.append({'FPR': 1, 'TPR': 1}, ignore_index=True)\n",
        "        roc_col = roc_col.sort_values(by=['FPR'])\n",
        "        \n",
        "        pr_col = pd.DataFrame({'Recall': [], 'Precision': []})\n",
        "        pr_col = pr_col.append({'Recall': 0, 'Precision': 1}, ignore_index=True)\n",
        "        for item1, item2 in zip(full_result[full_result['Sem-Thr']==i]['Recall'], full_result[full_result['Sem-Thr']==i]['Precision']):\n",
        "            pr_col = pr_col.append({'Recall': item1, 'Precision': item2}, ignore_index=True)\n",
        "        pr_col = pr_col.append({'Recall': 1, 'Precision': 0}, ignore_index=True)\n",
        "        pr_col = pr_col.sort_values(by=['Recall'])\n",
        "\n",
        "#         pr_gain_col = pd.DataFrame({'Rec-Gain': [], 'Prec-Gain': []})\n",
        "#         pr_gain_col = pr_gain_col.append({'Rec-Gain': 0, 'Prec-Gain': 1}, ignore_index=True)\n",
        "#         for item1, item2 in zip(full_result[full_result['Str-Thr']==i]['Rec-Gain'], full_result[full_result['Str-Thr']==i]['Prec-Gain']):\n",
        "#             pr_gain_col = pr_gain_col.append({'Rec-Gain': item1, 'Prec-Gain': item2}, ignore_index=True)\n",
        "#         pr_gain_col = pr_gain_col.append({'Rec-Gain': 1, 'Prec-Gain': 0}, ignore_index=True)\n",
        "#         pr_gain_col = pr_gain_col.sort_values(by=['Rec-Gain'])\n",
        "\n",
        "        \n",
        "        roc_auc = auc(roc_col['FPR'], roc_col['TPR'])\n",
        "        roc_auc = round(roc_auc,4)\n",
        "        \n",
        "        pr_auc = auc(pr_col['Recall'], pr_col['Precision'])\n",
        "        pr_auc = round(pr_auc,4)\n",
        "        \n",
        "#         pr_gain_auc = auc(pr_gain_col['Rec-Gain'], pr_gain_col['Prec-Gain'])\n",
        "#         pr_gain_auc = round(pr_gain_auc,3)\n",
        "        \n",
        "#         gini = (2 * roc_auc) - 1\n",
        "#         gini = round(gini,4)\n",
        "        \n",
        "        top_result.at[index_i] = list(full_result[(full_result['Sem-Thr']==i) & (full_result['F1']==max(full_result[full_result['Sem-Thr']==i]['F1']))].values[0]) + [pr_auc, roc_auc]    # using .to_numpy() instead of .values\n",
        "        \n",
        "        if roc_auc >= max_roc_auc:\n",
        "            max_roc_auc = roc_auc\n",
        "            sem_thr_max = i\n",
        "            # str_max_index = index_i\n",
        "        if pr_auc >= max_pr_auc:\n",
        "            max_pr_auc = pr_auc\n",
        "            sem_thr_pr_max = i\n",
        "        \n",
        "#         if pr_gain_auc >= max_pr_gain_auc:\n",
        "#             max_pr_gain_auc = pr_gain_auc\n",
        "#             str_thr_gain_max = i\n",
        "        \n",
        "    # Plot the diagrams\n",
        "    figsize(10, 8)\n",
        "    plt.style.use('seaborn-dark-palette')\n",
        "    \n",
        "    # Plot the ROC curve\n",
        "    plt.plot(list(np.linspace(0, 1, num = 11)), list(np.linspace(0, 1, num = 11)), 'o--r', label = 'Naive Model (Random)') \n",
        "    roc_col = pd.DataFrame({'FPR': [], 'TPR': []})\n",
        "    roc_col = roc_col.append({'FPR': 0, 'TPR': 0}, ignore_index=True)\n",
        "    for item1, item2 in zip(full_result[full_result['Sem-Thr']==sem_thr_max]['FPR'], full_result[full_result['Sem-Thr']==sem_thr_max]['TPR']):\n",
        "        roc_col = roc_col.append({'FPR': item1, 'TPR': item2}, ignore_index=True)\n",
        "    roc_col = roc_col.append({'FPR': 1, 'TPR': 1}, ignore_index=True)\n",
        "    roc_col = roc_col.sort_values(by=['FPR'])\n",
        "    plt.plot(roc_col['FPR'], roc_col['TPR'], 'o-b', label = w_method + '_' + s_method)\n",
        "    for x, y, s in zip(full_result[full_result['Sem-Thr']==sem_thr_max]['FPR'], full_result[full_result['Sem-Thr']==sem_thr_max]['TPR'], thresholds):\n",
        "        plt.text(x - 0.04, y + 0.01, s, fontdict={'size': 10})\n",
        "    plt.legend(prop={'size':12}, shadow=True)  # loc=2 upper left\n",
        "    plt.ylabel('True Positive Rate', size = 15)\n",
        "    plt.xlabel('False Positive Rate', size = 15)\n",
        "    plt.title('ROC Curve at Sem-Thr = %s (AUC = %s)' % (str(sem_thr_max), str(max_roc_auc)), size = 18)\n",
        "    plt.savefig(root_path + w_method + '_' + s_method + '_roc_curve.png', bbox_inches='tight')\n",
        "    plt.clf()\n",
        "    \n",
        "    # Plot Precision-Recall curve\n",
        "    plt.plot([0, 1], [0.1, 0.1], 'o--r', label='Naive Model (Random)')\n",
        "    pr_col = pd.DataFrame({'Recall': [], 'Precision': []})\n",
        "    pr_col = pr_col.append({'Recall': 0, 'Precision': 1}, ignore_index=True)\n",
        "    for item1, item2 in zip(full_result[full_result['Sem-Thr']==sem_thr_pr_max]['Recall'], full_result[full_result['Sem-Thr']==sem_thr_pr_max]['Precision']):\n",
        "        pr_col = pr_col.append({'Recall': item1, 'Precision': item2}, ignore_index=True)\n",
        "    pr_col = pr_col.append({'Recall': 1, 'Precision': 0}, ignore_index=True)\n",
        "    pr_col = pr_col.sort_values(by=['Recall'])\n",
        "    plt.plot(pr_col['Recall'], pr_col['Precision'], 'o-b', label = w_method + '_' + s_method)\n",
        "    for x, y, s in zip(full_result[full_result['Sem-Thr']==sem_thr_pr_max]['Recall'], full_result[full_result['Sem-Thr']==sem_thr_pr_max]['Precision'], thresholds):\n",
        "        plt.text(x - 0.04, y + 0.01, s, fontdict={'size': 10})\n",
        "    plt.legend(prop={'size':12}, shadow=True)\n",
        "    plt.ylabel('Precision', size = 15)\n",
        "    plt.xlabel('Recall', size = 15)\n",
        "    plt.title('Precision-Recall Curve at Sem-Thr = %s (AUC = %s)' % (str(sem_thr_pr_max), str(max_pr_auc)), size = 18)\n",
        "    plt.savefig(root_path + w_method + '_' + s_method + '_pr_curve.png', bbox_inches='tight')\n",
        "    plt.clf()\n",
        "\n",
        "    # Plot Precision-Recall-Gain curve\n",
        "#     plt.plot(list(np.linspace(0, 1, num = 11)), list(np.linspace(1, 0, num = 11)), 'o--r', label='Naive Model (Random)')\n",
        "#     pr_gain_col = pd.DataFrame({'Rec-Gain': [], 'Prec-Gain': []})\n",
        "#     pr_gain_col = pr_gain_col.append({'Rec-Gain': 0, 'Prec-Gain': 1}, ignore_index=True)\n",
        "#     for item1, item2 in zip(full_result[full_result['Str-Thr']==str_thr_gain_max]['Rec-Gain'], full_result[full_result['Str-Thr']==str_thr_gain_max]['Prec-Gain']):\n",
        "#         pr_gain_col = pr_gain_col.append({'Rec-Gain': item1, 'Prec-Gain': item2}, ignore_index=True)\n",
        "#     pr_gain_col = pr_gain_col.append({'Rec-Gain': 1, 'Prec-Gain': 0}, ignore_index=True)\n",
        "#     pr_gain_col = pr_gain_col.sort_values(by=['Rec-Gain'])\n",
        "#     plt.plot(pr_gain_col['Rec-Gain'], pr_gain_col['Prec-Gain'], 'o-b', label = w_method + '_' + s_method)\n",
        "#     for x, y, s in zip(full_result[full_result['Str-Thr']==str_thr_gain_max]['Rec-Gain'], full_result[full_result['Str-Thr']==str_thr_gain_max]['Prec-Gain'], thresholds):\n",
        "#         plt.text(x - 0.04, y + 0.01, s, fontdict={'size': 10})\n",
        "#     plt.legend(prop={'size':12}, shadow=True)\n",
        "#     plt.ylabel('Precision-Gain', size = 15)\n",
        "#     plt.xlabel('Recall-Gain', size = 15)\n",
        "#     plt.title('Precision-Recall Gain Curve at Str-Thr = %s (AUC = %s)' % (str(str_thr_gain_max), str(max_pr_gain_auc)), size = 18)\n",
        "#     plt.savefig(root_path + w_method + '_' + s_method + '_pr_gain_curve.png', bbox_inches='tight')\n",
        "#     plt.clf()\n",
        "\n",
        "    \n",
        "    full_result.to_csv(root_path + w_method + '_' + s_method + '_full_results.csv', index=False)\n",
        "    top_result.to_csv(root_path + w_method + '_' + s_method + '_top_results.csv', index=False)\n",
        "    \n",
        "    make_table(top_result[['Sem-Thr', 'Str-Thr', 'TP', 'FP', 'TN', 'FN', 'Precision', 'Recall', 'F1', 'TPR', 'FPR', 'TNR (Spec)']], w_method + '_' + s_method + '_topres_basic_table')\n",
        "    make_table(top_result[['Sem-Thr', 'Str-Thr', 'B-Accuracy', 'Accuracy', 'Kappa', 'MCC', 'PR-AUC', 'ROC-AUC']], w_method + '_' + s_method + '_topres_advanced_table')\n",
        "    \n",
        "    cm_list = list(top_result[top_result['PR-AUC']==max(top_result['PR-AUC'])][['TN', 'FP','FN', 'TP']].values[0])\n",
        "    cm = np.array([[int(cm_list[0]), int(cm_list[1])],[int(cm_list[2]), int(cm_list[3])]], dtype=np.float32)\n",
        "    confusion_matrix(cm, ['Not-Aligned','Aligned'], w_method + '-' + s_method)\n",
        "    \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo1pH_iLkosQ",
        "colab_type": "code",
        "outputId": "3cac629a-f307-499c-fd31-5c3304721816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "dct = Dictionary(clean_labels)\n",
        "# print(list(dct.values()))\n",
        "dct_set = set(dct.values())\n",
        "dct_set = dct_set - set(['haemolymphoid', 'prezygapophysis', 'maculs', 'terryh', 'postzygapophysis'])  # 'gudden', 'terryh', 'haemolymphoid', 'masera', 'maculs'\n",
        "X = model1[dct_set]\n",
        "import umap\n",
        "\n",
        "cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0,\n",
        "                              n_components=2, random_state=42).fit_transform(X)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.scatter(cluster_embedding[:, 0], cluster_embedding[:, 1], s=3, cmap='Spectral')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-14 00:18:27,166 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2019-09-14 00:18:27,257 : INFO : adding document #10000 to Dictionary(4104 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...)\n",
            "2019-09-14 00:18:27,279 : INFO : built Dictionary(4366 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...) from 12484 documents (total 43435 corpus positions)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAIMCAYAAADch1mNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 720x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXpkNvgtgiMS",
        "colab_type": "code",
        "outputId": "32e853c0-ef8c-4233-c270-2d5d39adc89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# ex = []\n",
        "# ex.append(data[data['ID']=='ncic12412']['Value'])\n",
        "# ex.append(data[data['ID']=='ma0000411']['Value'])\n",
        "# ex.append(data[data['ID']=='ncic12722']['Value'])\n",
        "# ex.append(data[data['ID']=='ma0000396']['Value'])\n",
        "# emb = simple_average(clean_labels, model0)\n",
        "\n",
        "file1_emb = simple_average(clean_labels1, new_vec1)\n",
        "file2_emb = simple_average(clean_labels2, new_vec1)\n",
        "\n",
        "\n",
        "##################################\n",
        "from sklearn.manifold import TSNE\n",
        "from __future__ import unicode_literals\n",
        "dct = Dictionary(clean_labels)\n",
        "dct_set = set(dct.values())\n",
        "dct_set = dct_set - set(['prezygapophysis', 'terryh', 'haemolymphoid', 'maculs', 'postzygapophysis'])\n",
        "def tsne_plot(model):\n",
        "    \n",
        "    \"Creates and TSNE model and plots it\"\n",
        "    labels = []\n",
        "    tokens = []\n",
        "    plt.rc('font', **{'sans-serif' : 'Arial', 'family' : 'sans-serif'})\n",
        "    \n",
        "    labels = ['ncic12234','ncic12999','ma0001588','ma0002478']\n",
        "    for i, sent1 in enumerate(file1_emb):\n",
        "        if (data1.loc[i, 'ID'] == 'ncic12234') or (data1.loc[i, 'ID'] == 'ncic12999'): \n",
        "            tokens.append(sent1)\n",
        "    for j, sent2 in enumerate(file2_emb):\n",
        "        if (data2.loc[j, 'ID'] == 'ma0001588') or (data2.loc[j, 'ID'] == 'ma0002478'): \n",
        "            tokens.append(sent2)\n",
        "\n",
        "#     for i, sent1 in enumerate(file1_emb):\n",
        "#         tokens.append(sent1)\n",
        "#         labels.append(data1.loc[i, 'ID'])\n",
        "#     for j, sent2 in enumerate(file2_emb):\n",
        "#         tokens.append(sent2)\n",
        "#         labels.append(data2.loc[j, 'ID'])\n",
        "    \n",
        "#     for word in dct_set:\n",
        "#         tokens.append(model[word])\n",
        "#         labels.append(word)\n",
        "        \n",
        "    \n",
        "    tsne_model = TSNE(n_components=2, perplexity=40, metric='cosine', \n",
        "                      early_exaggeration=10.0, init='pca', \n",
        "                      verbose=True, n_iter=400)\n",
        "    new_values = tsne_model.fit_transform(tokens)\n",
        "    \n",
        "    x = []\n",
        "    y = []\n",
        "    for value in new_values:\n",
        "        x.append(value[0])\n",
        "        y.append(value[1])\n",
        "    \n",
        "    return x, y, labels\n",
        "\n",
        "x_axis, y_axis, labels_plot = tsne_plot(new_vec1)\n",
        "\n",
        "list_of_tuples = list(zip(labels_plot, x_axis, y_axis))\n",
        "# df_for_plot = pd.DataFrame(columns=['Name', 'X', 'Y'])\n",
        "df_for_plot = pd.DataFrame(list_of_tuples, columns = ['Name', 'X', 'Y'])\n",
        "\n",
        "plt.figure(figsize=(16, 16))\n",
        "for i in range(len(x_axis)):\n",
        "    plt.scatter(x_axis[i], y_axis[i])\n",
        "    plt.annotate(labels_plot[i], \n",
        "                 xy=(x_axis[i], y_axis[i]), \n",
        "                 xytext=(5,2), \n",
        "                 textcoords='offset points', \n",
        "                 ha='right', \n",
        "                 va='bottom')\n",
        "\n",
        "x11 = float(df_for_plot[df_for_plot['Name']=='ncic12234']['X'])\n",
        "y11 = float(df_for_plot[df_for_plot['Name']=='ncic12234']['Y'])\n",
        "x21 = float(df_for_plot[df_for_plot['Name']=='ncic12999']['X'])\n",
        "y21 = float(df_for_plot[df_for_plot['Name']=='ncic12999']['Y'])\n",
        "x12 = float(df_for_plot[df_for_plot['Name']=='ma0001588']['X'])\n",
        "y12 = float(df_for_plot[df_for_plot['Name']=='ma0001588']['Y'])\n",
        "x22 = float(df_for_plot[df_for_plot['Name']=='ma0002478']['X'])\n",
        "y22 = float(df_for_plot[df_for_plot['Name']=='ma0002478']['Y'])\n",
        "# plt.arrow(x11, y11,x12-x11,y12-y11-4, color='red',alpha=0.3, zorder=0, length_includes_head=True, overhang=0.8, head_width=0.1, head_length=0.15)\n",
        "# plt.arrow(x21, y21,x22-x21-4,y22-y21, color='blue',alpha=0.3, zorder=0, length_includes_head=True, overhang=0.8, head_width=0.1, head_length=0.15)\n",
        "plt.annotate('', xy=(x12-1,y12-1), xytext=(x11,y11), arrowprops={'arrowstyle': '-|>'})\n",
        "plt.annotate('', xy=(x22-1,y22-1), xytext=(x21,y21), arrowprops={'arrowstyle': '-|>'})\n",
        "plt.ylabel('Y', size = 15)\n",
        "plt.xlabel('X', size = 15)\n",
        "plt.title('Distance Between Two Related Alignments', size = 18)\n",
        "# plt.savefig(root_path + 'another_avg_cosine' + '_align_dist.png', bbox_inches='tight')\n",
        "# plt.clf()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-14 00:27:46,941 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
            "2019-09-14 00:27:47,037 : INFO : adding document #10000 to Dictionary(4104 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...)\n",
            "2019-09-14 00:27:47,057 : INFO : built Dictionary(4366 unique tokens: ['anatomic', 'structure', 'substance', 'system', 'lip']...) from 12484 documents (total 43435 corpus positions)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[t-SNE] Computing 3 nearest neighbors...\n",
            "[t-SNE] Indexed 4 samples in 0.000s...\n",
            "[t-SNE] Computed neighbors for 4 samples in 0.001s...\n",
            "[t-SNE] Computed conditional probabilities for sample 4 / 4\n",
            "[t-SNE] Mean sigma: 1125899906842624.000000\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 23.934990\n",
            "[t-SNE] KL divergence after 400 iterations: 0.048722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
            "  (prop.get_family(), self.defaultFamily[fontext]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAOsCAYAAACGV9GSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wM/ASCD5y5UxgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x1152 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs-1IdgH_Stq",
        "colab_type": "code",
        "outputId": "1e23886b-f89a-4c9e-be89-dacb6cc3931b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print(df_for_plot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Name           X           Y\n",
            "0  ncic12412    7.362408 -178.321625\n",
            "1  ncic12722 -164.992035    2.220841\n",
            "2  ma0000396  184.941360   -2.865971\n",
            "3  ma0000411   12.532672  177.643250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDlDLSSUkUne",
        "colab_type": "code",
        "outputId": "883bf8c0-5200-40bf-fd0b-8948a95438ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# Install Altair and activate its colab renderer.\n",
        "print(\"Installing Altair...\")\n",
        "!pip install git+git://github.com/altair-viz/altair.git\n",
        "import altair as alt\n",
        "alt.data_transformers.enable('default', max_rows=None)\n",
        "alt.renderers.enable('colab')\n",
        "print(\"Done installing Altair.\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing Altair...\n",
            "Collecting git+git://github.com/altair-viz/altair.git\n",
            "  Cloning git://github.com/altair-viz/altair.git to /tmp/pip-req-build-7z8ud2mf\n",
            "  Running command git clone -q git://github.com/altair-viz/altair.git /tmp/pip-req-build-7z8ud2mf\n",
            "Requirement already satisfied (use --upgrade to upgrade): altair==3.3.0.dev0 from git+git://github.com/altair-viz/altair.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (2.10.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (0.24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (1.12.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair==3.3.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->altair==3.3.0.dev0) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->altair==3.3.0.dev0) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->altair==3.3.0.dev0) (2018.9)\n",
            "Building wheels for collected packages: altair\n",
            "  Building wheel for altair (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for altair: filename=altair-3.3.0.dev0-py2.py3-none-any.whl size=598632 sha256=5069812340fc717d8bd1600a8779ea1ced82abe17a0b4d41d2e02f837059b535\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b9loeht_/wheels/01/fd/91/025b6149b3949af76e93b3b3ceca5bf12cbdebc98fa46f9ec6\n",
            "Successfully built altair\n",
            "Done installing Altair.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMF5PCZmjSy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Interavtice altair\n",
        "nearest = alt.selection(\n",
        "    type='multi', encodings=['x', 'y'], on='mouseover', nearest=True,\n",
        "    empty='none')\n",
        "\n",
        "\n",
        "\n",
        "text = alt.Chart(df_for_plot).mark_text(align='left', dx=5, dy=-5).encode(\n",
        "    x='X',\n",
        "    y='Y',\n",
        "    text=alt.condition(nearest, 'Name', alt.value('')))\n",
        "\n",
        "\n",
        "base = alt.Chart(df_for_plot).mark_circle().encode(\n",
        "    x='X',\n",
        "    y='Y',\n",
        "#     color=alt.condition(genre_filter, \"genre\", alt.value(\"whitesmoke\")),\n",
        ").properties(\n",
        "    width=1200,\n",
        "    height=900,\n",
        "    selection=nearest).add_selection(\n",
        "    scales\n",
        ")\n",
        "\n",
        "alt.layer(base, text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh2jSNPMjsOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# another one\n",
        "scales = alt.selection_interval(bind='scales')\n",
        "\n",
        "alt.Chart(df_for_plot).mark_point().encode(\n",
        "    x='X:Q',\n",
        "    y='Y:Q',\n",
        "   \n",
        ").add_selection(\n",
        "    scales\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6j0XOfPCqqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@ray.remote\n",
        "@timing\n",
        "def semantic_similarity1(clean_corpus, clean_file1, clean_file2, model, weigh_method='avg', sim_method='cosine',\n",
        "                            threshold=0.8, str_threshold=0.8, alpha=0.5, f_threshold=0.6):\n",
        "    import csv\n",
        "    fields = ['ID1', 'ID2', 'sem_sim']  # 'str_sim', 'struc_sim'\n",
        "    len1 = len(clean_file1)\n",
        "    len2 = len(clean_file2)\n",
        "    clean_nontok_file1 = [' '.join(sent) for sent in clean_file1]\n",
        "    clean_nontok_file2 = [' '.join(sent) for sent in clean_file2]\n",
        "    outfile = open(root_path + weigh_method + '_' + sim_method + '_new_results.csv', 'w+', newline='') # or 'a+'\n",
        "    out_writer = csv.writer(outfile, delimiter=',')\n",
        "    out_writer.writerow(fields)\n",
        "    if weigh_method == 'avg':\n",
        "        file1_emb = simple_average(clean_file1, model)\n",
        "        file2_emb = simple_average(clean_file2, model)\n",
        "        if sim_method == 'cosine':\n",
        "            \n",
        "            for i in tqdm(range(len1)):\n",
        "                max_cosine = 0\n",
        "                j_index = 0\n",
        "                len_i = 1 / len(clean_file1[i])\n",
        "                for j in range(len2):\n",
        "#                     simm = 1 - cosine(file1_emb[i], file2_emb[j])\n",
        "                    cosine_list = []\n",
        "                    for w in clean_file1[i]:\n",
        "                        if w in model:\n",
        "                            cosine_list.append(cosine(model[w], file2_emb[j]))\n",
        "                    delta12 = len_i * sum(cosine_list)\n",
        "                    cosine_list = []\n",
        "                    for w in clean_file2[j]:\n",
        "                        if w in model:\n",
        "                            cosine_list.append(cosine(model[w], file1_emb[i]))\n",
        "                    delta21 = (1 / len(clean_file2[j])) * sum(cosine_list)\n",
        "                    simm = 1 - max(delta12, delta21)\n",
        "                    if simm >= max_cosine:\n",
        "                        max_cosine = simm\n",
        "                        j_index = j\n",
        "                if max_cosine >= threshold:\n",
        "#                         strsim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "#                         if strsim >= str_threshold:\n",
        "                    row = []\n",
        "                    row.append(data1.at[i, 'ID']) # data1.at[i, 'ID'] or data1.loc[i, 'ID']\n",
        "                    row.append(data2.at[j_index, 'ID'])\n",
        "                    row.append(max_cosine)\n",
        "                    out_writer.writerow(row)\n",
        "                \n",
        "\n",
        "            # by Cosine Sim pairwise\n",
        "            # sims = cosine_similarity(file1_emb, file2_emb)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "\n",
        "            # by Cosine Distance\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 max_sim = 0\n",
        "#                 j_index = 0\n",
        "#                 for j in range(len2):\n",
        "#                     # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "#                     str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "#                     sim = 1 - cosine(file1_emb[i], file2_emb[j])\n",
        "#                     f_sim = (alpha * str_sim) + ((1 - alpha) * sim)\n",
        "#                     if f_sim >= max_sim:\n",
        "#                         j_index = j\n",
        "#                         max_sim = f_sim        \n",
        "#                 if max_sim >= f_threshold:\n",
        "#                     row = []\n",
        "#                     row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                     row.append(data2.loc[j_index, 'ID'])\n",
        "#                     row.append(max_sim)\n",
        "#                     out_writer.writerow(row)\n",
        "            \n",
        "\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 max_sim = 0\n",
        "#                 j_index = 0\n",
        "#                 for j in range(len2):\n",
        "#                     # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "#                     str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "#                     # str_sim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "#                     if str_sim >= str_threshold:\n",
        "#                         sim = 1 - cosine(file1_emb[i], file2_emb[j])\n",
        "#                         if sim >= max_sim:\n",
        "#                             j_index = j\n",
        "#                             max_sim = sim        \n",
        "#                 if max_sim >= threshold:\n",
        "#                     row = []\n",
        "#                     row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                     row.append(data2.loc[j_index, 'ID'])\n",
        "#                     row.append(max_sim)\n",
        "#                     out_writer.writerow(row)\n",
        "    \n",
        "            \n",
        "#             # with str sim            \n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 max_sim = 0\n",
        "#                 j_index = 0\n",
        "#                 for j in range(len2):\n",
        "#                     # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "#                     str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "#                     # str_sim = similarity(clean_nontok_file1[i],clean_nontok_file2[j])\n",
        "#                     if str_sim >= max_sim:\n",
        "#                         j_index = j\n",
        "#                         max_sim = str_sim        \n",
        "#                 if max_sim >= str_threshold:\n",
        "#                     sim = 1 - cosine(file1_emb[i], file2_emb[j_index])\n",
        "#                     if sim >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j_index, 'ID'])\n",
        "#                         row.append(max_sim)\n",
        "#                         out_writer.writerow(row)\n",
        "\n",
        "#############\n",
        "\n",
        "#                 else:\n",
        "#                     sim = 1 - cosine(file1_emb[i], file2_emb[j_index])\n",
        "#                     if sim >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j_index, 'ID'])\n",
        "#                         row.append(max_sim)\n",
        "#                         out_writer.writerow(row)\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_emb[i],file2_emb[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'tfidf-emb':\n",
        "        #file1_tf = tfidf_v1(clean_corpus, model, clean_file1)\n",
        "        #file2_tf = tfidf_v1(clean_corpus, model, clean_file2)\n",
        "        file1_tf = tf_idf_v2(clean_corpus, model, clean_file1)\n",
        "        file2_tf = tf_idf_v2(clean_corpus, model, clean_file2)\n",
        "        if sim_method == 'cosine':\n",
        "            # by Cosine Sim pairwise\n",
        "            # sims = cosine_similarity(file1_tf, file2_tf)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = 1 - cosine(file1_tf[i], file2_tf[j_index])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j_index, 'ID'])\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)        \n",
        "        elif sim_method == 'ts-ss':\n",
        "            # using a function\n",
        "            # sims = tfidf_soft_cosine_TSSS(clean_corpus, clean_file1, clean_file2, model)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "            ######\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_tf[i], file2_tf[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'tfidf':\n",
        "        clean_nontok_file1 = [' '.join(sent) for sent in clean_file1]\n",
        "        clean_nontok_file2 = [' '.join(sent) for sent in clean_file2]\n",
        "        vectorizer = TfidfVectorizer()  # (preprocessor=nlp.clean_tf_idf_text)\n",
        "        docs_tfidf1 = vectorizer.fit_transform(clean_nontok_file1)\n",
        "        docs_tfidf2 = vectorizer.fit_transform(clean_nontok_file2)\n",
        "        # query_tfidf = vectorizer.transform([query])\n",
        "        if sim_method == 'cosine':\n",
        "            # by Cosine Sim pairwise\n",
        "            # sims = cosine_similarity(docs_tfidf1, docs_tfidf2)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(docs_tfidf1[i], docs_tfidf2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(docs_tfidf1[i], docs_tfidf2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'sif':\n",
        "#         file1_sif = smooth_inverse_frequency(clean_file1, model)\n",
        "#         file2_sif = smooth_inverse_frequency(clean_file2, model)\n",
        "        file1_sif = sif_embeddings1(clean_file1, model)\n",
        "        file2_sif = sif_embeddings1(clean_file2, model)\n",
        "        if sim_method == 'cosine':\n",
        "            # by Cosine Sim pairwise\n",
        "            # sims = cosine_similarity(file1_sif, file2_sif)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = 1 - cosine(file1_sif[i], file2_sif[j_index])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j_index, 'ID'])\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)      \n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(file1_sif[i], file2_sif[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'non-vector':\n",
        "        if sim_method == 'n-sim':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = model.wv.n_similarity(clean_file1[i], clean_file2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        elif sim_method == 'wmd':\n",
        "            # by wmdDistance\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    dis = word_mover_distance(clean_file1[i], clean_file2[j], model)\n",
        "                    sim = 1 / (1 + dis)\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        out_writer.writerow(row)\n",
        "\n",
        "#             # by WmdSimilarity\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 sims = wmd_gensim(clean_file1[i], clean_file2, model)\n",
        "#                 for j in range(len2):\n",
        "#                     if sims[j] >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j, 'ID'])\n",
        "#                         row.append(sims[j])\n",
        "#                         out_writer.writerow(row)\n",
        "        elif sim_method == 'soft':\n",
        "#             # by function 1\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 sim = soft_cosine_sim(model, clean_file1[i], clean_corpus, clean_file2, True)\n",
        "#                 for j in range(len2):\n",
        "#                     if sim[j] >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j, 'ID'])\n",
        "#                         row.append(sim[j])\n",
        "#                         out_writer.writerow(row)\n",
        "            \n",
        "#             # by function 2\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 sim = softcossimilarity(model, clean_file1[i], clean_corpus, clean_file2)\n",
        "#                 for j in range(len2):\n",
        "#                     if sim[j] >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j, 'ID'])\n",
        "#                         row.append(sim[j])\n",
        "#                         out_writer.writerow(row)\n",
        "\n",
        "            # without any functions\n",
        "\n",
        "#             # by softcossim: DEPRECATED\n",
        "#             termsim_index = WordEmbeddingSimilarityIndex(model.wv)  # Any trained model\n",
        "#             # Prepare a dictionary and a corpus.\n",
        "#             dictionary = Dictionary(clean_corpus)\n",
        "#             tf_idf = TfidfModel(dictionary=dictionary)\n",
        "            \n",
        "#             # Prepare the similarity matrix\n",
        "#             # Deprecated (with problem)\n",
        "#             # similarity_matrix = model.similarity_matrix(dictionary, tfidf=tf_idf, threshold=0.0, exponent=2.0, nonzero_limit=100)  # tfidf=None\n",
        "            \n",
        "#             similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary, tf_idf)  # construct similarity matrix\n",
        "#             # bow_corpus = [dictionary.doc2bow(document) for document in clean_corpus]\n",
        "#             bow_corpus1 = [dictionary.doc2bow(document) for document in clean_file1]\n",
        "#             bow_corpus2 = [dictionary.doc2bow(document) for document in clean_file2]\n",
        "#             # Compute soft cosine similarity\n",
        "#             for i in tqdm(range(len1)):\n",
        "#                 for j in range(len2):\n",
        "#                     sim = softcossim(bow_corpus1[i], bow_corpus2[j], similarity_matrix) # Deprecated\n",
        "#                     if sim >= threshold:\n",
        "#                         row = []\n",
        "#                         row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "#                         row.append(data2.loc[j, 'ID'])\n",
        "#                         row.append(sim)\n",
        "#                         out_writer.writerow(row)\n",
        "\n",
        "            # by inner_product\n",
        "            termsim_index = WordEmbeddingSimilarityIndex(model.wv)  # Any trained model\n",
        "            dictionary = Dictionary(clean_corpus)\n",
        "            tfidf_model = TfidfModel(dictionary=dictionary)\n",
        "            similarity_matrix = SparseTermSimilarityMatrix(termsim_index, dictionary,\n",
        "                                                           tfidf_model)  # construct similarity matrix\n",
        "            bow_corpus1 = [dictionary.doc2bow(document) for document in clean_file1]\n",
        "            bow_corpus2 = [dictionary.doc2bow(document) for document in clean_file2]\n",
        "            # Compute soft cosine similarity\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = similarity_matrix.inner_product(bow_corpus1[i], bow_corpus2[j_index], normalized=True) # return SCM\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j_index, 'ID'])\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)       \n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'fse':\n",
        "        from fse.models import Sentence2Vec\n",
        "        from fse.models.sentence2vec import CY_ROUTINES\n",
        "        # assert CY_ROUTINES\n",
        "        fse_model = Sentence2Vec(model)\n",
        "        # fse_embed1 = fse_model.train(clean_corpus)\n",
        "        fse_embed1 = fse_model.train(clean_file1)\n",
        "        fse_embed2 = fse_model.train(clean_file2)\n",
        "        fse_model.normalize(fse_embed1)\n",
        "        fse_model.normalize(fse_embed2)\n",
        "        # fse_embed1 = list(fse_embed1)\n",
        "        # fse_embed2 = list(fse_embed2)\n",
        "        if sim_method == 'cosine':\n",
        "            # by Cosine Sim pairwise\n",
        "            # sim = cosine_similarity(fse_embed1, fse_embed2)\n",
        "            # for i in tqdm(range(len1)):\n",
        "            #     for j in range(len2):\n",
        "            #         if sims[i][j] >= threshold:\n",
        "            #             row = []\n",
        "            #             row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "            #             row.append(data2.loc[j, 'ID'])\n",
        "            #             row.append(sims[i][j])\n",
        "            #             out_writer.writerow(row)\n",
        "\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(fse_embed1[i], fse_embed2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        elif sim_method == 'ts-ss':\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(fse_embed1[i], fse_embed2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "\n",
        "    elif weigh_method == 'spacy':\n",
        "        if sim_method == 'cosine':\n",
        "            spacy_emb1 = sentence_mean(nlp, clean_file1)\n",
        "            spacy_emb2 = sentence_mean(nlp, clean_file2)\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = 1 - cosine(spacy_emb1[i], spacy_emb2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        elif sim_method == 'ts-ss':\n",
        "            spacy_emb1 = sentence_mean(nlp, clean_file1)\n",
        "            spacy_emb2 = sentence_mean(nlp, clean_file2)\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(spacy_emb1[i], spacy_emb2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        elif sim_method == 'spacy':\n",
        "            nlpp = spacy.load('en_core_web_sm')\n",
        "            doc1 = []\n",
        "            doc2 = []\n",
        "            for i in tqdm(range(len1)):\n",
        "                doc1.append(nlpp(' '.join(clean_file1[i])))\n",
        "            for j in tqdm(range(len2)):\n",
        "                doc2.append(nlpp(' '.join(clean_file2[j])))\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = doc1[i].similarity(doc2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'wordnet':\n",
        "        from wnet import similarity\n",
        "        for i in tqdm(range(len1)):\n",
        "            sent1 = clean_file1[i]\n",
        "            for j in range(len2):\n",
        "                sim = similarity(sent1, clean_file2[j], True)\n",
        "                if sim >= threshold:\n",
        "                    row = []\n",
        "                    row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                    row.append(data2.loc[j, 'ID'])\n",
        "                    row.append(sim)\n",
        "                    out_writer.writerow(row)\n",
        "    elif weigh_method == 'infersent-glove':\n",
        "        from infersentmodel import InferSent\n",
        "        clean_nontok_corpus = [' '.join(sent) for sent in clean_corpus]\n",
        "        infer_model, emb1, emb2 = infersent_v1(clean_nontok_corpus, clean_nontok_file1, clean_nontok_file2, ver=1,\n",
        "                                               model_path=root_path + 'encoder/', glove_path=bio_data2)\n",
        "        if sim_method == 'cosine':\n",
        "            # sim = 1 - cosine(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = 1 - cosine(emb1[i], emb2[j_index])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j_index, 'ID'])\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)       \n",
        "        elif sim_method == 'ts-ss':\n",
        "            # sim = TS_SS(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(emb1[i], emb2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID'])  # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'infersent-fasttext':\n",
        "        from infersentmodel import InferSent\n",
        "        clean_nontok_corpus = [' '.join(sent) for sent in clean_corpus]\n",
        "        infer_model, emb1, emb2 = infersent_v1(clean_nontok_corpus, clean_nontok_file1, clean_nontok_file2, ver=2, model_path=root_path + 'encoder/', fasttext_path=google_pretrained_model)\n",
        "        if sim_method == 'cosine':\n",
        "            # sim = 1 - cosine(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            # by Cosine Distance\n",
        "            for i in tqdm(range(len1)):\n",
        "                max_sim = 0\n",
        "                j_index = 0\n",
        "                for j in range(len2):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        j_index = j\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = 1 - cosine(emb1[i], emb2[j_index])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j_index, 'ID'])\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)                   \n",
        "        elif sim_method == 'ts-ss':\n",
        "            # sim = TS_SS(infer_model.encode(['the cat eats.'])[0], infer_model.encode(['the cat drinks.'])[0])\n",
        "            for i in tqdm(range(len1)):\n",
        "                for j in range(len2):\n",
        "                    sim = TS_SS(emb1[i], emb2[j])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(data1.loc[i, 'ID']) # data1.at[i, 'ID']\n",
        "                        row.append(data2.loc[j, 'ID'])\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    elif weigh_method == 'doc2vec':\n",
        "        #from d2v import d2v_method\n",
        "        d2v_tags = [text for text in data['ID']]\n",
        "        d2v_model = d2v_method(clean_corpus, d2v_tags, max_epochs=100, loading=True)\n",
        "        if sim_method == 'cosine':\n",
        "            for i, id1 in tqdm(enumerate(data1['ID'])):\n",
        "                id1_vec = d2v_model.docvecs[id1]\n",
        "                max_sim = 0\n",
        "                id2_new = ''\n",
        "                for j, id2 in enumerate(data2['ID']):\n",
        "                    # str_sim = trigram_sim(clean_file1[i], clean_file2[j])\n",
        "                    str_sim = fuzz.token_sort_ratio(clean_nontok_file1[i],clean_nontok_file2[j]) / 100\n",
        "                    if str_sim >= max_sim:\n",
        "                        id2_new = id2\n",
        "                        max_sim = str_sim        \n",
        "                if max_sim >= str_threshold:\n",
        "                    sim = 1 - cosine(id1_vec, d2v_model.docvecs[id2_new])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(id1)\n",
        "                        row.append(id2_new)\n",
        "                        row.append(max_sim)\n",
        "                        out_writer.writerow(row)                           \n",
        "        elif sim_method == 'ts-ss':\n",
        "            for id1 in tqdm(data1['ID']):\n",
        "                id1_vec = d2v_model.docvecs[id1]\n",
        "                for id2 in data2['ID']:\n",
        "                    sim = TS_SS(id1_vec, d2v_model.docvecs[id2])\n",
        "                    if sim >= threshold:\n",
        "                        row = []\n",
        "                        row.append(id1)\n",
        "                        row.append(id2)\n",
        "                        row.append(sim)\n",
        "                        out_writer.writerow(row)\n",
        "        else:\n",
        "            print('Similarity Method Error: Unfortunately, the entered similarity method \"' + sim_method +\n",
        "                  '\" is not defined in this weighing method \"' + weigh_method + '\"')\n",
        "    else:\n",
        "        print('Weighing Method Error: Unfortunately, the entered weighing method \"' + weigh_method +\n",
        "              '\" is not defined in this function')\n",
        "    outfile.close()\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "#@ray.remote\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaYOR53XCrco",
        "colab_type": "code",
        "outputId": "a2a6685c-0643-4eec-fbf3-c1e5292a29b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from ts_ss import TS_SS\n",
        "#from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "semantic_similarity1(clean_labels, clean_labels1, clean_labels2,  new_vec1, weigh_method='avg', sim_method='cosine', threshold=0.8, str_threshold=0.9, alpha=0.9, f_threshold=0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in double_scalars\n",
            "\n",
            "  0%|          | 0/3298 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/3298 [00:00<51:08,  1.07it/s]\u001b[A\n",
            "  0%|          | 2/3298 [00:01<44:39,  1.23it/s]\u001b[A\n",
            "  0%|          | 3/3298 [00:02<44:36,  1.23it/s]\u001b[A\n",
            "  0%|          | 4/3298 [00:03<45:02,  1.22it/s]\u001b[A\n",
            "  0%|          | 5/3298 [00:03<42:45,  1.28it/s]\u001b[A\n",
            "  0%|          | 6/3298 [00:04<43:16,  1.27it/s]\u001b[A\n",
            "  0%|          | 7/3298 [00:05<43:41,  1.26it/s]\u001b[A\n",
            "  0%|          | 8/3298 [00:06<41:27,  1.32it/s]\u001b[A\n",
            "  0%|          | 9/3298 [00:06<39:58,  1.37it/s]\u001b[A\n",
            "  0%|          | 10/3298 [00:07<39:03,  1.40it/s]\u001b[A\n",
            "  0%|          | 11/3298 [00:07<36:08,  1.52it/s]\u001b[A\n",
            "  0%|          | 12/3298 [00:08<36:31,  1.50it/s]\u001b[A\n",
            "  0%|          | 13/3298 [00:09<36:27,  1.50it/s]\u001b[A\n",
            "  0%|          | 14/3298 [00:09<34:13,  1.60it/s]\u001b[A\n",
            "  0%|          | 15/3298 [00:10<34:32,  1.58it/s]\u001b[A\n",
            "  0%|          | 16/3298 [00:11<37:40,  1.45it/s]\u001b[A\n",
            "  1%|          | 17/3298 [00:11<37:11,  1.47it/s]\u001b[A\n",
            "  1%|          | 18/3298 [00:12<36:50,  1.48it/s]\u001b[A\n",
            "  1%|          | 19/3298 [00:13<34:11,  1.60it/s]\u001b[A\n",
            "  1%|          | 20/3298 [00:13<37:01,  1.48it/s]\u001b[A\n",
            "  1%|          | 21/3298 [00:14<38:56,  1.40it/s]\u001b[A\n",
            "  1%|          | 22/3298 [00:15<40:21,  1.35it/s]\u001b[A\n",
            "  1%|          | 23/3298 [00:16<41:21,  1.32it/s]\u001b[A\n",
            "  1%|          | 24/3298 [00:17<42:11,  1.29it/s]\u001b[A\n",
            "  1%|          | 25/3298 [00:17<42:39,  1.28it/s]\u001b[A\n",
            "  1%|          | 26/3298 [00:18<43:03,  1.27it/s]\u001b[A\n",
            "  1%|          | 27/3298 [00:19<38:24,  1.42it/s]\u001b[A\n",
            "  1%|          | 28/3298 [00:20<39:48,  1.37it/s]\u001b[A\n",
            "  1%|          | 29/3298 [00:20<38:31,  1.41it/s]\u001b[A\n",
            "  1%|          | 30/3298 [00:21<37:32,  1.45it/s]\u001b[A\n",
            "  1%|          | 31/3298 [00:22<37:04,  1.47it/s]\u001b[A\n",
            "  1%|          | 32/3298 [00:22<39:05,  1.39it/s]\u001b[A\n",
            "  1%|          | 33/3298 [00:23<39:52,  1.36it/s]\u001b[A\n",
            "  1%|          | 34/3298 [00:24<40:47,  1.33it/s]\u001b[A\n",
            "  1%|          | 35/3298 [00:24<37:07,  1.46it/s]\u001b[A\n",
            "  1%|          | 36/3298 [00:25<36:28,  1.49it/s]\u001b[A\n",
            "  1%|          | 37/3298 [00:26<36:21,  1.50it/s]\u001b[A\n",
            "  1%|          | 38/3298 [00:26<36:05,  1.51it/s]\u001b[A\n",
            "  1%|          | 39/3298 [00:27<33:26,  1.62it/s]\u001b[A\n",
            "  1%|          | 40/3298 [00:28<34:00,  1.60it/s]\u001b[A\n",
            "  1%|          | 41/3298 [00:28<34:17,  1.58it/s]\u001b[A\n",
            "  1%|▏         | 42/3298 [00:29<32:28,  1.67it/s]\u001b[A\n",
            "  1%|▏         | 43/3298 [00:29<33:50,  1.60it/s]\u001b[A\n",
            "  1%|▏         | 44/3298 [00:30<34:12,  1.59it/s]\u001b[A\n",
            "  1%|▏         | 45/3298 [00:31<34:39,  1.56it/s]\u001b[A\n",
            "  1%|▏         | 46/3298 [00:31<35:16,  1.54it/s]\u001b[A\n",
            "  1%|▏         | 47/3298 [00:32<35:08,  1.54it/s]\u001b[A\n",
            "  1%|▏         | 48/3298 [00:33<35:24,  1.53it/s]\u001b[A\n",
            "  1%|▏         | 49/3298 [00:33<35:30,  1.53it/s]\u001b[A\n",
            "  2%|▏         | 50/3298 [00:34<35:17,  1.53it/s]\u001b[A\n",
            "  2%|▏         | 51/3298 [00:35<38:03,  1.42it/s]\u001b[A\n",
            "  2%|▏         | 52/3298 [00:35<37:17,  1.45it/s]\u001b[A\n",
            "  2%|▏         | 53/3298 [00:36<36:36,  1.48it/s]\u001b[A\n",
            "  2%|▏         | 54/3298 [00:37<36:23,  1.49it/s]\u001b[A\n",
            "  2%|▏         | 55/3298 [00:37<36:20,  1.49it/s]\u001b[A\n",
            "  2%|▏         | 56/3298 [00:38<36:06,  1.50it/s]\u001b[A\n",
            "  2%|▏         | 57/3298 [00:39<33:40,  1.60it/s]\u001b[A\n",
            "  2%|▏         | 58/3298 [00:39<31:49,  1.70it/s]\u001b[A\n",
            "  2%|▏         | 59/3298 [00:40<33:21,  1.62it/s]\u001b[A\n",
            "  2%|▏         | 60/3298 [00:40<33:55,  1.59it/s]\u001b[A\n",
            "  2%|▏         | 61/3298 [00:41<36:38,  1.47it/s]\u001b[A\n",
            "  2%|▏         | 62/3298 [00:42<41:00,  1.32it/s]\u001b[A\n",
            "  2%|▏         | 63/3298 [00:43<41:22,  1.30it/s]\u001b[A\n",
            "  2%|▏         | 64/3298 [00:43<37:10,  1.45it/s]\u001b[A\n",
            "  2%|▏         | 65/3298 [00:44<36:30,  1.48it/s]\u001b[A\n",
            "  2%|▏         | 66/3298 [00:45<36:05,  1.49it/s]\u001b[A\n",
            "  2%|▏         | 67/3298 [00:46<40:32,  1.33it/s]\u001b[A\n",
            "  2%|▏         | 68/3298 [00:47<41:06,  1.31it/s]\u001b[A\n",
            "  2%|▏         | 69/3298 [00:47<39:17,  1.37it/s]\u001b[A\n",
            "  2%|▏         | 70/3298 [00:48<42:30,  1.27it/s]\u001b[A\n",
            "  2%|▏         | 71/3298 [00:49<44:51,  1.20it/s]\u001b[A\n",
            "  2%|▏         | 72/3298 [00:50<39:44,  1.35it/s]\u001b[A\n",
            "  2%|▏         | 73/3298 [00:50<36:13,  1.48it/s]\u001b[A\n",
            "  2%|▏         | 74/3298 [00:51<37:52,  1.42it/s]\u001b[A\n",
            "  2%|▏         | 75/3298 [00:52<41:38,  1.29it/s]\u001b[A\n",
            "  2%|▏         | 76/3298 [00:53<44:05,  1.22it/s]\u001b[A\n",
            "  2%|▏         | 77/3298 [00:54<46:04,  1.16it/s]\u001b[A\n",
            "  2%|▏         | 78/3298 [00:55<47:19,  1.13it/s]\u001b[A\n",
            "  2%|▏         | 79/3298 [00:55<46:24,  1.16it/s]\u001b[A\n",
            "  2%|▏         | 80/3298 [00:56<43:14,  1.24it/s]\u001b[A\n",
            "  2%|▏         | 81/3298 [00:57<40:53,  1.31it/s]\u001b[A\n",
            "  2%|▏         | 82/3298 [00:57<37:20,  1.44it/s]\u001b[A\n",
            "  3%|▎         | 83/3298 [00:58<34:42,  1.54it/s]\u001b[A\n",
            "  3%|▎         | 84/3298 [00:58<32:54,  1.63it/s]\u001b[A\n",
            "  3%|▎         | 85/3298 [00:59<31:26,  1.70it/s]\u001b[A\n",
            "  3%|▎         | 86/3298 [01:00<32:34,  1.64it/s]\u001b[A\n",
            "  3%|▎         | 87/3298 [01:00<31:09,  1.72it/s]\u001b[A\n",
            "  3%|▎         | 88/3298 [01:01<30:17,  1.77it/s]\u001b[A\n",
            "  3%|▎         | 89/3298 [01:01<31:49,  1.68it/s]\u001b[A\n",
            "  3%|▎         | 90/3298 [01:02<32:49,  1.63it/s]\u001b[A\n",
            "  3%|▎         | 91/3298 [01:03<33:55,  1.58it/s]\u001b[A\n",
            "  3%|▎         | 92/3298 [01:03<34:17,  1.56it/s]\u001b[A\n",
            "  3%|▎         | 93/3298 [01:04<32:15,  1.66it/s]\u001b[A\n",
            "  3%|▎         | 94/3298 [01:04<33:11,  1.61it/s]\u001b[A\n",
            "  3%|▎         | 95/3298 [01:05<31:33,  1.69it/s]\u001b[A\n",
            "  3%|▎         | 96/3298 [01:06<32:38,  1.64it/s]\u001b[A\n",
            "  3%|▎         | 97/3298 [01:06<33:26,  1.59it/s]\u001b[A\n",
            "  3%|▎         | 98/3298 [01:07<31:55,  1.67it/s]\u001b[A\n",
            "  3%|▎         | 99/3298 [01:07<32:46,  1.63it/s]\u001b[A\n",
            "  3%|▎         | 100/3298 [01:08<33:20,  1.60it/s]\u001b[A\n",
            "  3%|▎         | 101/3298 [01:09<33:47,  1.58it/s]\u001b[A\n",
            "  3%|▎         | 102/3298 [01:10<36:28,  1.46it/s]\u001b[A\n",
            "  3%|▎         | 103/3298 [01:10<38:10,  1.39it/s]\u001b[A\n",
            "  3%|▎         | 104/3298 [01:11<39:23,  1.35it/s]\u001b[A\n",
            "  3%|▎         | 105/3298 [01:12<37:57,  1.40it/s]\u001b[A\n",
            "  3%|▎         | 106/3298 [01:12<37:04,  1.43it/s]\u001b[A\n",
            "  3%|▎         | 107/3298 [01:13<36:21,  1.46it/s]\u001b[A\n",
            "  3%|▎         | 108/3298 [01:14<33:49,  1.57it/s]\u001b[A\n",
            "  3%|▎         | 109/3298 [01:14<31:57,  1.66it/s]\u001b[A\n",
            "  3%|▎         | 110/3298 [01:15<30:33,  1.74it/s]\u001b[A\n",
            "  3%|▎         | 111/3298 [01:15<29:39,  1.79it/s]\u001b[A\n",
            "  3%|▎         | 112/3298 [01:16<31:04,  1.71it/s]\u001b[A\n",
            "  3%|▎         | 113/3298 [01:17<32:12,  1.65it/s]\u001b[A\n",
            "  3%|▎         | 114/3298 [01:17<30:54,  1.72it/s]\u001b[A\n",
            "  3%|▎         | 115/3298 [01:18<30:07,  1.76it/s]\u001b[A\n",
            "  4%|▎         | 116/3298 [01:18<31:18,  1.69it/s]\u001b[A\n",
            "  4%|▎         | 117/3298 [01:19<32:12,  1.65it/s]\u001b[A\n",
            "  4%|▎         | 118/3298 [01:20<33:05,  1.60it/s]\u001b[A\n",
            "  4%|▎         | 119/3298 [01:20<33:29,  1.58it/s]\u001b[A\n",
            "  4%|▎         | 120/3298 [01:21<34:00,  1.56it/s]\u001b[A\n",
            "  4%|▎         | 121/3298 [01:22<36:18,  1.46it/s]\u001b[A\n",
            "  4%|▎         | 122/3298 [01:22<36:08,  1.46it/s]\u001b[A\n",
            "  4%|▎         | 123/3298 [01:23<35:36,  1.49it/s]\u001b[A\n",
            "  4%|▍         | 124/3298 [01:24<35:43,  1.48it/s]\u001b[A\n",
            "  4%|▍         | 125/3298 [01:25<39:40,  1.33it/s]\u001b[A\n",
            "  4%|▍         | 126/3298 [01:25<40:17,  1.31it/s]\u001b[A\n",
            "  4%|▍         | 127/3298 [01:26<43:00,  1.23it/s]\u001b[A\n",
            "  4%|▍         | 128/3298 [01:27<46:48,  1.13it/s]\u001b[A\n",
            "  4%|▍         | 129/3298 [01:28<45:26,  1.16it/s]\u001b[A\n",
            "  4%|▍         | 130/3298 [01:29<39:57,  1.32it/s]\u001b[A\n",
            "  4%|▍         | 131/3298 [01:29<38:12,  1.38it/s]\u001b[A\n",
            "  4%|▍         | 132/3298 [01:30<35:01,  1.51it/s]\u001b[A\n",
            "  4%|▍         | 133/3298 [01:31<37:04,  1.42it/s]\u001b[A\n",
            "  4%|▍         | 134/3298 [01:31<38:23,  1.37it/s]\u001b[A\n",
            "  4%|▍         | 135/3298 [01:32<35:04,  1.50it/s]\u001b[A\n",
            "  4%|▍         | 136/3298 [01:32<32:33,  1.62it/s]\u001b[A\n",
            "  4%|▍         | 137/3298 [01:33<30:43,  1.71it/s]\u001b[A\n",
            "  4%|▍         | 138/3298 [01:34<31:54,  1.65it/s]\u001b[A\n",
            "  4%|▍         | 139/3298 [01:34<32:45,  1.61it/s]\u001b[A\n",
            "  4%|▍         | 140/3298 [01:35<33:16,  1.58it/s]\u001b[A\n",
            "  4%|▍         | 141/3298 [01:35<31:16,  1.68it/s]\u001b[A\n",
            "  4%|▍         | 142/3298 [01:36<31:59,  1.64it/s]\u001b[A\n",
            "  4%|▍         | 143/3298 [01:37<32:41,  1.61it/s]\u001b[A\n",
            "  4%|▍         | 144/3298 [01:37<33:18,  1.58it/s]\u001b[A\n",
            "  4%|▍         | 145/3298 [01:38<31:28,  1.67it/s]\u001b[A\n",
            "  4%|▍         | 146/3298 [01:38<30:16,  1.74it/s]\u001b[A\n",
            "  4%|▍         | 147/3298 [01:39<31:26,  1.67it/s]\u001b[A\n",
            "  4%|▍         | 148/3298 [01:40<32:40,  1.61it/s]\u001b[A\n",
            "  5%|▍         | 149/3298 [01:40<33:04,  1.59it/s]\u001b[A\n",
            "  5%|▍         | 150/3298 [01:41<33:12,  1.58it/s]\u001b[A\n",
            "  5%|▍         | 151/3298 [01:42<31:34,  1.66it/s]\u001b[A\n",
            "  5%|▍         | 152/3298 [01:42<30:19,  1.73it/s]\u001b[A\n",
            "  5%|▍         | 153/3298 [01:43<29:18,  1.79it/s]\u001b[A\n",
            "  5%|▍         | 154/3298 [01:43<28:46,  1.82it/s]\u001b[A\n",
            "  5%|▍         | 155/3298 [01:44<28:03,  1.87it/s]\u001b[A\n",
            "  5%|▍         | 156/3298 [01:44<27:41,  1.89it/s]\u001b[A\n",
            "  5%|▍         | 157/3298 [01:45<27:29,  1.90it/s]\u001b[A\n",
            "  5%|▍         | 158/3298 [01:45<27:19,  1.91it/s]\u001b[A\n",
            "  5%|▍         | 159/3298 [01:46<27:19,  1.91it/s]\u001b[A\n",
            "  5%|▍         | 160/3298 [01:46<29:19,  1.78it/s]\u001b[A\n",
            "  5%|▍         | 161/3298 [01:47<30:47,  1.70it/s]\u001b[A\n",
            "  5%|▍         | 162/3298 [01:48<31:36,  1.65it/s]\u001b[A\n",
            "  5%|▍         | 163/3298 [01:48<32:14,  1.62it/s]\u001b[A\n",
            "  5%|▍         | 164/3298 [01:49<32:47,  1.59it/s]\u001b[A\n",
            "  5%|▌         | 165/3298 [01:49<31:11,  1.67it/s]\u001b[A\n",
            "  5%|▌         | 166/3298 [01:50<34:22,  1.52it/s]\u001b[A\n",
            "  5%|▌         | 167/3298 [01:51<34:26,  1.52it/s]\u001b[A\n",
            "  5%|▌         | 168/3298 [01:51<32:20,  1.61it/s]\u001b[A\n",
            "  5%|▌         | 169/3298 [01:52<30:39,  1.70it/s]\u001b[A\n",
            "  5%|▌         | 170/3298 [01:53<31:32,  1.65it/s]\u001b[A\n",
            "  5%|▌         | 171/3298 [01:53<30:09,  1.73it/s]\u001b[A\n",
            "  5%|▌         | 172/3298 [01:54<29:28,  1.77it/s]\u001b[A\n",
            "  5%|▌         | 173/3298 [01:54<28:50,  1.81it/s]\u001b[A\n",
            "  5%|▌         | 174/3298 [01:55<30:10,  1.73it/s]\u001b[A\n",
            "  5%|▌         | 175/3298 [01:56<31:31,  1.65it/s]\u001b[A\n",
            "  5%|▌         | 176/3298 [01:56<30:09,  1.73it/s]\u001b[A\n",
            "  5%|▌         | 177/3298 [01:57<31:04,  1.67it/s]\u001b[A\n",
            "  5%|▌         | 178/3298 [01:57<29:50,  1.74it/s]\u001b[A\n",
            "  5%|▌         | 179/3298 [01:58<28:41,  1.81it/s]\u001b[A\n",
            "  5%|▌         | 180/3298 [01:58<28:17,  1.84it/s]\u001b[A\n",
            "  5%|▌         | 181/3298 [01:59<27:46,  1.87it/s]\u001b[A\n",
            "  6%|▌         | 182/3298 [01:59<29:34,  1.76it/s]\u001b[A\n",
            "  6%|▌         | 183/3298 [02:00<28:45,  1.81it/s]\u001b[A\n",
            "  6%|▌         | 184/3298 [02:00<28:11,  1.84it/s]\u001b[A\n",
            "  6%|▌         | 185/3298 [02:01<29:39,  1.75it/s]\u001b[A\n",
            "  6%|▌         | 186/3298 [02:02<29:00,  1.79it/s]\u001b[A\n",
            "  6%|▌         | 187/3298 [02:02<28:19,  1.83it/s]\u001b[A\n",
            "  6%|▌         | 188/3298 [02:03<30:09,  1.72it/s]\u001b[A\n",
            "  6%|▌         | 189/3298 [02:03<29:10,  1.78it/s]\u001b[A\n",
            "  6%|▌         | 190/3298 [02:04<30:37,  1.69it/s]\u001b[A\n",
            "  6%|▌         | 191/3298 [02:05<31:40,  1.63it/s]\u001b[A\n",
            "  6%|▌         | 192/3298 [02:05<30:07,  1.72it/s]\u001b[A\n",
            "  6%|▌         | 193/3298 [02:06<29:17,  1.77it/s]\u001b[A\n",
            "  6%|▌         | 194/3298 [02:06<30:46,  1.68it/s]\u001b[A\n",
            "  6%|▌         | 195/3298 [02:07<29:19,  1.76it/s]\u001b[A\n",
            "  6%|▌         | 196/3298 [02:07<30:43,  1.68it/s]\u001b[A\n",
            "  6%|▌         | 197/3298 [02:08<29:25,  1.76it/s]\u001b[A\n",
            "  6%|▌         | 198/3298 [02:09<30:39,  1.69it/s]\u001b[A\n",
            "  6%|▌         | 199/3298 [02:09<33:41,  1.53it/s]\u001b[A\n",
            "  6%|▌         | 200/3298 [02:10<35:45,  1.44it/s]\u001b[A\n",
            "  6%|▌         | 201/3298 [02:11<37:11,  1.39it/s]\u001b[A\n",
            "  6%|▌         | 202/3298 [02:11<33:49,  1.53it/s]\u001b[A\n",
            "  6%|▌         | 203/3298 [02:12<31:19,  1.65it/s]\u001b[A\n",
            "  6%|▌         | 204/3298 [02:13<31:55,  1.62it/s]\u001b[A\n",
            "  6%|▌         | 205/3298 [02:13<32:29,  1.59it/s]\u001b[A\n",
            "  6%|▌         | 206/3298 [02:14<30:40,  1.68it/s]\u001b[A\n",
            "  6%|▋         | 207/3298 [02:14<29:27,  1.75it/s]\u001b[A\n",
            "  6%|▋         | 208/3298 [02:15<28:27,  1.81it/s]\u001b[A\n",
            "  6%|▋         | 209/3298 [02:15<29:47,  1.73it/s]\u001b[A\n",
            "  6%|▋         | 210/3298 [02:16<30:41,  1.68it/s]\u001b[A\n",
            "  6%|▋         | 211/3298 [02:17<31:41,  1.62it/s]\u001b[A\n",
            "  6%|▋         | 212/3298 [02:17<32:35,  1.58it/s]\u001b[A\n",
            "  6%|▋         | 213/3298 [02:18<32:54,  1.56it/s]\u001b[A\n",
            "  6%|▋         | 214/3298 [02:19<31:04,  1.65it/s]\u001b[A\n",
            "  7%|▋         | 215/3298 [02:19<31:50,  1.61it/s]\u001b[A\n",
            "  7%|▋         | 216/3298 [02:20<32:25,  1.58it/s]\u001b[A\n",
            "  7%|▋         | 217/3298 [02:20<30:33,  1.68it/s]\u001b[A\n",
            "  7%|▋         | 218/3298 [02:21<29:16,  1.75it/s]\u001b[A\n",
            "  7%|▋         | 219/3298 [02:21<28:28,  1.80it/s]\u001b[A\n",
            "  7%|▋         | 220/3298 [02:22<27:45,  1.85it/s]\u001b[A\n",
            "  7%|▋         | 221/3298 [02:23<27:30,  1.86it/s]\u001b[A\n",
            "  7%|▋         | 222/3298 [02:23<29:26,  1.74it/s]\u001b[A\n",
            "  7%|▋         | 223/3298 [02:24<30:25,  1.68it/s]\u001b[A\n",
            "  7%|▋         | 224/3298 [02:25<33:12,  1.54it/s]\u001b[A\n",
            "  7%|▋         | 225/3298 [02:25<33:19,  1.54it/s]\u001b[A\n",
            "  7%|▋         | 226/3298 [02:26<35:22,  1.45it/s]\u001b[A\n",
            "  7%|▋         | 227/3298 [02:27<32:36,  1.57it/s]\u001b[A\n",
            "  7%|▋         | 228/3298 [02:27<32:46,  1.56it/s]\u001b[A\n",
            "  7%|▋         | 229/3298 [02:28<30:49,  1.66it/s]\u001b[A\n",
            "  7%|▋         | 230/3298 [02:28<31:31,  1.62it/s]\u001b[A\n",
            "  7%|▋         | 231/3298 [02:29<29:57,  1.71it/s]\u001b[A\n",
            "  7%|▋         | 232/3298 [02:29<30:42,  1.66it/s]\u001b[A\n",
            "  7%|▋         | 233/3298 [02:30<31:21,  1.63it/s]\u001b[A\n",
            "  7%|▋         | 234/3298 [02:31<31:52,  1.60it/s]\u001b[A\n",
            "  7%|▋         | 235/3298 [02:31<32:05,  1.59it/s]\u001b[A\n",
            "  7%|▋         | 236/3298 [02:32<32:32,  1.57it/s]\u001b[A\n",
            "  7%|▋         | 237/3298 [02:33<30:44,  1.66it/s]\u001b[A\n",
            "  7%|▋         | 238/3298 [02:33<29:23,  1.74it/s]\u001b[A\n",
            "  7%|▋         | 239/3298 [02:34<30:43,  1.66it/s]\u001b[A\n",
            "  7%|▋         | 240/3298 [02:35<33:49,  1.51it/s]\u001b[A\n",
            "  7%|▋         | 241/3298 [02:36<38:15,  1.33it/s]\u001b[A\n",
            "  7%|▋         | 242/3298 [02:36<34:47,  1.46it/s]\u001b[A\n",
            "  7%|▋         | 243/3298 [02:37<32:17,  1.58it/s]\u001b[A\n",
            "  7%|▋         | 244/3298 [02:37<32:42,  1.56it/s]\u001b[A\n",
            "  7%|▋         | 245/3298 [02:38<32:40,  1.56it/s]\u001b[A\n",
            "  7%|▋         | 246/3298 [02:39<32:58,  1.54it/s]\u001b[A\n",
            "  7%|▋         | 247/3298 [02:39<30:55,  1.64it/s]\u001b[A\n",
            "  8%|▊         | 248/3298 [02:40<31:39,  1.61it/s]\u001b[A\n",
            "  8%|▊         | 249/3298 [02:40<31:54,  1.59it/s]\u001b[A\n",
            "  8%|▊         | 250/3298 [02:41<32:04,  1.58it/s]\u001b[A\n",
            "  8%|▊         | 251/3298 [02:42<34:18,  1.48it/s]\u001b[A\n",
            "  8%|▊         | 252/3298 [02:42<33:49,  1.50it/s]\u001b[A\n",
            "  8%|▊         | 253/3298 [02:43<33:35,  1.51it/s]\u001b[A\n",
            "  8%|▊         | 254/3298 [02:44<33:31,  1.51it/s]\u001b[A\n",
            "  8%|▊         | 255/3298 [02:44<33:20,  1.52it/s]\u001b[A\n",
            "  8%|▊         | 256/3298 [02:45<33:03,  1.53it/s]\u001b[A\n",
            "  8%|▊         | 257/3298 [02:46<30:56,  1.64it/s]\u001b[A\n",
            "  8%|▊         | 258/3298 [02:46<31:53,  1.59it/s]\u001b[A\n",
            "  8%|▊         | 259/3298 [02:47<30:08,  1.68it/s]\u001b[A\n",
            "  8%|▊         | 260/3298 [02:47<30:59,  1.63it/s]\u001b[A\n",
            "  8%|▊         | 261/3298 [02:48<29:20,  1.72it/s]\u001b[A\n",
            "  8%|▊         | 262/3298 [02:49<30:30,  1.66it/s]\u001b[A\n",
            "  8%|▊         | 263/3298 [02:49<31:28,  1.61it/s]\u001b[A\n",
            "  8%|▊         | 264/3298 [02:50<31:48,  1.59it/s]\u001b[A\n",
            "  8%|▊         | 265/3298 [02:51<34:03,  1.48it/s]\u001b[A\n",
            "  8%|▊         | 266/3298 [02:51<35:47,  1.41it/s]\u001b[A\n",
            "  8%|▊         | 267/3298 [02:52<37:00,  1.36it/s]\u001b[A\n",
            "  8%|▊         | 268/3298 [02:53<33:39,  1.50it/s]\u001b[A\n",
            "  8%|▊         | 269/3298 [02:53<31:33,  1.60it/s]\u001b[A\n",
            "  8%|▊         | 270/3298 [02:54<33:56,  1.49it/s]\u001b[A\n",
            "  8%|▊         | 271/3298 [02:55<31:40,  1.59it/s]\u001b[A\n",
            "  8%|▊         | 272/3298 [02:55<31:59,  1.58it/s]\u001b[A\n",
            "  8%|▊         | 273/3298 [02:56<30:21,  1.66it/s]\u001b[A\n",
            "  8%|▊         | 274/3298 [02:56<29:30,  1.71it/s]\u001b[A\n",
            "  8%|▊         | 275/3298 [02:57<28:33,  1.76it/s]\u001b[A\n",
            "  8%|▊         | 276/3298 [02:57<27:47,  1.81it/s]\u001b[A\n",
            "  8%|▊         | 277/3298 [02:58<26:55,  1.87it/s]\u001b[A\n",
            "  8%|▊         | 278/3298 [02:59<30:55,  1.63it/s]\u001b[A\n",
            "  8%|▊         | 279/3298 [02:59<29:27,  1.71it/s]\u001b[A\n",
            "  8%|▊         | 280/3298 [03:00<32:24,  1.55it/s]\u001b[A\n",
            "  9%|▊         | 281/3298 [03:01<34:56,  1.44it/s]\u001b[A\n",
            "  9%|▊         | 282/3298 [03:02<36:27,  1.38it/s]\u001b[A\n",
            "  9%|▊         | 283/3298 [03:02<39:21,  1.28it/s]\u001b[A\n",
            "  9%|▊         | 284/3298 [03:03<41:37,  1.21it/s]\u001b[A\n",
            "  9%|▊         | 285/3298 [03:04<40:55,  1.23it/s]\u001b[A\n",
            "  9%|▊         | 286/3298 [03:05<40:22,  1.24it/s]\u001b[A\n",
            "  9%|▊         | 287/3298 [03:06<37:56,  1.32it/s]\u001b[A\n",
            "  9%|▊         | 288/3298 [03:06<38:23,  1.31it/s]\u001b[A\n",
            "  9%|▉         | 289/3298 [03:07<38:34,  1.30it/s]\u001b[A\n",
            "  9%|▉         | 290/3298 [03:08<34:41,  1.45it/s]\u001b[A\n",
            "  9%|▉         | 291/3298 [03:08<36:00,  1.39it/s]\u001b[A\n",
            "  9%|▉         | 292/3298 [03:09<34:56,  1.43it/s]\u001b[A\n",
            "  9%|▉         | 293/3298 [03:10<40:14,  1.24it/s]\u001b[A\n",
            "  9%|▉         | 294/3298 [03:11<39:41,  1.26it/s]\u001b[A\n",
            "  9%|▉         | 295/3298 [03:12<39:31,  1.27it/s]\u001b[A\n",
            "  9%|▉         | 296/3298 [03:12<35:13,  1.42it/s]\u001b[A\n",
            "  9%|▉         | 297/3298 [03:13<38:23,  1.30it/s]\u001b[A\n",
            "  9%|▉         | 298/3298 [03:14<34:41,  1.44it/s]\u001b[A\n",
            "  9%|▉         | 299/3298 [03:14<31:45,  1.57it/s]\u001b[A\n",
            "  9%|▉         | 300/3298 [03:15<29:49,  1.68it/s]\u001b[A\n",
            "  9%|▉         | 301/3298 [03:15<30:19,  1.65it/s]\u001b[A\n",
            "  9%|▉         | 302/3298 [03:16<28:52,  1.73it/s]\u001b[A\n",
            "  9%|▉         | 303/3298 [03:16<29:54,  1.67it/s]\u001b[A\n",
            "  9%|▉         | 304/3298 [03:17<30:28,  1.64it/s]\u001b[A\n",
            "  9%|▉         | 305/3298 [03:18<30:46,  1.62it/s]\u001b[A\n",
            "  9%|▉         | 306/3298 [03:18<29:16,  1.70it/s]\u001b[A\n",
            "  9%|▉         | 307/3298 [03:19<27:58,  1.78it/s]\u001b[A\n",
            "  9%|▉         | 308/3298 [03:19<27:10,  1.83it/s]\u001b[A\n",
            "  9%|▉         | 309/3298 [03:20<26:31,  1.88it/s]\u001b[A\n",
            "  9%|▉         | 310/3298 [03:20<27:59,  1.78it/s]\u001b[A\n",
            "  9%|▉         | 311/3298 [03:21<29:13,  1.70it/s]\u001b[A\n",
            "  9%|▉         | 312/3298 [03:22<34:00,  1.46it/s]\u001b[A\n",
            "  9%|▉         | 313/3298 [03:23<33:32,  1.48it/s]\u001b[A\n",
            " 10%|▉         | 314/3298 [03:23<33:11,  1.50it/s]\u001b[A\n",
            " 10%|▉         | 315/3298 [03:24<34:54,  1.42it/s]\u001b[A\n",
            " 10%|▉         | 316/3298 [03:25<33:53,  1.47it/s]\u001b[A\n",
            " 10%|▉         | 317/3298 [03:25<33:23,  1.49it/s]\u001b[A\n",
            " 10%|▉         | 318/3298 [03:26<30:56,  1.60it/s]\u001b[A\n",
            " 10%|▉         | 319/3298 [03:26<31:23,  1.58it/s]\u001b[A\n",
            " 10%|▉         | 320/3298 [03:27<31:34,  1.57it/s]\u001b[A\n",
            " 10%|▉         | 321/3298 [03:28<31:43,  1.56it/s]\u001b[A\n",
            " 10%|▉         | 322/3298 [03:28<29:41,  1.67it/s]\u001b[A\n",
            " 10%|▉         | 323/3298 [03:29<30:28,  1.63it/s]\u001b[A\n",
            " 10%|▉         | 324/3298 [03:30<30:48,  1.61it/s]\u001b[A\n",
            " 10%|▉         | 325/3298 [03:30<29:03,  1.71it/s]\u001b[A\n",
            " 10%|▉         | 326/3298 [03:31<27:49,  1.78it/s]\u001b[A\n",
            " 10%|▉         | 327/3298 [03:31<32:44,  1.51it/s]\u001b[A\n",
            " 10%|▉         | 328/3298 [03:32<30:11,  1.64it/s]\u001b[A\n",
            " 10%|▉         | 329/3298 [03:33<30:25,  1.63it/s]\u001b[A\n",
            " 10%|█         | 330/3298 [03:33<30:40,  1.61it/s]\u001b[A\n",
            " 10%|█         | 331/3298 [03:34<30:36,  1.62it/s]\u001b[A\n",
            " 10%|█         | 332/3298 [03:34<30:46,  1.61it/s]\u001b[A\n",
            " 10%|█         | 333/3298 [03:35<30:52,  1.60it/s]\u001b[A\n",
            " 10%|█         | 334/3298 [03:36<31:13,  1.58it/s]\u001b[A\n",
            " 10%|█         | 335/3298 [03:36<29:15,  1.69it/s]\u001b[A\n",
            " 10%|█         | 336/3298 [03:37<29:56,  1.65it/s]\u001b[A\n",
            " 10%|█         | 337/3298 [03:37<28:28,  1.73it/s]\u001b[A\n",
            " 10%|█         | 338/3298 [03:38<29:23,  1.68it/s]\u001b[A\n",
            " 10%|█         | 339/3298 [03:39<28:32,  1.73it/s]\u001b[A\n",
            " 10%|█         | 340/3298 [03:39<27:28,  1.79it/s]\u001b[A\n",
            " 10%|█         | 341/3298 [03:40<26:54,  1.83it/s]\u001b[A\n",
            " 10%|█         | 342/3298 [03:40<28:19,  1.74it/s]\u001b[A\n",
            " 10%|█         | 343/3298 [03:41<29:21,  1.68it/s]\u001b[A\n",
            " 10%|█         | 344/3298 [03:42<30:17,  1.62it/s]\u001b[A\n",
            " 10%|█         | 345/3298 [03:42<32:51,  1.50it/s]\u001b[A\n",
            " 10%|█         | 346/3298 [03:43<32:30,  1.51it/s]\u001b[A\n",
            " 11%|█         | 347/3298 [03:44<36:14,  1.36it/s]\u001b[A\n",
            " 11%|█         | 348/3298 [03:45<38:35,  1.27it/s]\u001b[A\n",
            " 11%|█         | 349/3298 [03:45<36:21,  1.35it/s]\u001b[A\n",
            " 11%|█         | 350/3298 [03:46<32:53,  1.49it/s]\u001b[A\n",
            " 11%|█         | 351/3298 [03:46<30:28,  1.61it/s]\u001b[A\n",
            " 11%|█         | 352/3298 [03:47<30:57,  1.59it/s]\u001b[A\n",
            " 11%|█         | 353/3298 [03:48<33:04,  1.48it/s]\u001b[A\n",
            " 11%|█         | 354/3298 [03:48<32:29,  1.51it/s]\u001b[A\n",
            " 11%|█         | 355/3298 [03:49<34:21,  1.43it/s]\u001b[A\n",
            " 11%|█         | 356/3298 [03:50<35:19,  1.39it/s]\u001b[A\n",
            " 11%|█         | 357/3298 [03:51<32:17,  1.52it/s]\u001b[A\n",
            " 11%|█         | 358/3298 [03:51<34:25,  1.42it/s]\u001b[A\n",
            " 11%|█         | 359/3298 [03:52<31:19,  1.56it/s]\u001b[A\n",
            " 11%|█         | 360/3298 [03:52<31:20,  1.56it/s]\u001b[A\n",
            " 11%|█         | 361/3298 [03:53<33:09,  1.48it/s]\u001b[A\n",
            " 11%|█         | 362/3298 [03:54<32:35,  1.50it/s]\u001b[A\n",
            " 11%|█         | 363/3298 [03:55<32:18,  1.51it/s]\u001b[A\n",
            " 11%|█         | 364/3298 [03:55<33:50,  1.44it/s]\u001b[A\n",
            " 11%|█         | 365/3298 [03:56<36:34,  1.34it/s]\u001b[A\n",
            " 11%|█         | 366/3298 [03:57<36:43,  1.33it/s]\u001b[A\n",
            " 11%|█         | 367/3298 [03:58<36:59,  1.32it/s]\u001b[A\n",
            " 11%|█         | 368/3298 [03:58<35:10,  1.39it/s]\u001b[A\n",
            " 11%|█         | 369/3298 [03:59<34:09,  1.43it/s]\u001b[A\n",
            " 11%|█         | 370/3298 [04:00<33:25,  1.46it/s]\u001b[A\n",
            " 11%|█         | 371/3298 [04:00<30:55,  1.58it/s]\u001b[A\n",
            " 11%|█▏        | 372/3298 [04:01<29:14,  1.67it/s]\u001b[A\n",
            " 11%|█▏        | 373/3298 [04:01<32:06,  1.52it/s]\u001b[A\n",
            " 11%|█▏        | 374/3298 [04:02<34:03,  1.43it/s]\u001b[A\n",
            " 11%|█▏        | 375/3298 [04:03<33:12,  1.47it/s]\u001b[A\n",
            " 11%|█▏        | 376/3298 [04:04<34:54,  1.40it/s]\u001b[A\n",
            " 11%|█▏        | 377/3298 [04:04<34:02,  1.43it/s]\u001b[A\n",
            " 11%|█▏        | 378/3298 [04:05<33:10,  1.47it/s]\u001b[A\n",
            " 11%|█▏        | 379/3298 [04:06<34:31,  1.41it/s]\u001b[A\n",
            " 12%|█▏        | 380/3298 [04:07<35:17,  1.38it/s]\u001b[A\n",
            " 12%|█▏        | 381/3298 [04:07<34:04,  1.43it/s]\u001b[A\n",
            " 12%|█▏        | 382/3298 [04:08<35:21,  1.37it/s]\u001b[A\n",
            " 12%|█▏        | 383/3298 [04:09<35:58,  1.35it/s]\u001b[A\n",
            " 12%|█▏        | 384/3298 [04:10<36:26,  1.33it/s]\u001b[A\n",
            " 12%|█▏        | 385/3298 [04:10<34:52,  1.39it/s]\u001b[A\n",
            " 12%|█▏        | 386/3298 [04:11<33:56,  1.43it/s]\u001b[A\n",
            " 12%|█▏        | 387/3298 [04:11<33:29,  1.45it/s]\u001b[A\n",
            " 12%|█▏        | 388/3298 [04:12<30:55,  1.57it/s]\u001b[A\n",
            " 12%|█▏        | 389/3298 [04:13<30:51,  1.57it/s]\u001b[A\n",
            " 12%|█▏        | 390/3298 [04:13<30:53,  1.57it/s]\u001b[A\n",
            " 12%|█▏        | 391/3298 [04:14<31:01,  1.56it/s]\u001b[A\n",
            " 12%|█▏        | 392/3298 [04:15<30:50,  1.57it/s]\u001b[A\n",
            " 12%|█▏        | 393/3298 [04:15<31:07,  1.56it/s]\u001b[A\n",
            " 12%|█▏        | 394/3298 [04:16<32:51,  1.47it/s]\u001b[A\n",
            " 12%|█▏        | 395/3298 [04:17<34:10,  1.42it/s]\u001b[A\n",
            " 12%|█▏        | 396/3298 [04:17<31:31,  1.53it/s]\u001b[A\n",
            " 12%|█▏        | 397/3298 [04:18<31:29,  1.53it/s]\u001b[A\n",
            " 12%|█▏        | 398/3298 [04:19<31:28,  1.54it/s]\u001b[A\n",
            " 12%|█▏        | 399/3298 [04:19<29:14,  1.65it/s]\u001b[A\n",
            " 12%|█▏        | 400/3298 [04:20<31:57,  1.51it/s]\u001b[A\n",
            " 12%|█▏        | 401/3298 [04:20<29:40,  1.63it/s]\u001b[A\n",
            " 12%|█▏        | 402/3298 [04:21<29:54,  1.61it/s]\u001b[A\n",
            " 12%|█▏        | 403/3298 [04:22<30:28,  1.58it/s]\u001b[A\n",
            " 12%|█▏        | 404/3298 [04:22<32:53,  1.47it/s]\u001b[A\n",
            " 12%|█▏        | 405/3298 [04:23<32:25,  1.49it/s]\u001b[A\n",
            " 12%|█▏        | 406/3298 [04:24<31:59,  1.51it/s]\u001b[A\n",
            " 12%|█▏        | 407/3298 [04:24<31:57,  1.51it/s]\u001b[A\n",
            " 12%|█▏        | 408/3298 [04:25<31:39,  1.52it/s]\u001b[A\n",
            " 12%|█▏        | 409/3298 [04:26<31:49,  1.51it/s]\u001b[A\n",
            " 12%|█▏        | 410/3298 [04:26<29:37,  1.62it/s]\u001b[A\n",
            " 12%|█▏        | 411/3298 [04:27<28:03,  1.71it/s]\u001b[A\n",
            " 12%|█▏        | 412/3298 [04:27<27:06,  1.77it/s]\u001b[A\n",
            " 13%|█▎        | 413/3298 [04:28<28:16,  1.70it/s]\u001b[A\n",
            " 13%|█▎        | 414/3298 [04:29<29:15,  1.64it/s]\u001b[A\n",
            " 13%|█▎        | 415/3298 [04:29<29:39,  1.62it/s]\u001b[A\n",
            " 13%|█▎        | 416/3298 [04:30<29:46,  1.61it/s]\u001b[A\n",
            " 13%|█▎        | 417/3298 [04:30<30:01,  1.60it/s]\u001b[A\n",
            " 13%|█▎        | 418/3298 [04:31<30:24,  1.58it/s]\u001b[A\n",
            " 13%|█▎        | 419/3298 [04:32<30:43,  1.56it/s]\u001b[A\n",
            " 13%|█▎        | 420/3298 [04:32<31:06,  1.54it/s]\u001b[A\n",
            " 13%|█▎        | 421/3298 [04:33<31:01,  1.55it/s]\u001b[A\n",
            " 13%|█▎        | 422/3298 [04:34<29:06,  1.65it/s]\u001b[A\n",
            " 13%|█▎        | 423/3298 [04:34<27:41,  1.73it/s]\u001b[A\n",
            " 13%|█▎        | 424/3298 [04:35<28:30,  1.68it/s]\u001b[A\n",
            " 13%|█▎        | 425/3298 [04:36<31:20,  1.53it/s]\u001b[A\n",
            " 13%|█▎        | 426/3298 [04:36<31:13,  1.53it/s]\u001b[A\n",
            " 13%|█▎        | 427/3298 [04:37<30:52,  1.55it/s]\u001b[A\n",
            " 13%|█▎        | 428/3298 [04:37<28:50,  1.66it/s]\u001b[A\n",
            " 13%|█▎        | 429/3298 [04:38<27:25,  1.74it/s]\u001b[A\n",
            " 13%|█▎        | 430/3298 [04:38<28:17,  1.69it/s]\u001b[A\n",
            " 13%|█▎        | 431/3298 [04:39<28:49,  1.66it/s]\u001b[A\n",
            " 13%|█▎        | 432/3298 [04:40<29:36,  1.61it/s]\u001b[A\n",
            " 13%|█▎        | 433/3298 [04:40<27:58,  1.71it/s]\u001b[A\n",
            " 13%|█▎        | 434/3298 [04:41<26:41,  1.79it/s]\u001b[A\n",
            " 13%|█▎        | 435/3298 [04:41<25:48,  1.85it/s]\u001b[A\n",
            " 13%|█▎        | 436/3298 [04:42<27:11,  1.75it/s]\u001b[A\n",
            " 13%|█▎        | 437/3298 [04:43<28:18,  1.68it/s]\u001b[A\n",
            " 13%|█▎        | 438/3298 [04:43<26:55,  1.77it/s]\u001b[A\n",
            " 13%|█▎        | 439/3298 [04:44<28:27,  1.67it/s]\u001b[A\n",
            " 13%|█▎        | 440/3298 [04:44<29:08,  1.63it/s]\u001b[A\n",
            " 13%|█▎        | 441/3298 [04:45<29:29,  1.61it/s]\u001b[A\n",
            " 13%|█▎        | 442/3298 [04:46<28:06,  1.69it/s]\u001b[A\n",
            " 13%|█▎        | 443/3298 [04:46<26:55,  1.77it/s]\u001b[A\n",
            " 13%|█▎        | 444/3298 [04:47<26:09,  1.82it/s]\u001b[A\n",
            " 13%|█▎        | 445/3298 [04:47<27:19,  1.74it/s]\u001b[A\n",
            " 14%|█▎        | 446/3298 [04:48<28:15,  1.68it/s]\u001b[A\n",
            " 14%|█▎        | 447/3298 [04:49<30:53,  1.54it/s]\u001b[A\n",
            " 14%|█▎        | 448/3298 [04:49<30:59,  1.53it/s]\u001b[A\n",
            " 14%|█▎        | 449/3298 [04:50<28:58,  1.64it/s]\u001b[A\n",
            " 14%|█▎        | 450/3298 [04:50<27:48,  1.71it/s]\u001b[A\n",
            " 14%|█▎        | 451/3298 [04:51<28:39,  1.66it/s]\u001b[A\n",
            " 14%|█▎        | 452/3298 [04:51<27:21,  1.73it/s]\u001b[A\n",
            " 14%|█▎        | 453/3298 [04:52<28:13,  1.68it/s]\u001b[A\n",
            " 14%|█▍        | 454/3298 [04:53<28:53,  1.64it/s]\u001b[A\n",
            " 14%|█▍        | 455/3298 [04:53<29:40,  1.60it/s]\u001b[A\n",
            " 14%|█▍        | 456/3298 [04:54<28:06,  1.69it/s]\u001b[A\n",
            " 14%|█▍        | 457/3298 [04:55<28:58,  1.63it/s]\u001b[A\n",
            " 14%|█▍        | 458/3298 [04:55<29:28,  1.61it/s]\u001b[A\n",
            " 14%|█▍        | 459/3298 [04:56<30:01,  1.58it/s]\u001b[A\n",
            " 14%|█▍        | 460/3298 [04:57<30:22,  1.56it/s]\u001b[A\n",
            " 14%|█▍        | 461/3298 [04:57<28:41,  1.65it/s]\u001b[A\n",
            " 14%|█▍        | 462/3298 [04:58<27:26,  1.72it/s]\u001b[A\n",
            " 14%|█▍        | 463/3298 [04:58<28:32,  1.66it/s]\u001b[A\n",
            " 14%|█▍        | 464/3298 [04:59<29:11,  1.62it/s]\u001b[A\n",
            " 14%|█▍        | 465/3298 [05:00<29:42,  1.59it/s]\u001b[A\n",
            " 14%|█▍        | 466/3298 [05:00<29:57,  1.58it/s]\u001b[A\n",
            " 14%|█▍        | 467/3298 [05:01<30:25,  1.55it/s]\u001b[A\n",
            " 14%|█▍        | 468/3298 [05:02<30:50,  1.53it/s]\u001b[A\n",
            " 14%|█▍        | 469/3298 [05:02<31:01,  1.52it/s]\u001b[A\n",
            " 14%|█▍        | 470/3298 [05:03<31:07,  1.51it/s]\u001b[A\n",
            " 14%|█▍        | 471/3298 [05:04<31:08,  1.51it/s]\u001b[A\n",
            " 14%|█▍        | 472/3298 [05:04<29:10,  1.61it/s]\u001b[A\n",
            " 14%|█▍        | 473/3298 [05:05<27:36,  1.71it/s]\u001b[A\n",
            " 14%|█▍        | 474/3298 [05:05<28:22,  1.66it/s]\u001b[A\n",
            " 14%|█▍        | 475/3298 [05:06<28:52,  1.63it/s]\u001b[A\n",
            " 14%|█▍        | 476/3298 [05:06<29:09,  1.61it/s]\u001b[A\n",
            " 14%|█▍        | 477/3298 [05:07<29:18,  1.60it/s]\u001b[A\n",
            " 14%|█▍        | 478/3298 [05:08<29:44,  1.58it/s]\u001b[A\n",
            " 15%|█▍        | 479/3298 [05:08<28:06,  1.67it/s]\u001b[A\n",
            " 15%|█▍        | 480/3298 [05:09<28:45,  1.63it/s]\u001b[A\n",
            " 15%|█▍        | 481/3298 [05:10<29:25,  1.60it/s]\u001b[A\n",
            " 15%|█▍        | 482/3298 [05:10<29:32,  1.59it/s]\u001b[A\n",
            " 15%|█▍        | 483/3298 [05:11<29:48,  1.57it/s]\u001b[A\n",
            " 15%|█▍        | 484/3298 [05:12<30:02,  1.56it/s]\u001b[A\n",
            " 15%|█▍        | 485/3298 [05:12<28:15,  1.66it/s]\u001b[A\n",
            " 15%|█▍        | 486/3298 [05:13<28:58,  1.62it/s]\u001b[A\n",
            " 15%|█▍        | 487/3298 [05:13<31:16,  1.50it/s]\u001b[A\n",
            " 15%|█▍        | 488/3298 [05:14<30:47,  1.52it/s]\u001b[A\n",
            " 15%|█▍        | 489/3298 [05:15<30:20,  1.54it/s]\u001b[A\n",
            " 15%|█▍        | 490/3298 [05:15<28:32,  1.64it/s]\u001b[A\n",
            " 15%|█▍        | 491/3298 [05:16<28:58,  1.61it/s]\u001b[A\n",
            " 15%|█▍        | 492/3298 [05:17<29:19,  1.59it/s]\u001b[A\n",
            " 15%|█▍        | 493/3298 [05:17<27:35,  1.69it/s]\u001b[A\n",
            " 15%|█▍        | 494/3298 [05:18<28:24,  1.65it/s]\u001b[A\n",
            " 15%|█▌        | 495/3298 [05:19<32:45,  1.43it/s]\u001b[A\n",
            " 15%|█▌        | 496/3298 [05:20<35:41,  1.31it/s]\u001b[A\n",
            " 15%|█▌        | 497/3298 [05:20<33:56,  1.38it/s]\u001b[A\n",
            " 15%|█▌        | 498/3298 [05:21<32:44,  1.43it/s]\u001b[A\n",
            " 15%|█▌        | 499/3298 [05:21<32:13,  1.45it/s]\u001b[A\n",
            " 15%|█▌        | 500/3298 [05:22<31:35,  1.48it/s]\u001b[A\n",
            " 15%|█▌        | 501/3298 [05:23<31:05,  1.50it/s]\u001b[A\n",
            " 15%|█▌        | 502/3298 [05:23<31:07,  1.50it/s]\u001b[A\n",
            " 15%|█▌        | 503/3298 [05:24<30:47,  1.51it/s]\u001b[A\n",
            " 15%|█▌        | 504/3298 [05:25<28:40,  1.62it/s]\u001b[A\n",
            " 15%|█▌        | 505/3298 [05:25<27:11,  1.71it/s]\u001b[A\n",
            " 15%|█▌        | 506/3298 [05:26<26:43,  1.74it/s]\u001b[A\n",
            " 15%|█▌        | 507/3298 [05:26<25:50,  1.80it/s]\u001b[A\n",
            " 15%|█▌        | 508/3298 [05:27<26:38,  1.75it/s]\u001b[A\n",
            " 15%|█▌        | 509/3298 [05:27<27:41,  1.68it/s]\u001b[A\n",
            " 15%|█▌        | 510/3298 [05:28<28:21,  1.64it/s]\u001b[A\n",
            " 15%|█▌        | 511/3298 [05:29<26:59,  1.72it/s]\u001b[A\n",
            " 16%|█▌        | 512/3298 [05:29<27:36,  1.68it/s]\u001b[A\n",
            " 16%|█▌        | 513/3298 [05:30<29:54,  1.55it/s]\u001b[A\n",
            " 16%|█▌        | 514/3298 [05:31<29:47,  1.56it/s]\u001b[A\n",
            " 16%|█▌        | 515/3298 [05:31<27:54,  1.66it/s]\u001b[A\n",
            " 16%|█▌        | 516/3298 [05:32<28:36,  1.62it/s]\u001b[A\n",
            " 16%|█▌        | 517/3298 [05:33<30:49,  1.50it/s]\u001b[A\n",
            " 16%|█▌        | 518/3298 [05:33<30:28,  1.52it/s]\u001b[A\n",
            " 16%|█▌        | 519/3298 [05:34<30:08,  1.54it/s]\u001b[A\n",
            " 16%|█▌        | 520/3298 [05:34<30:09,  1.54it/s]\u001b[A\n",
            " 16%|█▌        | 521/3298 [05:35<28:07,  1.65it/s]\u001b[A\n",
            " 16%|█▌        | 522/3298 [05:35<27:04,  1.71it/s]\u001b[A\n",
            " 16%|█▌        | 523/3298 [05:36<25:59,  1.78it/s]\u001b[A\n",
            " 16%|█▌        | 524/3298 [05:37<25:33,  1.81it/s]\u001b[A\n",
            " 16%|█▌        | 525/3298 [05:37<26:42,  1.73it/s]\u001b[A\n",
            " 16%|█▌        | 526/3298 [05:38<27:37,  1.67it/s]\u001b[A\n",
            " 16%|█▌        | 527/3298 [05:38<28:19,  1.63it/s]\u001b[A\n",
            " 16%|█▌        | 528/3298 [05:39<28:35,  1.62it/s]\u001b[A\n",
            " 16%|█▌        | 529/3298 [05:40<28:40,  1.61it/s]\u001b[A\n",
            " 16%|█▌        | 530/3298 [05:40<26:52,  1.72it/s]\u001b[A\n",
            " 16%|█▌        | 531/3298 [05:41<27:46,  1.66it/s]\u001b[A\n",
            " 16%|█▌        | 532/3298 [05:41<26:34,  1.73it/s]\u001b[A\n",
            " 16%|█▌        | 533/3298 [05:42<27:30,  1.68it/s]\u001b[A\n",
            " 16%|█▌        | 534/3298 [05:43<28:04,  1.64it/s]\u001b[A\n",
            " 16%|█▌        | 535/3298 [05:43<26:49,  1.72it/s]\u001b[A\n",
            " 16%|█▋        | 536/3298 [05:44<29:28,  1.56it/s]\u001b[A\n",
            " 16%|█▋        | 537/3298 [05:45<31:23,  1.47it/s]\u001b[A\n",
            " 16%|█▋        | 538/3298 [05:45<30:55,  1.49it/s]\u001b[A\n",
            " 16%|█▋        | 539/3298 [05:46<28:44,  1.60it/s]\u001b[A\n",
            " 16%|█▋        | 540/3298 [05:47<29:09,  1.58it/s]\u001b[A\n",
            " 16%|█▋        | 541/3298 [05:47<29:20,  1.57it/s]\u001b[A\n",
            " 16%|█▋        | 542/3298 [05:48<29:16,  1.57it/s]\u001b[A\n",
            " 16%|█▋        | 543/3298 [05:48<29:22,  1.56it/s]\u001b[A\n",
            " 16%|█▋        | 544/3298 [05:49<29:37,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 545/3298 [05:50<29:28,  1.56it/s]\u001b[A\n",
            " 17%|█▋        | 546/3298 [05:51<31:15,  1.47it/s]\u001b[A\n",
            " 17%|█▋        | 547/3298 [05:51<32:21,  1.42it/s]\u001b[A\n",
            " 17%|█▋        | 548/3298 [05:52<33:16,  1.38it/s]\u001b[A\n",
            " 17%|█▋        | 549/3298 [05:53<33:50,  1.35it/s]\u001b[A\n",
            " 17%|█▋        | 550/3298 [05:54<34:11,  1.34it/s]\u001b[A\n",
            " 17%|█▋        | 551/3298 [05:54<34:39,  1.32it/s]\u001b[A\n",
            " 17%|█▋        | 552/3298 [05:55<34:58,  1.31it/s]\u001b[A\n",
            " 17%|█▋        | 553/3298 [05:56<33:09,  1.38it/s]\u001b[A\n",
            " 17%|█▋        | 554/3298 [05:57<33:53,  1.35it/s]\u001b[A\n",
            " 17%|█▋        | 555/3298 [05:57<32:30,  1.41it/s]\u001b[A\n",
            " 17%|█▋        | 556/3298 [05:58<31:35,  1.45it/s]\u001b[A\n",
            " 17%|█▋        | 557/3298 [05:59<30:56,  1.48it/s]\u001b[A\n",
            " 17%|█▋        | 558/3298 [05:59<30:27,  1.50it/s]\u001b[A\n",
            " 17%|█▋        | 559/3298 [06:00<30:12,  1.51it/s]\u001b[A\n",
            " 17%|█▋        | 560/3298 [06:00<29:53,  1.53it/s]\u001b[A\n",
            " 17%|█▋        | 561/3298 [06:01<29:30,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 562/3298 [06:02<29:25,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 563/3298 [06:02<29:30,  1.54it/s]\u001b[A\n",
            " 17%|█▋        | 564/3298 [06:03<29:21,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 565/3298 [06:04<29:20,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 566/3298 [06:04<29:15,  1.56it/s]\u001b[A\n",
            " 17%|█▋        | 567/3298 [06:05<29:03,  1.57it/s]\u001b[A\n",
            " 17%|█▋        | 568/3298 [06:06<29:24,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 569/3298 [06:06<29:19,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 570/3298 [06:07<29:16,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 571/3298 [06:08<29:20,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 572/3298 [06:08<29:18,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 573/3298 [06:09<29:19,  1.55it/s]\u001b[A\n",
            " 17%|█▋        | 574/3298 [06:09<29:25,  1.54it/s]\u001b[A\n",
            " 17%|█▋        | 575/3298 [06:10<29:34,  1.53it/s]\u001b[A\n",
            " 17%|█▋        | 576/3298 [06:11<29:28,  1.54it/s]\u001b[A\n",
            " 17%|█▋        | 577/3298 [06:11<29:23,  1.54it/s]\u001b[A\n",
            " 18%|█▊        | 578/3298 [06:12<29:07,  1.56it/s]\u001b[A\n",
            " 18%|█▊        | 579/3298 [06:13<29:01,  1.56it/s]\u001b[A\n",
            " 18%|█▊        | 580/3298 [06:13<29:09,  1.55it/s]\u001b[A\n",
            " 18%|█▊        | 581/3298 [06:14<30:55,  1.46it/s]\u001b[A\n",
            " 18%|█▊        | 582/3298 [06:15<32:02,  1.41it/s]\u001b[A\n",
            " 18%|█▊        | 583/3298 [06:16<32:55,  1.37it/s]\u001b[A\n",
            " 18%|█▊        | 584/3298 [06:16<31:56,  1.42it/s]\u001b[A\n",
            " 18%|█▊        | 585/3298 [06:17<31:10,  1.45it/s]\u001b[A\n",
            " 18%|█▊        | 586/3298 [06:18<30:46,  1.47it/s]\u001b[A\n",
            " 18%|█▊        | 587/3298 [06:18<30:32,  1.48it/s]\u001b[A\n",
            " 18%|█▊        | 588/3298 [06:19<30:15,  1.49it/s]\u001b[A\n",
            " 18%|█▊        | 589/3298 [06:20<30:32,  1.48it/s]\u001b[A\n",
            " 18%|█▊        | 590/3298 [06:20<30:14,  1.49it/s]\u001b[A\n",
            " 18%|█▊        | 591/3298 [06:21<31:51,  1.42it/s]\u001b[A\n",
            " 18%|█▊        | 592/3298 [06:22<36:45,  1.23it/s]\u001b[A\n",
            " 18%|█▊        | 593/3298 [06:23<36:13,  1.24it/s]\u001b[A\n",
            " 18%|█▊        | 594/3298 [06:24<36:00,  1.25it/s]\u001b[A\n",
            " 18%|█▊        | 595/3298 [06:24<34:15,  1.31it/s]\u001b[A\n",
            " 18%|█▊        | 596/3298 [06:25<32:46,  1.37it/s]\u001b[A\n",
            " 18%|█▊        | 597/3298 [06:26<33:35,  1.34it/s]\u001b[A\n",
            " 18%|█▊        | 598/3298 [06:27<34:00,  1.32it/s]\u001b[A\n",
            " 18%|█▊        | 599/3298 [06:27<34:28,  1.31it/s]\u001b[A\n",
            " 18%|█▊        | 600/3298 [06:28<32:50,  1.37it/s]\u001b[A\n",
            " 18%|█▊        | 601/3298 [06:29<31:36,  1.42it/s]\u001b[A\n",
            " 18%|█▊        | 602/3298 [06:29<28:55,  1.55it/s]\u001b[A\n",
            " 18%|█▊        | 603/3298 [06:30<28:32,  1.57it/s]\u001b[A\n",
            " 18%|█▊        | 604/3298 [06:30<28:31,  1.57it/s]\u001b[A\n",
            " 18%|█▊        | 605/3298 [06:31<28:32,  1.57it/s]\u001b[A\n",
            " 18%|█▊        | 606/3298 [06:32<28:28,  1.58it/s]\u001b[A\n",
            " 18%|█▊        | 607/3298 [06:32<28:18,  1.58it/s]\u001b[A\n",
            " 18%|█▊        | 608/3298 [06:33<28:21,  1.58it/s]\u001b[A\n",
            " 18%|█▊        | 609/3298 [06:34<28:43,  1.56it/s]\u001b[A\n",
            " 18%|█▊        | 610/3298 [06:34<30:20,  1.48it/s]\u001b[A\n",
            " 19%|█▊        | 611/3298 [06:35<33:27,  1.34it/s]\u001b[A\n",
            " 19%|█▊        | 612/3298 [06:36<33:42,  1.33it/s]\u001b[A\n",
            " 19%|█▊        | 613/3298 [06:37<33:57,  1.32it/s]\u001b[A\n",
            " 19%|█▊        | 614/3298 [06:38<34:20,  1.30it/s]\u001b[A\n",
            " 19%|█▊        | 615/3298 [06:38<32:37,  1.37it/s]\u001b[A\n",
            " 19%|█▊        | 616/3298 [06:39<33:13,  1.35it/s]\u001b[A\n",
            " 19%|█▊        | 617/3298 [06:40<31:55,  1.40it/s]\u001b[A\n",
            " 19%|█▊        | 618/3298 [06:40<32:54,  1.36it/s]\u001b[A\n",
            " 19%|█▉        | 619/3298 [06:41<31:35,  1.41it/s]\u001b[A\n",
            " 19%|█▉        | 620/3298 [06:42<30:55,  1.44it/s]\u001b[A\n",
            " 19%|█▉        | 621/3298 [06:43<31:58,  1.40it/s]\u001b[A\n",
            " 19%|█▉        | 622/3298 [06:43<32:55,  1.35it/s]\u001b[A\n",
            " 19%|█▉        | 623/3298 [06:44<31:28,  1.42it/s]\u001b[A\n",
            " 19%|█▉        | 624/3298 [06:45<32:10,  1.38it/s]\u001b[A\n",
            " 19%|█▉        | 625/3298 [06:45<31:08,  1.43it/s]\u001b[A\n",
            " 19%|█▉        | 626/3298 [06:46<32:09,  1.38it/s]\u001b[A\n",
            " 19%|█▉        | 627/3298 [06:47<30:55,  1.44it/s]\u001b[A\n",
            " 19%|█▉        | 628/3298 [06:48<33:53,  1.31it/s]\u001b[A\n",
            " 19%|█▉        | 629/3298 [06:48<34:14,  1.30it/s]\u001b[A\n",
            " 19%|█▉        | 630/3298 [06:49<34:23,  1.29it/s]\u001b[A\n",
            " 19%|█▉        | 631/3298 [06:50<32:44,  1.36it/s]\u001b[A\n",
            " 19%|█▉        | 632/3298 [06:51<31:47,  1.40it/s]\u001b[A\n",
            " 19%|█▉        | 633/3298 [06:52<34:39,  1.28it/s]\u001b[A\n",
            " 19%|█▉        | 634/3298 [06:52<35:03,  1.27it/s]\u001b[A\n",
            " 19%|█▉        | 635/3298 [06:53<36:34,  1.21it/s]\u001b[A\n",
            " 19%|█▉        | 636/3298 [06:54<37:32,  1.18it/s]\u001b[A\n",
            " 19%|█▉        | 637/3298 [06:55<38:02,  1.17it/s]\u001b[A\n",
            " 19%|█▉        | 638/3298 [06:56<34:57,  1.27it/s]\u001b[A\n",
            " 19%|█▉        | 639/3298 [06:56<32:55,  1.35it/s]\u001b[A\n",
            " 19%|█▉        | 640/3298 [06:57<31:18,  1.41it/s]\u001b[A\n",
            " 19%|█▉        | 641/3298 [06:58<30:21,  1.46it/s]\u001b[A\n",
            " 19%|█▉        | 642/3298 [06:58<28:04,  1.58it/s]\u001b[A\n",
            " 19%|█▉        | 643/3298 [06:59<26:21,  1.68it/s]\u001b[A\n",
            " 20%|█▉        | 644/3298 [06:59<28:48,  1.54it/s]\u001b[A\n",
            " 20%|█▉        | 645/3298 [07:00<32:22,  1.37it/s]\u001b[A\n",
            " 20%|█▉        | 646/3298 [07:01<31:09,  1.42it/s]\u001b[A\n",
            " 20%|█▉        | 647/3298 [07:02<32:14,  1.37it/s]\u001b[A\n",
            " 20%|█▉        | 648/3298 [07:02<31:02,  1.42it/s]\u001b[A\n",
            " 20%|█▉        | 649/3298 [07:03<30:20,  1.46it/s]\u001b[A\n",
            " 20%|█▉        | 650/3298 [07:04<33:16,  1.33it/s]\u001b[A\n",
            " 20%|█▉        | 651/3298 [07:05<32:00,  1.38it/s]\u001b[A\n",
            " 20%|█▉        | 652/3298 [07:05<34:33,  1.28it/s]\u001b[A\n",
            " 20%|█▉        | 653/3298 [07:06<34:36,  1.27it/s]\u001b[A\n",
            " 20%|█▉        | 654/3298 [07:07<30:52,  1.43it/s]\u001b[A\n",
            " 20%|█▉        | 655/3298 [07:07<30:06,  1.46it/s]\u001b[A\n",
            " 20%|█▉        | 656/3298 [07:08<27:50,  1.58it/s]\u001b[A\n",
            " 20%|█▉        | 657/3298 [07:09<31:24,  1.40it/s]\u001b[A\n",
            " 20%|█▉        | 658/3298 [07:10<34:07,  1.29it/s]\u001b[A\n",
            " 20%|█▉        | 659/3298 [07:10<33:55,  1.30it/s]\u001b[A\n",
            " 20%|██        | 660/3298 [07:11<33:46,  1.30it/s]\u001b[A\n",
            " 20%|██        | 661/3298 [07:12<31:56,  1.38it/s]\u001b[A\n",
            " 20%|██        | 662/3298 [07:13<30:55,  1.42it/s]\u001b[A\n",
            " 20%|██        | 663/3298 [07:13<32:16,  1.36it/s]\u001b[A\n",
            " 20%|██        | 664/3298 [07:14<30:57,  1.42it/s]\u001b[A\n",
            " 20%|██        | 665/3298 [07:15<30:10,  1.45it/s]\u001b[A\n",
            " 20%|██        | 666/3298 [07:15<31:30,  1.39it/s]\u001b[A\n",
            " 20%|██        | 667/3298 [07:16<34:11,  1.28it/s]\u001b[A\n",
            " 20%|██        | 668/3298 [07:17<33:46,  1.30it/s]\u001b[A\n",
            " 20%|██        | 669/3298 [07:18<35:22,  1.24it/s]\u001b[A\n",
            " 20%|██        | 670/3298 [07:19<33:19,  1.31it/s]\u001b[A\n",
            " 20%|██        | 671/3298 [07:19<29:48,  1.47it/s]\u001b[A\n",
            " 20%|██        | 672/3298 [07:20<31:11,  1.40it/s]\u001b[A\n",
            " 20%|██        | 673/3298 [07:21<30:17,  1.44it/s]\u001b[A\n",
            " 20%|██        | 674/3298 [07:21<31:19,  1.40it/s]\u001b[A\n",
            " 20%|██        | 675/3298 [07:22<32:02,  1.36it/s]\u001b[A\n",
            " 20%|██        | 676/3298 [07:23<31:05,  1.41it/s]\u001b[A\n",
            " 21%|██        | 677/3298 [07:23<28:28,  1.53it/s]\u001b[A\n",
            " 21%|██        | 678/3298 [07:24<30:13,  1.44it/s]\u001b[A\n",
            " 21%|██        | 679/3298 [07:25<31:30,  1.39it/s]\u001b[A\n",
            " 21%|██        | 680/3298 [07:26<32:10,  1.36it/s]\u001b[A\n",
            " 21%|██        | 681/3298 [07:26<32:46,  1.33it/s]\u001b[A\n",
            " 21%|██        | 682/3298 [07:27<29:31,  1.48it/s]\u001b[A\n",
            " 21%|██        | 683/3298 [07:27<27:11,  1.60it/s]\u001b[A\n",
            " 21%|██        | 684/3298 [07:28<25:35,  1.70it/s]\u001b[A\n",
            " 21%|██        | 685/3298 [07:29<28:00,  1.56it/s]\u001b[A\n",
            " 21%|██        | 686/3298 [07:29<29:37,  1.47it/s]\u001b[A\n",
            " 21%|██        | 687/3298 [07:30<27:14,  1.60it/s]\u001b[A\n",
            " 21%|██        | 688/3298 [07:31<29:09,  1.49it/s]\u001b[A\n",
            " 21%|██        | 689/3298 [07:31<29:11,  1.49it/s]\u001b[A\n",
            " 21%|██        | 690/3298 [07:32<29:02,  1.50it/s]\u001b[A\n",
            " 21%|██        | 691/3298 [07:33<30:36,  1.42it/s]\u001b[A\n",
            " 21%|██        | 692/3298 [07:33<28:22,  1.53it/s]\u001b[A\n",
            " 21%|██        | 693/3298 [07:34<31:47,  1.37it/s]\u001b[A\n",
            " 21%|██        | 694/3298 [07:35<28:50,  1.51it/s]\u001b[A\n",
            " 21%|██        | 695/3298 [07:35<27:13,  1.59it/s]\u001b[A\n",
            " 21%|██        | 696/3298 [07:36<25:43,  1.69it/s]\u001b[A\n",
            " 21%|██        | 697/3298 [07:36<24:38,  1.76it/s]\u001b[A\n",
            " 21%|██        | 698/3298 [07:37<27:18,  1.59it/s]\u001b[A\n",
            " 21%|██        | 699/3298 [07:38<27:33,  1.57it/s]\u001b[A\n",
            " 21%|██        | 700/3298 [07:38<27:43,  1.56it/s]\u001b[A\n",
            " 21%|██▏       | 701/3298 [07:39<31:33,  1.37it/s]\u001b[A\n",
            " 21%|██▏       | 702/3298 [07:40<28:43,  1.51it/s]\u001b[A\n",
            " 21%|██▏       | 703/3298 [07:40<26:58,  1.60it/s]\u001b[A\n",
            " 21%|██▏       | 704/3298 [07:41<25:32,  1.69it/s]\u001b[A\n",
            " 21%|██▏       | 705/3298 [07:42<27:59,  1.54it/s]\u001b[A\n",
            " 21%|██▏       | 706/3298 [07:42<26:11,  1.65it/s]\u001b[A\n",
            " 21%|██▏       | 707/3298 [07:43<26:43,  1.62it/s]\u001b[A\n",
            " 21%|██▏       | 708/3298 [07:44<28:50,  1.50it/s]\u001b[A\n",
            " 21%|██▏       | 709/3298 [07:44<28:40,  1.50it/s]\u001b[A\n",
            " 22%|██▏       | 710/3298 [07:45<28:38,  1.51it/s]\u001b[A\n",
            " 22%|██▏       | 711/3298 [07:46<28:20,  1.52it/s]\u001b[A\n",
            " 22%|██▏       | 712/3298 [07:46<28:09,  1.53it/s]\u001b[A\n",
            " 22%|██▏       | 713/3298 [07:47<29:58,  1.44it/s]\u001b[A\n",
            " 22%|██▏       | 714/3298 [07:48<29:15,  1.47it/s]\u001b[A\n",
            " 22%|██▏       | 715/3298 [07:48<30:11,  1.43it/s]\u001b[A\n",
            " 22%|██▏       | 716/3298 [07:49<30:57,  1.39it/s]\u001b[A\n",
            " 22%|██▏       | 717/3298 [07:50<31:47,  1.35it/s]\u001b[A\n",
            " 22%|██▏       | 718/3298 [07:51<33:51,  1.27it/s]\u001b[A\n",
            " 22%|██▏       | 719/3298 [07:52<35:29,  1.21it/s]\u001b[A\n",
            " 22%|██▏       | 720/3298 [07:53<34:58,  1.23it/s]\u001b[A\n",
            " 22%|██▏       | 721/3298 [07:53<30:57,  1.39it/s]\u001b[A\n",
            " 22%|██▏       | 722/3298 [07:54<30:12,  1.42it/s]\u001b[A\n",
            " 22%|██▏       | 723/3298 [07:54<27:45,  1.55it/s]\u001b[A\n",
            " 22%|██▏       | 724/3298 [07:55<26:04,  1.65it/s]\u001b[A\n",
            " 22%|██▏       | 725/3298 [07:55<25:00,  1.71it/s]\u001b[A\n",
            " 22%|██▏       | 726/3298 [07:56<26:09,  1.64it/s]\u001b[A\n",
            " 22%|██▏       | 727/3298 [07:57<25:07,  1.71it/s]\u001b[A\n",
            " 22%|██▏       | 728/3298 [07:57<26:02,  1.65it/s]\u001b[A\n",
            " 22%|██▏       | 729/3298 [07:58<28:08,  1.52it/s]\u001b[A\n",
            " 22%|██▏       | 730/3298 [07:59<28:07,  1.52it/s]\u001b[A\n",
            " 22%|██▏       | 731/3298 [07:59<28:17,  1.51it/s]\u001b[A\n",
            " 22%|██▏       | 732/3298 [08:00<28:07,  1.52it/s]\u001b[A\n",
            " 22%|██▏       | 733/3298 [08:01<28:15,  1.51it/s]\u001b[A\n",
            " 22%|██▏       | 734/3298 [08:01<26:29,  1.61it/s]\u001b[A\n",
            " 22%|██▏       | 735/3298 [08:02<27:02,  1.58it/s]\u001b[A\n",
            " 22%|██▏       | 736/3298 [08:03<31:07,  1.37it/s]\u001b[A\n",
            " 22%|██▏       | 737/3298 [08:03<30:09,  1.42it/s]\u001b[A\n",
            " 22%|██▏       | 738/3298 [08:04<29:16,  1.46it/s]\u001b[A\n",
            " 22%|██▏       | 739/3298 [08:05<27:03,  1.58it/s]\u001b[A\n",
            " 22%|██▏       | 740/3298 [08:05<25:24,  1.68it/s]\u001b[A\n",
            " 22%|██▏       | 741/3298 [08:06<25:44,  1.66it/s]\u001b[A\n",
            " 22%|██▏       | 742/3298 [08:06<26:02,  1.64it/s]\u001b[A\n",
            " 23%|██▎       | 743/3298 [08:07<26:12,  1.62it/s]\u001b[A\n",
            " 23%|██▎       | 744/3298 [08:08<26:30,  1.61it/s]\u001b[A\n",
            " 23%|██▎       | 745/3298 [08:08<26:40,  1.60it/s]\u001b[A\n",
            " 23%|██▎       | 746/3298 [08:09<25:24,  1.67it/s]\u001b[A\n",
            " 23%|██▎       | 747/3298 [08:09<24:23,  1.74it/s]\u001b[A\n",
            " 23%|██▎       | 748/3298 [08:10<23:28,  1.81it/s]\u001b[A\n",
            " 23%|██▎       | 749/3298 [08:10<24:39,  1.72it/s]\u001b[A\n",
            " 23%|██▎       | 750/3298 [08:11<25:22,  1.67it/s]\u001b[A\n",
            " 23%|██▎       | 751/3298 [08:12<26:19,  1.61it/s]\u001b[A\n",
            " 23%|██▎       | 752/3298 [08:12<26:45,  1.59it/s]\u001b[A\n",
            " 23%|██▎       | 753/3298 [08:13<26:48,  1.58it/s]\u001b[A\n",
            " 23%|██▎       | 754/3298 [08:14<25:37,  1.65it/s]\u001b[A\n",
            " 23%|██▎       | 755/3298 [08:14<26:09,  1.62it/s]\u001b[A\n",
            " 23%|██▎       | 756/3298 [08:15<26:28,  1.60it/s]\u001b[A\n",
            " 23%|██▎       | 757/3298 [08:16<27:05,  1.56it/s]\u001b[A\n",
            " 23%|██▎       | 758/3298 [08:16<27:06,  1.56it/s]\u001b[A\n",
            " 23%|██▎       | 759/3298 [08:17<29:07,  1.45it/s]\u001b[A\n",
            " 23%|██▎       | 760/3298 [08:18<28:35,  1.48it/s]\u001b[A\n",
            " 23%|██▎       | 761/3298 [08:18<28:05,  1.51it/s]\u001b[A\n",
            " 23%|██▎       | 762/3298 [08:19<27:49,  1.52it/s]\u001b[A\n",
            " 23%|██▎       | 763/3298 [08:20<27:26,  1.54it/s]\u001b[A\n",
            " 23%|██▎       | 764/3298 [08:20<27:13,  1.55it/s]\u001b[A\n",
            " 23%|██▎       | 765/3298 [08:21<28:51,  1.46it/s]\u001b[A\n",
            " 23%|██▎       | 766/3298 [08:22<29:54,  1.41it/s]\u001b[A\n",
            " 23%|██▎       | 767/3298 [08:22<29:06,  1.45it/s]\u001b[A\n",
            " 23%|██▎       | 768/3298 [08:23<29:59,  1.41it/s]\u001b[A\n",
            " 23%|██▎       | 769/3298 [08:24<30:54,  1.36it/s]\u001b[A\n",
            " 23%|██▎       | 770/3298 [08:25<31:17,  1.35it/s]\u001b[A\n",
            " 23%|██▎       | 771/3298 [08:25<31:43,  1.33it/s]\u001b[A\n",
            " 23%|██▎       | 772/3298 [08:26<32:01,  1.31it/s]\u001b[A\n",
            " 23%|██▎       | 773/3298 [08:27<34:01,  1.24it/s]\u001b[A\n",
            " 23%|██▎       | 774/3298 [08:28<35:12,  1.20it/s]\u001b[A\n",
            " 23%|██▎       | 775/3298 [08:29<36:03,  1.17it/s]\u001b[A\n",
            " 24%|██▎       | 776/3298 [08:30<34:52,  1.21it/s]\u001b[A\n",
            " 24%|██▎       | 777/3298 [08:31<35:43,  1.18it/s]\u001b[A\n",
            " 24%|██▎       | 778/3298 [08:31<33:05,  1.27it/s]\u001b[A\n",
            " 24%|██▎       | 779/3298 [08:32<31:14,  1.34it/s]\u001b[A\n",
            " 24%|██▎       | 780/3298 [08:33<29:53,  1.40it/s]\u001b[A\n",
            " 24%|██▎       | 781/3298 [08:33<30:51,  1.36it/s]\u001b[A\n",
            " 24%|██▎       | 782/3298 [08:34<32:57,  1.27it/s]\u001b[A\n",
            " 24%|██▎       | 783/3298 [08:35<29:26,  1.42it/s]\u001b[A\n",
            " 24%|██▍       | 784/3298 [08:36<30:49,  1.36it/s]\u001b[A\n",
            " 24%|██▍       | 785/3298 [08:36<29:39,  1.41it/s]\u001b[A\n",
            " 24%|██▍       | 786/3298 [08:37<27:12,  1.54it/s]\u001b[A\n",
            " 24%|██▍       | 787/3298 [08:37<25:48,  1.62it/s]\u001b[A\n",
            " 24%|██▍       | 788/3298 [08:38<24:23,  1.72it/s]\u001b[A\n",
            " 24%|██▍       | 789/3298 [08:38<25:06,  1.67it/s]\u001b[A\n",
            " 24%|██▍       | 790/3298 [08:39<25:25,  1.64it/s]\u001b[A\n",
            " 24%|██▍       | 791/3298 [08:39<24:00,  1.74it/s]\u001b[A\n",
            " 24%|██▍       | 792/3298 [08:40<24:43,  1.69it/s]\u001b[A\n",
            " 24%|██▍       | 793/3298 [08:41<23:43,  1.76it/s]\u001b[A\n",
            " 24%|██▍       | 794/3298 [08:41<23:01,  1.81it/s]\u001b[A\n",
            " 24%|██▍       | 795/3298 [08:42<25:37,  1.63it/s]\u001b[A\n",
            " 24%|██▍       | 796/3298 [08:43<27:34,  1.51it/s]\u001b[A\n",
            " 24%|██▍       | 797/3298 [08:43<27:10,  1.53it/s]\u001b[A\n",
            " 24%|██▍       | 798/3298 [08:44<25:27,  1.64it/s]\u001b[A\n",
            " 24%|██▍       | 799/3298 [08:44<26:01,  1.60it/s]\u001b[A\n",
            " 24%|██▍       | 800/3298 [08:45<26:13,  1.59it/s]\u001b[A\n",
            " 24%|██▍       | 801/3298 [08:46<26:23,  1.58it/s]\u001b[A\n",
            " 24%|██▍       | 802/3298 [08:47<28:17,  1.47it/s]\u001b[A\n",
            " 24%|██▍       | 803/3298 [08:47<27:49,  1.49it/s]\u001b[A\n",
            " 24%|██▍       | 804/3298 [08:48<30:49,  1.35it/s]\u001b[A\n",
            " 24%|██▍       | 805/3298 [08:49<31:12,  1.33it/s]\u001b[A\n",
            " 24%|██▍       | 806/3298 [08:50<29:51,  1.39it/s]\u001b[A\n",
            " 24%|██▍       | 807/3298 [08:50<30:58,  1.34it/s]\u001b[A\n",
            " 24%|██▍       | 808/3298 [08:51<29:38,  1.40it/s]\u001b[A\n",
            " 25%|██▍       | 809/3298 [08:52<33:39,  1.23it/s]\u001b[A\n",
            " 25%|██▍       | 810/3298 [08:53<33:11,  1.25it/s]\u001b[A\n",
            " 25%|██▍       | 811/3298 [08:53<31:29,  1.32it/s]\u001b[A\n",
            " 25%|██▍       | 812/3298 [08:54<31:58,  1.30it/s]\u001b[A\n",
            " 25%|██▍       | 813/3298 [08:55<30:26,  1.36it/s]\u001b[A\n",
            " 25%|██▍       | 814/3298 [08:56<29:17,  1.41it/s]\u001b[A\n",
            " 25%|██▍       | 815/3298 [08:56<28:19,  1.46it/s]\u001b[A\n",
            " 25%|██▍       | 816/3298 [08:57<27:44,  1.49it/s]\u001b[A\n",
            " 25%|██▍       | 817/3298 [08:57<27:22,  1.51it/s]\u001b[A\n",
            " 25%|██▍       | 818/3298 [08:58<26:54,  1.54it/s]\u001b[A\n",
            " 25%|██▍       | 819/3298 [08:59<27:02,  1.53it/s]\u001b[A\n",
            " 25%|██▍       | 820/3298 [08:59<25:13,  1.64it/s]\u001b[A\n",
            " 25%|██▍       | 821/3298 [09:00<23:57,  1.72it/s]\u001b[A\n",
            " 25%|██▍       | 822/3298 [09:00<23:08,  1.78it/s]\u001b[A\n",
            " 25%|██▍       | 823/3298 [09:01<22:23,  1.84it/s]\u001b[A\n",
            " 25%|██▍       | 824/3298 [09:01<23:33,  1.75it/s]\u001b[A\n",
            " 25%|██▌       | 825/3298 [09:02<24:27,  1.68it/s]\u001b[A\n",
            " 25%|██▌       | 826/3298 [09:03<26:52,  1.53it/s]\u001b[A\n",
            " 25%|██▌       | 827/3298 [09:03<26:43,  1.54it/s]\u001b[A\n",
            " 25%|██▌       | 828/3298 [09:04<28:11,  1.46it/s]\u001b[A\n",
            " 25%|██▌       | 829/3298 [09:05<27:48,  1.48it/s]\u001b[A\n",
            " 25%|██▌       | 830/3298 [09:05<25:55,  1.59it/s]\u001b[A\n",
            " 25%|██▌       | 831/3298 [09:06<25:50,  1.59it/s]\u001b[A\n",
            " 25%|██▌       | 832/3298 [09:07<27:27,  1.50it/s]\u001b[A\n",
            " 25%|██▌       | 833/3298 [09:07<27:16,  1.51it/s]\u001b[A\n",
            " 25%|██▌       | 834/3298 [09:08<28:26,  1.44it/s]\u001b[A\n",
            " 25%|██▌       | 835/3298 [09:09<30:47,  1.33it/s]\u001b[A\n",
            " 25%|██▌       | 836/3298 [09:10<29:20,  1.40it/s]\u001b[A\n",
            " 25%|██▌       | 837/3298 [09:10<26:42,  1.54it/s]\u001b[A\n",
            " 25%|██▌       | 838/3298 [09:11<24:47,  1.65it/s]\u001b[A\n",
            " 25%|██▌       | 839/3298 [09:12<28:32,  1.44it/s]\u001b[A\n",
            " 25%|██▌       | 840/3298 [09:12<27:55,  1.47it/s]\u001b[A\n",
            " 26%|██▌       | 841/3298 [09:13<27:18,  1.50it/s]\u001b[A\n",
            " 26%|██▌       | 842/3298 [09:13<25:22,  1.61it/s]\u001b[A\n",
            " 26%|██▌       | 843/3298 [09:14<27:13,  1.50it/s]\u001b[A\n",
            " 26%|██▌       | 844/3298 [09:15<26:50,  1.52it/s]\u001b[A\n",
            " 26%|██▌       | 845/3298 [09:15<25:02,  1.63it/s]\u001b[A\n",
            " 26%|██▌       | 846/3298 [09:16<23:30,  1.74it/s]\u001b[A\n",
            " 26%|██▌       | 847/3298 [09:17<26:00,  1.57it/s]\u001b[A\n",
            " 26%|██▌       | 848/3298 [09:17<24:15,  1.68it/s]\u001b[A\n",
            " 26%|██▌       | 849/3298 [09:18<23:06,  1.77it/s]\u001b[A\n",
            " 26%|██▌       | 850/3298 [09:18<23:54,  1.71it/s]\u001b[A\n",
            " 26%|██▌       | 851/3298 [09:19<22:43,  1.79it/s]\u001b[A\n",
            " 26%|██▌       | 852/3298 [09:19<23:34,  1.73it/s]\u001b[A\n",
            " 26%|██▌       | 853/3298 [09:20<24:03,  1.69it/s]\u001b[A\n",
            " 26%|██▌       | 854/3298 [09:21<24:34,  1.66it/s]\u001b[A\n",
            " 26%|██▌       | 855/3298 [09:21<25:04,  1.62it/s]\u001b[A\n",
            " 26%|██▌       | 856/3298 [09:22<23:39,  1.72it/s]\u001b[A\n",
            " 26%|██▌       | 857/3298 [09:22<22:46,  1.79it/s]\u001b[A\n",
            " 26%|██▌       | 858/3298 [09:23<22:03,  1.84it/s]\u001b[A\n",
            " 26%|██▌       | 859/3298 [09:23<21:33,  1.89it/s]\u001b[A\n",
            " 26%|██▌       | 860/3298 [09:24<21:18,  1.91it/s]\u001b[A\n",
            " 26%|██▌       | 861/3298 [09:24<21:04,  1.93it/s]\u001b[A\n",
            " 26%|██▌       | 862/3298 [09:25<22:29,  1.80it/s]\u001b[A\n",
            " 26%|██▌       | 863/3298 [09:26<23:23,  1.73it/s]\u001b[A\n",
            " 26%|██▌       | 864/3298 [09:26<22:21,  1.82it/s]\u001b[A\n",
            " 26%|██▌       | 865/3298 [09:27<25:07,  1.61it/s]\u001b[A\n",
            " 26%|██▋       | 866/3298 [09:28<25:28,  1.59it/s]\u001b[A\n",
            " 26%|██▋       | 867/3298 [09:28<24:03,  1.68it/s]\u001b[A\n",
            " 26%|██▋       | 868/3298 [09:29<24:35,  1.65it/s]\u001b[A\n",
            " 26%|██▋       | 869/3298 [09:29<23:26,  1.73it/s]\u001b[A\n",
            " 26%|██▋       | 870/3298 [09:30<22:27,  1.80it/s]\u001b[A\n",
            " 26%|██▋       | 871/3298 [09:30<21:51,  1.85it/s]\u001b[A\n",
            " 26%|██▋       | 872/3298 [09:31<22:55,  1.76it/s]\u001b[A\n",
            " 26%|██▋       | 873/3298 [09:31<22:04,  1.83it/s]\u001b[A\n",
            " 27%|██▋       | 874/3298 [09:32<21:19,  1.89it/s]\u001b[A\n",
            " 27%|██▋       | 875/3298 [09:32<22:31,  1.79it/s]\u001b[A\n",
            " 27%|██▋       | 876/3298 [09:33<21:48,  1.85it/s]\u001b[A\n",
            " 27%|██▋       | 877/3298 [09:34<23:07,  1.75it/s]\u001b[A\n",
            " 27%|██▋       | 878/3298 [09:34<25:17,  1.59it/s]\u001b[A\n",
            " 27%|██▋       | 879/3298 [09:35<26:48,  1.50it/s]\u001b[A\n",
            " 27%|██▋       | 880/3298 [09:36<27:55,  1.44it/s]\u001b[A\n",
            " 27%|██▋       | 881/3298 [09:37<28:35,  1.41it/s]\u001b[A\n",
            " 27%|██▋       | 882/3298 [09:37<30:51,  1.30it/s]\u001b[A\n",
            " 27%|██▋       | 883/3298 [09:38<31:00,  1.30it/s]\u001b[A\n",
            " 27%|██▋       | 884/3298 [09:39<30:58,  1.30it/s]\u001b[A\n",
            " 27%|██▋       | 885/3298 [09:40<30:40,  1.31it/s]\u001b[A\n",
            " 27%|██▋       | 886/3298 [09:41<32:11,  1.25it/s]\u001b[A\n",
            " 27%|██▋       | 887/3298 [09:41<30:01,  1.34it/s]\u001b[A\n",
            " 27%|██▋       | 888/3298 [09:42<33:05,  1.21it/s]\u001b[A\n",
            " 27%|██▋       | 889/3298 [09:43<30:35,  1.31it/s]\u001b[A\n",
            " 27%|██▋       | 890/3298 [09:44<32:23,  1.24it/s]\u001b[A\n",
            " 27%|██▋       | 891/3298 [09:44<30:27,  1.32it/s]\u001b[A\n",
            " 27%|██▋       | 892/3298 [09:45<27:16,  1.47it/s]\u001b[A\n",
            " 27%|██▋       | 893/3298 [09:45<25:26,  1.58it/s]\u001b[A\n",
            " 27%|██▋       | 894/3298 [09:46<23:51,  1.68it/s]\u001b[A\n",
            " 27%|██▋       | 895/3298 [09:47<24:26,  1.64it/s]\u001b[A\n",
            " 27%|██▋       | 896/3298 [09:47<26:28,  1.51it/s]\u001b[A\n",
            " 27%|██▋       | 897/3298 [09:48<26:01,  1.54it/s]\u001b[A\n",
            " 27%|██▋       | 898/3298 [09:49<25:47,  1.55it/s]\u001b[A\n",
            " 27%|██▋       | 899/3298 [09:49<27:30,  1.45it/s]\u001b[A\n",
            " 27%|██▋       | 900/3298 [09:50<26:49,  1.49it/s]\u001b[A\n",
            " 27%|██▋       | 901/3298 [09:51<26:27,  1.51it/s]\u001b[A\n",
            " 27%|██▋       | 902/3298 [09:51<26:16,  1.52it/s]\u001b[A\n",
            " 27%|██▋       | 903/3298 [09:52<25:58,  1.54it/s]\u001b[A\n",
            " 27%|██▋       | 904/3298 [09:53<25:35,  1.56it/s]\u001b[A\n",
            " 27%|██▋       | 905/3298 [09:54<28:52,  1.38it/s]\u001b[A\n",
            " 27%|██▋       | 906/3298 [09:54<26:13,  1.52it/s]\u001b[A\n",
            " 28%|██▊       | 907/3298 [09:55<24:28,  1.63it/s]\u001b[A\n",
            " 28%|██▊       | 908/3298 [09:55<23:09,  1.72it/s]\u001b[A\n",
            " 28%|██▊       | 909/3298 [09:56<22:26,  1.77it/s]\u001b[A\n",
            " 28%|██▊       | 910/3298 [09:56<23:16,  1.71it/s]\u001b[A\n",
            " 28%|██▊       | 911/3298 [09:57<22:23,  1.78it/s]\u001b[A\n",
            " 28%|██▊       | 912/3298 [09:57<23:18,  1.71it/s]\u001b[A\n",
            " 28%|██▊       | 913/3298 [09:58<23:45,  1.67it/s]\u001b[A\n",
            " 28%|██▊       | 914/3298 [09:59<22:32,  1.76it/s]\u001b[A\n",
            " 28%|██▊       | 915/3298 [09:59<25:13,  1.57it/s]\u001b[A\n",
            " 28%|██▊       | 916/3298 [10:00<26:55,  1.47it/s]\u001b[A\n",
            " 28%|██▊       | 917/3298 [10:01<28:02,  1.41it/s]\u001b[A\n",
            " 28%|██▊       | 918/3298 [10:02<28:44,  1.38it/s]\u001b[A\n",
            " 28%|██▊       | 919/3298 [10:02<29:16,  1.35it/s]\u001b[A\n",
            " 28%|██▊       | 920/3298 [10:03<27:56,  1.42it/s]\u001b[A\n",
            " 28%|██▊       | 921/3298 [10:04<27:34,  1.44it/s]\u001b[A\n",
            " 28%|██▊       | 922/3298 [10:04<27:13,  1.45it/s]\u001b[A\n",
            " 28%|██▊       | 923/3298 [10:05<26:53,  1.47it/s]\u001b[A\n",
            " 28%|██▊       | 924/3298 [10:06<25:05,  1.58it/s]\u001b[A\n",
            " 28%|██▊       | 925/3298 [10:06<25:31,  1.55it/s]\u001b[A\n",
            " 28%|██▊       | 926/3298 [10:07<24:07,  1.64it/s]\u001b[A\n",
            " 28%|██▊       | 927/3298 [10:07<24:37,  1.60it/s]\u001b[A\n",
            " 28%|██▊       | 928/3298 [10:08<23:21,  1.69it/s]\u001b[A\n",
            " 28%|██▊       | 929/3298 [10:09<24:02,  1.64it/s]\u001b[A\n",
            " 28%|██▊       | 930/3298 [10:09<23:04,  1.71it/s]\u001b[A\n",
            " 28%|██▊       | 931/3298 [10:10<24:06,  1.64it/s]\u001b[A\n",
            " 28%|██▊       | 932/3298 [10:10<24:24,  1.62it/s]\u001b[A\n",
            " 28%|██▊       | 933/3298 [10:11<24:40,  1.60it/s]\u001b[A\n",
            " 28%|██▊       | 934/3298 [10:12<23:08,  1.70it/s]\u001b[A\n",
            " 28%|██▊       | 935/3298 [10:12<22:00,  1.79it/s]\u001b[A\n",
            " 28%|██▊       | 936/3298 [10:13<21:19,  1.85it/s]\u001b[A\n",
            " 28%|██▊       | 937/3298 [10:13<22:24,  1.76it/s]\u001b[A\n",
            " 28%|██▊       | 938/3298 [10:14<23:32,  1.67it/s]\u001b[A\n",
            " 28%|██▊       | 939/3298 [10:15<25:59,  1.51it/s]\u001b[A\n",
            " 29%|██▊       | 940/3298 [10:15<26:03,  1.51it/s]\u001b[A\n",
            " 29%|██▊       | 941/3298 [10:16<24:10,  1.62it/s]\u001b[A\n",
            " 29%|██▊       | 942/3298 [10:16<24:36,  1.60it/s]\u001b[A\n",
            " 29%|██▊       | 943/3298 [10:17<26:35,  1.48it/s]\u001b[A\n",
            " 29%|██▊       | 944/3298 [10:18<26:13,  1.50it/s]\u001b[A\n",
            " 29%|██▊       | 945/3298 [10:19<25:58,  1.51it/s]\u001b[A\n",
            " 29%|██▊       | 946/3298 [10:19<24:16,  1.62it/s]\u001b[A\n",
            " 29%|██▊       | 947/3298 [10:20<24:41,  1.59it/s]\u001b[A\n",
            " 29%|██▊       | 948/3298 [10:20<25:20,  1.55it/s]\u001b[A\n",
            " 29%|██▉       | 949/3298 [10:21<28:53,  1.35it/s]\u001b[A\n",
            " 29%|██▉       | 950/3298 [10:22<29:29,  1.33it/s]\u001b[A\n",
            " 29%|██▉       | 951/3298 [10:23<28:25,  1.38it/s]\u001b[A\n",
            " 29%|██▉       | 952/3298 [10:23<26:07,  1.50it/s]\u001b[A\n",
            " 29%|██▉       | 953/3298 [10:24<25:58,  1.50it/s]\u001b[A\n",
            " 29%|██▉       | 954/3298 [10:25<27:35,  1.42it/s]\u001b[A\n",
            " 29%|██▉       | 955/3298 [10:26<28:34,  1.37it/s]\u001b[A\n",
            " 29%|██▉       | 956/3298 [10:26<27:24,  1.42it/s]\u001b[A\n",
            " 29%|██▉       | 957/3298 [10:27<26:28,  1.47it/s]\u001b[A\n",
            " 29%|██▉       | 958/3298 [10:28<27:38,  1.41it/s]\u001b[A\n",
            " 29%|██▉       | 959/3298 [10:29<30:07,  1.29it/s]\u001b[A\n",
            " 29%|██▉       | 960/3298 [10:29<28:30,  1.37it/s]\u001b[A\n",
            " 29%|██▉       | 961/3298 [10:30<27:20,  1.42it/s]\u001b[A\n",
            " 29%|██▉       | 962/3298 [10:30<25:03,  1.55it/s]\u001b[A\n",
            " 29%|██▉       | 963/3298 [10:31<24:51,  1.57it/s]\u001b[A\n",
            " 29%|██▉       | 964/3298 [10:32<23:36,  1.65it/s]\u001b[A\n",
            " 29%|██▉       | 965/3298 [10:32<23:54,  1.63it/s]\u001b[A\n",
            " 29%|██▉       | 966/3298 [10:33<27:20,  1.42it/s]\u001b[A\n",
            " 29%|██▉       | 967/3298 [10:34<26:37,  1.46it/s]\u001b[A\n",
            " 29%|██▉       | 968/3298 [10:34<26:02,  1.49it/s]\u001b[A\n",
            " 29%|██▉       | 969/3298 [10:35<25:36,  1.52it/s]\u001b[A\n",
            " 29%|██▉       | 970/3298 [10:36<25:21,  1.53it/s]\u001b[A\n",
            " 29%|██▉       | 971/3298 [10:36<25:05,  1.55it/s]\u001b[A\n",
            " 29%|██▉       | 972/3298 [10:37<26:21,  1.47it/s]\u001b[A\n",
            " 30%|██▉       | 973/3298 [10:38<27:30,  1.41it/s]\u001b[A\n",
            " 30%|██▉       | 974/3298 [10:39<28:32,  1.36it/s]\u001b[A\n",
            " 30%|██▉       | 975/3298 [10:39<27:22,  1.41it/s]\u001b[A\n",
            " 30%|██▉       | 976/3298 [10:40<26:39,  1.45it/s]\u001b[A\n",
            " 30%|██▉       | 977/3298 [10:41<26:13,  1.48it/s]\u001b[A\n",
            " 30%|██▉       | 978/3298 [10:41<27:22,  1.41it/s]\u001b[A\n",
            " 30%|██▉       | 979/3298 [10:42<28:01,  1.38it/s]\u001b[A\n",
            " 30%|██▉       | 980/3298 [10:43<28:32,  1.35it/s]\u001b[A\n",
            " 30%|██▉       | 981/3298 [10:44<30:18,  1.27it/s]\u001b[A\n",
            " 30%|██▉       | 982/3298 [10:44<30:18,  1.27it/s]\u001b[A\n",
            " 30%|██▉       | 983/3298 [10:45<31:32,  1.22it/s]\u001b[A\n",
            " 30%|██▉       | 984/3298 [10:46<30:57,  1.25it/s]\u001b[A\n",
            " 30%|██▉       | 985/3298 [10:47<29:07,  1.32it/s]\u001b[A\n",
            " 30%|██▉       | 986/3298 [10:48<29:20,  1.31it/s]\u001b[A\n",
            " 30%|██▉       | 987/3298 [10:48<29:25,  1.31it/s]\u001b[A\n",
            " 30%|██▉       | 988/3298 [10:49<30:46,  1.25it/s]\u001b[A\n",
            " 30%|██▉       | 989/3298 [10:50<28:47,  1.34it/s]\u001b[A\n",
            " 30%|███       | 990/3298 [10:51<30:50,  1.25it/s]\u001b[A\n",
            " 30%|███       | 991/3298 [10:52<31:58,  1.20it/s]\u001b[A\n",
            " 30%|███       | 992/3298 [10:52<31:17,  1.23it/s]\u001b[A\n",
            " 30%|███       | 993/3298 [10:53<30:32,  1.26it/s]\u001b[A\n",
            " 30%|███       | 994/3298 [10:54<30:11,  1.27it/s]\u001b[A\n",
            " 30%|███       | 995/3298 [10:55<32:44,  1.17it/s]\u001b[A\n",
            " 30%|███       | 996/3298 [10:56<33:30,  1.14it/s]\u001b[A\n",
            " 30%|███       | 997/3298 [10:57<30:33,  1.25it/s]\u001b[A\n",
            " 30%|███       | 998/3298 [10:57<30:03,  1.28it/s]\u001b[A\n",
            " 30%|███       | 999/3298 [10:58<29:48,  1.29it/s]\u001b[A\n",
            " 30%|███       | 1000/3298 [10:59<29:30,  1.30it/s]\u001b[A\n",
            " 30%|███       | 1001/3298 [11:00<30:52,  1.24it/s]\u001b[A\n",
            " 30%|███       | 1002/3298 [11:00<30:20,  1.26it/s]\u001b[A\n",
            " 30%|███       | 1003/3298 [11:01<33:02,  1.16it/s]\u001b[A\n",
            " 30%|███       | 1004/3298 [11:02<32:00,  1.19it/s]\u001b[A\n",
            " 30%|███       | 1005/3298 [11:03<31:35,  1.21it/s]\u001b[A\n",
            " 31%|███       | 1006/3298 [11:04<30:48,  1.24it/s]\u001b[A\n",
            " 31%|███       | 1007/3298 [11:05<30:42,  1.24it/s]\u001b[A\n",
            " 31%|███       | 1008/3298 [11:05<30:20,  1.26it/s]\u001b[A\n",
            " 31%|███       | 1009/3298 [11:06<29:57,  1.27it/s]\u001b[A\n",
            " 31%|███       | 1010/3298 [11:07<29:35,  1.29it/s]\u001b[A\n",
            " 31%|███       | 1011/3298 [11:08<29:38,  1.29it/s]\u001b[A\n",
            " 31%|███       | 1012/3298 [11:09<30:57,  1.23it/s]\u001b[A\n",
            " 31%|███       | 1013/3298 [11:09<30:23,  1.25it/s]\u001b[A\n",
            " 31%|███       | 1014/3298 [11:10<30:00,  1.27it/s]\u001b[A\n",
            " 31%|███       | 1015/3298 [11:11<29:55,  1.27it/s]\u001b[A\n",
            " 31%|███       | 1016/3298 [11:12<31:09,  1.22it/s]\u001b[A\n",
            " 31%|███       | 1017/3298 [11:13<30:46,  1.24it/s]\u001b[A\n",
            " 31%|███       | 1018/3298 [11:13<27:16,  1.39it/s]\u001b[A\n",
            " 31%|███       | 1019/3298 [11:14<24:56,  1.52it/s]\u001b[A\n",
            " 31%|███       | 1020/3298 [11:14<26:05,  1.45it/s]\u001b[A\n",
            " 31%|███       | 1021/3298 [11:15<25:30,  1.49it/s]\u001b[A\n",
            " 31%|███       | 1022/3298 [11:16<25:05,  1.51it/s]\u001b[A\n",
            " 31%|███       | 1023/3298 [11:16<25:02,  1.51it/s]\u001b[A\n",
            " 31%|███       | 1024/3298 [11:17<25:11,  1.50it/s]\u001b[A\n",
            " 31%|███       | 1025/3298 [11:18<25:18,  1.50it/s]\u001b[A\n",
            " 31%|███       | 1026/3298 [11:18<26:47,  1.41it/s]\u001b[A\n",
            " 31%|███       | 1027/3298 [11:19<28:02,  1.35it/s]\u001b[A\n",
            " 31%|███       | 1028/3298 [11:20<25:32,  1.48it/s]\u001b[A\n",
            " 31%|███       | 1029/3298 [11:20<25:21,  1.49it/s]\u001b[A\n",
            " 31%|███       | 1030/3298 [11:21<25:23,  1.49it/s]\u001b[A\n",
            " 31%|███▏      | 1031/3298 [11:22<25:16,  1.49it/s]\u001b[A\n",
            " 31%|███▏      | 1032/3298 [11:22<25:09,  1.50it/s]\u001b[A\n",
            " 31%|███▏      | 1033/3298 [11:23<25:09,  1.50it/s]\u001b[A\n",
            " 31%|███▏      | 1034/3298 [11:24<25:02,  1.51it/s]\u001b[A\n",
            " 31%|███▏      | 1035/3298 [11:24<23:44,  1.59it/s]\u001b[A\n",
            " 31%|███▏      | 1036/3298 [11:25<23:57,  1.57it/s]\u001b[A\n",
            " 31%|███▏      | 1037/3298 [11:26<25:33,  1.47it/s]\u001b[A\n",
            " 31%|███▏      | 1038/3298 [11:26<25:14,  1.49it/s]\u001b[A\n",
            " 32%|███▏      | 1039/3298 [11:27<25:13,  1.49it/s]\u001b[A\n",
            " 32%|███▏      | 1040/3298 [11:28<25:14,  1.49it/s]\u001b[A\n",
            " 32%|███▏      | 1041/3298 [11:29<26:48,  1.40it/s]\u001b[A\n",
            " 32%|███▏      | 1042/3298 [11:29<26:17,  1.43it/s]\u001b[A\n",
            " 32%|███▏      | 1043/3298 [11:30<25:33,  1.47it/s]\u001b[A\n",
            " 32%|███▏      | 1044/3298 [11:30<25:12,  1.49it/s]\u001b[A\n",
            " 32%|███▏      | 1045/3298 [11:31<26:44,  1.40it/s]\u001b[A\n",
            " 32%|███▏      | 1046/3298 [11:32<27:38,  1.36it/s]\u001b[A\n",
            " 32%|███▏      | 1047/3298 [11:33<28:18,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 1048/3298 [11:34<30:21,  1.24it/s]\u001b[A\n",
            " 32%|███▏      | 1049/3298 [11:35<30:14,  1.24it/s]\u001b[A\n",
            " 32%|███▏      | 1050/3298 [11:35<27:06,  1.38it/s]\u001b[A\n",
            " 32%|███▏      | 1051/3298 [11:36<27:58,  1.34it/s]\u001b[A\n",
            " 32%|███▏      | 1052/3298 [11:37<28:36,  1.31it/s]\u001b[A\n",
            " 32%|███▏      | 1053/3298 [11:37<27:24,  1.37it/s]\u001b[A\n",
            " 32%|███▏      | 1054/3298 [11:38<26:31,  1.41it/s]\u001b[A\n",
            " 32%|███▏      | 1055/3298 [11:39<26:04,  1.43it/s]\u001b[A\n",
            " 32%|███▏      | 1056/3298 [11:40<27:05,  1.38it/s]\u001b[A\n",
            " 32%|███▏      | 1057/3298 [11:40<26:19,  1.42it/s]\u001b[A\n",
            " 32%|███▏      | 1058/3298 [11:41<24:15,  1.54it/s]\u001b[A\n",
            " 32%|███▏      | 1059/3298 [11:41<24:39,  1.51it/s]\u001b[A\n",
            " 32%|███▏      | 1060/3298 [11:42<26:12,  1.42it/s]\u001b[A\n",
            " 32%|███▏      | 1061/3298 [11:43<25:42,  1.45it/s]\u001b[A\n",
            " 32%|███▏      | 1062/3298 [11:44<25:16,  1.47it/s]\u001b[A\n",
            " 32%|███▏      | 1063/3298 [11:44<24:59,  1.49it/s]\u001b[A\n",
            " 32%|███▏      | 1064/3298 [11:45<23:25,  1.59it/s]\u001b[A\n",
            " 32%|███▏      | 1065/3298 [11:45<25:17,  1.47it/s]\u001b[A\n",
            " 32%|███▏      | 1066/3298 [11:46<27:55,  1.33it/s]\u001b[A\n",
            " 32%|███▏      | 1067/3298 [11:47<28:30,  1.30it/s]\u001b[A\n",
            " 32%|███▏      | 1068/3298 [11:48<27:18,  1.36it/s]\u001b[A\n",
            " 32%|███▏      | 1069/3298 [11:49<28:03,  1.32it/s]\u001b[A\n",
            " 32%|███▏      | 1070/3298 [11:50<30:03,  1.24it/s]\u001b[A\n",
            " 32%|███▏      | 1071/3298 [11:50<29:44,  1.25it/s]\u001b[A\n",
            " 33%|███▎      | 1072/3298 [11:51<27:58,  1.33it/s]\u001b[A\n",
            " 33%|███▎      | 1073/3298 [11:52<26:52,  1.38it/s]\u001b[A\n",
            " 33%|███▎      | 1074/3298 [11:52<26:09,  1.42it/s]\u001b[A\n",
            " 33%|███▎      | 1075/3298 [11:53<25:35,  1.45it/s]\u001b[A\n",
            " 33%|███▎      | 1076/3298 [11:54<27:06,  1.37it/s]\u001b[A\n",
            " 33%|███▎      | 1077/3298 [11:55<30:58,  1.20it/s]\u001b[A\n",
            " 33%|███▎      | 1078/3298 [11:56<28:58,  1.28it/s]\u001b[A\n",
            " 33%|███▎      | 1079/3298 [11:56<27:51,  1.33it/s]\u001b[A\n",
            " 33%|███▎      | 1080/3298 [11:57<26:40,  1.39it/s]\u001b[A\n",
            " 33%|███▎      | 1081/3298 [11:57<24:39,  1.50it/s]\u001b[A\n",
            " 33%|███▎      | 1082/3298 [11:58<24:28,  1.51it/s]\u001b[A\n",
            " 33%|███▎      | 1083/3298 [11:59<24:26,  1.51it/s]\u001b[A\n",
            " 33%|███▎      | 1084/3298 [11:59<24:34,  1.50it/s]\u001b[A\n",
            " 33%|███▎      | 1085/3298 [12:00<24:49,  1.49it/s]\u001b[A\n",
            " 33%|███▎      | 1086/3298 [12:01<26:07,  1.41it/s]\u001b[A\n",
            " 33%|███▎      | 1087/3298 [12:02<27:02,  1.36it/s]\u001b[A\n",
            " 33%|███▎      | 1088/3298 [12:02<27:36,  1.33it/s]\u001b[A\n",
            " 33%|███▎      | 1089/3298 [12:03<26:41,  1.38it/s]\u001b[A\n",
            " 33%|███▎      | 1090/3298 [12:04<27:29,  1.34it/s]\u001b[A\n",
            " 33%|███▎      | 1091/3298 [12:05<29:39,  1.24it/s]\u001b[A\n",
            " 33%|███▎      | 1092/3298 [12:06<28:00,  1.31it/s]\u001b[A\n",
            " 33%|███▎      | 1093/3298 [12:06<28:25,  1.29it/s]\u001b[A\n",
            " 33%|███▎      | 1094/3298 [12:07<28:31,  1.29it/s]\u001b[A\n",
            " 33%|███▎      | 1095/3298 [12:08<27:02,  1.36it/s]\u001b[A\n",
            " 33%|███▎      | 1096/3298 [12:09<27:50,  1.32it/s]\u001b[A\n",
            " 33%|███▎      | 1097/3298 [12:09<26:57,  1.36it/s]\u001b[A\n",
            " 33%|███▎      | 1098/3298 [12:10<26:02,  1.41it/s]\u001b[A\n",
            " 33%|███▎      | 1099/3298 [12:11<25:44,  1.42it/s]\u001b[A\n",
            " 33%|███▎      | 1100/3298 [12:11<25:12,  1.45it/s]\u001b[A\n",
            " 33%|███▎      | 1101/3298 [12:12<24:49,  1.48it/s]\u001b[A\n",
            " 33%|███▎      | 1102/3298 [12:13<24:40,  1.48it/s]\u001b[A\n",
            " 33%|███▎      | 1103/3298 [12:13<24:39,  1.48it/s]\u001b[A\n",
            " 33%|███▎      | 1104/3298 [12:14<24:22,  1.50it/s]\u001b[A\n",
            " 34%|███▎      | 1105/3298 [12:15<25:52,  1.41it/s]\u001b[A\n",
            " 34%|███▎      | 1106/3298 [12:15<25:19,  1.44it/s]\u001b[A\n",
            " 34%|███▎      | 1107/3298 [12:16<24:50,  1.47it/s]\u001b[A\n",
            " 34%|███▎      | 1108/3298 [12:17<24:44,  1.47it/s]\u001b[A\n",
            " 34%|███▎      | 1109/3298 [12:18<26:08,  1.40it/s]\u001b[A\n",
            " 34%|███▎      | 1110/3298 [12:18<25:25,  1.43it/s]\u001b[A\n",
            " 34%|███▎      | 1111/3298 [12:19<27:59,  1.30it/s]\u001b[A\n",
            " 34%|███▎      | 1112/3298 [12:20<28:23,  1.28it/s]\u001b[A\n",
            " 34%|███▎      | 1113/3298 [12:21<27:08,  1.34it/s]\u001b[A\n",
            " 34%|███▍      | 1114/3298 [12:21<27:44,  1.31it/s]\u001b[A\n",
            " 34%|███▍      | 1115/3298 [12:22<26:43,  1.36it/s]\u001b[A\n",
            " 34%|███▍      | 1116/3298 [12:23<26:07,  1.39it/s]\u001b[A\n",
            " 34%|███▍      | 1117/3298 [12:23<25:31,  1.42it/s]\u001b[A\n",
            " 34%|███▍      | 1118/3298 [12:24<24:59,  1.45it/s]\u001b[A\n",
            " 34%|███▍      | 1119/3298 [12:25<24:43,  1.47it/s]\u001b[A\n",
            " 34%|███▍      | 1120/3298 [12:25<24:38,  1.47it/s]\u001b[A\n",
            " 34%|███▍      | 1121/3298 [12:26<24:19,  1.49it/s]\u001b[A\n",
            " 34%|███▍      | 1122/3298 [12:27<27:03,  1.34it/s]\u001b[A\n",
            " 34%|███▍      | 1123/3298 [12:28<29:19,  1.24it/s]\u001b[A\n",
            " 34%|███▍      | 1124/3298 [12:29<30:49,  1.18it/s]\u001b[A\n",
            " 34%|███▍      | 1125/3298 [12:30<31:54,  1.13it/s]\u001b[A\n",
            " 34%|███▍      | 1126/3298 [12:30<27:59,  1.29it/s]\u001b[A\n",
            " 34%|███▍      | 1127/3298 [12:31<26:52,  1.35it/s]\u001b[A\n",
            " 34%|███▍      | 1128/3298 [12:32<25:59,  1.39it/s]\u001b[A\n",
            " 34%|███▍      | 1129/3298 [12:32<25:23,  1.42it/s]\u001b[A\n",
            " 34%|███▍      | 1130/3298 [12:33<26:19,  1.37it/s]\u001b[A\n",
            " 34%|███▍      | 1131/3298 [12:34<25:36,  1.41it/s]\u001b[A\n",
            " 34%|███▍      | 1132/3298 [12:34<25:04,  1.44it/s]\u001b[A\n",
            " 34%|███▍      | 1133/3298 [12:35<26:05,  1.38it/s]\u001b[A\n",
            " 34%|███▍      | 1134/3298 [12:36<25:24,  1.42it/s]\u001b[A\n",
            " 34%|███▍      | 1135/3298 [12:37<24:57,  1.44it/s]\u001b[A\n",
            " 34%|███▍      | 1136/3298 [12:37<24:34,  1.47it/s]\u001b[A\n",
            " 34%|███▍      | 1137/3298 [12:38<24:23,  1.48it/s]\u001b[A\n",
            " 35%|███▍      | 1138/3298 [12:39<24:14,  1.49it/s]\u001b[A\n",
            " 35%|███▍      | 1139/3298 [12:39<24:03,  1.50it/s]\u001b[A\n",
            " 35%|███▍      | 1140/3298 [12:40<24:11,  1.49it/s]\u001b[A\n",
            " 35%|███▍      | 1141/3298 [12:41<24:00,  1.50it/s]\u001b[A\n",
            " 35%|███▍      | 1142/3298 [12:41<23:51,  1.51it/s]\u001b[A\n",
            " 35%|███▍      | 1143/3298 [12:42<23:50,  1.51it/s]\u001b[A\n",
            " 35%|███▍      | 1144/3298 [12:42<23:34,  1.52it/s]\u001b[A\n",
            " 35%|███▍      | 1145/3298 [12:43<21:56,  1.64it/s]\u001b[A\n",
            " 35%|███▍      | 1146/3298 [12:44<22:34,  1.59it/s]\u001b[A\n",
            " 35%|███▍      | 1147/3298 [12:44<21:06,  1.70it/s]\u001b[A\n",
            " 35%|███▍      | 1148/3298 [12:45<20:11,  1.78it/s]\u001b[A\n",
            " 35%|███▍      | 1149/3298 [12:45<19:30,  1.84it/s]\u001b[A\n",
            " 35%|███▍      | 1150/3298 [12:46<20:38,  1.73it/s]\u001b[A\n",
            " 35%|███▍      | 1151/3298 [12:46<21:32,  1.66it/s]\u001b[A\n",
            " 35%|███▍      | 1152/3298 [12:47<23:54,  1.50it/s]\u001b[A\n",
            " 35%|███▍      | 1153/3298 [12:48<23:52,  1.50it/s]\u001b[A\n",
            " 35%|███▍      | 1154/3298 [12:49<26:32,  1.35it/s]\u001b[A\n",
            " 35%|███▌      | 1155/3298 [12:50<27:09,  1.32it/s]\u001b[A\n",
            " 35%|███▌      | 1156/3298 [12:50<26:03,  1.37it/s]\u001b[A\n",
            " 35%|███▌      | 1157/3298 [12:51<25:11,  1.42it/s]\u001b[A\n",
            " 35%|███▌      | 1158/3298 [12:52<24:32,  1.45it/s]\u001b[A\n",
            " 35%|███▌      | 1159/3298 [12:52<24:19,  1.47it/s]\u001b[A\n",
            " 35%|███▌      | 1160/3298 [12:53<24:01,  1.48it/s]\u001b[A\n",
            " 35%|███▌      | 1161/3298 [12:54<23:52,  1.49it/s]\u001b[A\n",
            " 35%|███▌      | 1162/3298 [12:54<23:44,  1.50it/s]\u001b[A\n",
            " 35%|███▌      | 1163/3298 [12:55<22:05,  1.61it/s]\u001b[A\n",
            " 35%|███▌      | 1164/3298 [12:55<22:32,  1.58it/s]\u001b[A\n",
            " 35%|███▌      | 1165/3298 [12:56<22:48,  1.56it/s]\u001b[A\n",
            " 35%|███▌      | 1166/3298 [12:57<22:56,  1.55it/s]\u001b[A\n",
            " 35%|███▌      | 1167/3298 [12:58<24:23,  1.46it/s]\u001b[A\n",
            " 35%|███▌      | 1168/3298 [12:58<25:30,  1.39it/s]\u001b[A\n",
            " 35%|███▌      | 1169/3298 [12:59<24:44,  1.43it/s]\u001b[A\n",
            " 35%|███▌      | 1170/3298 [13:00<24:35,  1.44it/s]\u001b[A\n",
            " 36%|███▌      | 1171/3298 [13:00<24:22,  1.45it/s]\u001b[A\n",
            " 36%|███▌      | 1172/3298 [13:01<25:25,  1.39it/s]\u001b[A\n",
            " 36%|███▌      | 1173/3298 [13:02<23:21,  1.52it/s]\u001b[A\n",
            " 36%|███▌      | 1174/3298 [13:02<23:25,  1.51it/s]\u001b[A\n",
            " 36%|███▌      | 1175/3298 [13:03<26:24,  1.34it/s]\u001b[A\n",
            " 36%|███▌      | 1176/3298 [13:04<28:23,  1.25it/s]\u001b[A\n",
            " 36%|███▌      | 1177/3298 [13:05<26:48,  1.32it/s]\u001b[A\n",
            " 36%|███▌      | 1178/3298 [13:06<25:44,  1.37it/s]\u001b[A\n",
            " 36%|███▌      | 1179/3298 [13:06<25:03,  1.41it/s]\u001b[A\n",
            " 36%|███▌      | 1180/3298 [13:07<24:28,  1.44it/s]\u001b[A\n",
            " 36%|███▌      | 1181/3298 [13:08<24:25,  1.44it/s]\u001b[A\n",
            " 36%|███▌      | 1182/3298 [13:08<23:55,  1.47it/s]\u001b[A\n",
            " 36%|███▌      | 1183/3298 [13:09<26:26,  1.33it/s]\u001b[A\n",
            " 36%|███▌      | 1184/3298 [13:10<24:01,  1.47it/s]\u001b[A\n",
            " 36%|███▌      | 1185/3298 [13:10<25:01,  1.41it/s]\u001b[A\n",
            " 36%|███▌      | 1186/3298 [13:11<24:16,  1.45it/s]\u001b[A\n",
            " 36%|███▌      | 1187/3298 [13:12<23:52,  1.47it/s]\u001b[A\n",
            " 36%|███▌      | 1188/3298 [13:12<23:26,  1.50it/s]\u001b[A\n",
            " 36%|███▌      | 1189/3298 [13:13<23:15,  1.51it/s]\u001b[A\n",
            " 36%|███▌      | 1190/3298 [13:14<21:45,  1.62it/s]\u001b[A\n",
            " 36%|███▌      | 1191/3298 [13:14<21:58,  1.60it/s]\u001b[A\n",
            " 36%|███▌      | 1192/3298 [13:15<22:13,  1.58it/s]\u001b[A\n",
            " 36%|███▌      | 1193/3298 [13:15<22:21,  1.57it/s]\u001b[A\n",
            " 36%|███▌      | 1194/3298 [13:16<22:20,  1.57it/s]\u001b[A\n",
            " 36%|███▌      | 1195/3298 [13:17<22:34,  1.55it/s]\u001b[A\n",
            " 36%|███▋      | 1196/3298 [13:17<22:45,  1.54it/s]\u001b[A\n",
            " 36%|███▋      | 1197/3298 [13:18<22:35,  1.55it/s]\u001b[A\n",
            " 36%|███▋      | 1198/3298 [13:19<22:39,  1.54it/s]\u001b[A\n",
            " 36%|███▋      | 1199/3298 [13:19<22:44,  1.54it/s]\u001b[A\n",
            " 36%|███▋      | 1200/3298 [13:20<22:44,  1.54it/s]\u001b[A\n",
            " 36%|███▋      | 1201/3298 [13:21<22:50,  1.53it/s]\u001b[A\n",
            " 36%|███▋      | 1202/3298 [13:21<23:03,  1.51it/s]\u001b[A\n",
            " 36%|███▋      | 1203/3298 [13:22<22:57,  1.52it/s]\u001b[A\n",
            " 37%|███▋      | 1204/3298 [13:23<21:35,  1.62it/s]\u001b[A\n",
            " 37%|███▋      | 1205/3298 [13:23<21:58,  1.59it/s]\u001b[A\n",
            " 37%|███▋      | 1206/3298 [13:24<25:09,  1.39it/s]\u001b[A\n",
            " 37%|███▋      | 1207/3298 [13:25<23:06,  1.51it/s]\u001b[A\n",
            " 37%|███▋      | 1208/3298 [13:25<21:36,  1.61it/s]\u001b[A\n",
            " 37%|███▋      | 1209/3298 [13:26<23:19,  1.49it/s]\u001b[A\n",
            " 37%|███▋      | 1210/3298 [13:27<23:18,  1.49it/s]\u001b[A\n",
            " 37%|███▋      | 1211/3298 [13:27<24:42,  1.41it/s]\u001b[A\n",
            " 37%|███▋      | 1212/3298 [13:28<27:02,  1.29it/s]\u001b[A\n",
            " 37%|███▋      | 1213/3298 [13:29<27:13,  1.28it/s]\u001b[A\n",
            " 37%|███▋      | 1214/3298 [13:30<28:43,  1.21it/s]\u001b[A\n",
            " 37%|███▋      | 1215/3298 [13:31<28:21,  1.22it/s]\u001b[A\n",
            " 37%|███▋      | 1216/3298 [13:32<28:13,  1.23it/s]\u001b[A\n",
            " 37%|███▋      | 1217/3298 [13:33<29:23,  1.18it/s]\u001b[A\n",
            " 37%|███▋      | 1218/3298 [13:33<28:53,  1.20it/s]\u001b[A\n",
            " 37%|███▋      | 1219/3298 [13:34<27:10,  1.27it/s]\u001b[A\n",
            " 37%|███▋      | 1220/3298 [13:35<27:09,  1.28it/s]\u001b[A\n",
            " 37%|███▋      | 1221/3298 [13:35<24:33,  1.41it/s]\u001b[A\n",
            " 37%|███▋      | 1222/3298 [13:36<23:57,  1.44it/s]\u001b[A\n",
            " 37%|███▋      | 1223/3298 [13:37<26:11,  1.32it/s]\u001b[A\n",
            " 37%|███▋      | 1224/3298 [13:38<29:36,  1.17it/s]\u001b[A\n",
            " 37%|███▋      | 1225/3298 [13:39<28:54,  1.20it/s]\u001b[A\n",
            " 37%|███▋      | 1226/3298 [13:40<28:34,  1.21it/s]\u001b[A\n",
            " 37%|███▋      | 1227/3298 [13:40<26:51,  1.28it/s]\u001b[A\n",
            " 37%|███▋      | 1228/3298 [13:41<25:38,  1.35it/s]\u001b[A\n",
            " 37%|███▋      | 1229/3298 [13:42<24:38,  1.40it/s]\u001b[A\n",
            " 37%|███▋      | 1230/3298 [13:42<23:52,  1.44it/s]\u001b[A\n",
            " 37%|███▋      | 1231/3298 [13:43<23:20,  1.48it/s]\u001b[A\n",
            " 37%|███▋      | 1232/3298 [13:44<22:56,  1.50it/s]\u001b[A\n",
            " 37%|███▋      | 1233/3298 [13:44<22:47,  1.51it/s]\u001b[A\n",
            " 37%|███▋      | 1234/3298 [13:45<22:39,  1.52it/s]\u001b[A\n",
            " 37%|███▋      | 1235/3298 [13:45<22:32,  1.53it/s]\u001b[A\n",
            " 37%|███▋      | 1236/3298 [13:46<22:31,  1.53it/s]\u001b[A\n",
            " 38%|███▊      | 1237/3298 [13:47<23:54,  1.44it/s]\u001b[A\n",
            " 38%|███▊      | 1238/3298 [13:48<23:30,  1.46it/s]\u001b[A\n",
            " 38%|███▊      | 1239/3298 [13:48<23:17,  1.47it/s]\u001b[A\n",
            " 38%|███▊      | 1240/3298 [13:49<24:17,  1.41it/s]\u001b[A\n",
            " 38%|███▊      | 1241/3298 [13:50<23:39,  1.45it/s]\u001b[A\n",
            " 38%|███▊      | 1242/3298 [13:50<23:11,  1.48it/s]\u001b[A\n",
            " 38%|███▊      | 1243/3298 [13:51<22:42,  1.51it/s]\u001b[A\n",
            " 38%|███▊      | 1244/3298 [13:52<22:38,  1.51it/s]\u001b[A\n",
            " 38%|███▊      | 1245/3298 [13:52<22:36,  1.51it/s]\u001b[A\n",
            " 38%|███▊      | 1246/3298 [13:53<22:25,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1247/3298 [13:54<22:29,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1248/3298 [13:54<22:24,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1249/3298 [13:55<22:22,  1.53it/s]\u001b[A\n",
            " 38%|███▊      | 1250/3298 [13:56<22:31,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1251/3298 [13:56<22:24,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1252/3298 [13:57<22:28,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1253/3298 [13:58<22:21,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1254/3298 [13:58<22:14,  1.53it/s]\u001b[A\n",
            " 38%|███▊      | 1255/3298 [13:59<22:14,  1.53it/s]\u001b[A\n",
            " 38%|███▊      | 1256/3298 [14:00<22:30,  1.51it/s]\u001b[A\n",
            " 38%|███▊      | 1257/3298 [14:00<22:21,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1258/3298 [14:01<22:25,  1.52it/s]\u001b[A\n",
            " 38%|███▊      | 1259/3298 [14:01<22:35,  1.50it/s]\u001b[A\n",
            " 38%|███▊      | 1260/3298 [14:02<23:58,  1.42it/s]\u001b[A\n",
            " 38%|███▊      | 1261/3298 [14:03<23:29,  1.45it/s]\u001b[A\n",
            " 38%|███▊      | 1262/3298 [14:04<23:18,  1.46it/s]\u001b[A\n",
            " 38%|███▊      | 1263/3298 [14:04<22:57,  1.48it/s]\u001b[A\n",
            " 38%|███▊      | 1264/3298 [14:05<22:39,  1.50it/s]\u001b[A\n",
            " 38%|███▊      | 1265/3298 [14:06<22:36,  1.50it/s]\u001b[A\n",
            " 38%|███▊      | 1266/3298 [14:06<22:44,  1.49it/s]\u001b[A\n",
            " 38%|███▊      | 1267/3298 [14:07<22:37,  1.50it/s]\u001b[A\n",
            " 38%|███▊      | 1268/3298 [14:08<24:07,  1.40it/s]\u001b[A\n",
            " 38%|███▊      | 1269/3298 [14:08<23:39,  1.43it/s]\u001b[A\n",
            " 39%|███▊      | 1270/3298 [14:09<23:22,  1.45it/s]\u001b[A\n",
            " 39%|███▊      | 1271/3298 [14:10<23:15,  1.45it/s]\u001b[A\n",
            " 39%|███▊      | 1272/3298 [14:10<22:58,  1.47it/s]\u001b[A\n",
            " 39%|███▊      | 1273/3298 [14:11<22:44,  1.48it/s]\u001b[A\n",
            " 39%|███▊      | 1274/3298 [14:12<22:32,  1.50it/s]\u001b[A\n",
            " 39%|███▊      | 1275/3298 [14:12<20:58,  1.61it/s]\u001b[A\n",
            " 39%|███▊      | 1276/3298 [14:13<21:18,  1.58it/s]\u001b[A\n",
            " 39%|███▊      | 1277/3298 [14:14<21:49,  1.54it/s]\u001b[A\n",
            " 39%|███▉      | 1278/3298 [14:14<22:00,  1.53it/s]\u001b[A\n",
            " 39%|███▉      | 1279/3298 [14:15<23:29,  1.43it/s]\u001b[A\n",
            " 39%|███▉      | 1280/3298 [14:16<26:01,  1.29it/s]\u001b[A\n",
            " 39%|███▉      | 1281/3298 [14:17<27:50,  1.21it/s]\u001b[A\n",
            " 39%|███▉      | 1282/3298 [14:18<27:33,  1.22it/s]\u001b[A\n",
            " 39%|███▉      | 1283/3298 [14:19<27:14,  1.23it/s]\u001b[A\n",
            " 39%|███▉      | 1284/3298 [14:19<25:40,  1.31it/s]\u001b[A\n",
            " 39%|███▉      | 1285/3298 [14:20<25:57,  1.29it/s]\u001b[A\n",
            " 39%|███▉      | 1286/3298 [14:21<27:21,  1.23it/s]\u001b[A\n",
            " 39%|███▉      | 1287/3298 [14:22<28:38,  1.17it/s]\u001b[A\n",
            " 39%|███▉      | 1288/3298 [14:23<28:10,  1.19it/s]\u001b[A\n",
            " 39%|███▉      | 1289/3298 [14:24<28:55,  1.16it/s]\u001b[A\n",
            " 39%|███▉      | 1290/3298 [14:24<28:19,  1.18it/s]\u001b[A\n",
            " 39%|███▉      | 1291/3298 [14:25<27:53,  1.20it/s]\u001b[A\n",
            " 39%|███▉      | 1292/3298 [14:26<27:28,  1.22it/s]\u001b[A\n",
            " 39%|███▉      | 1293/3298 [14:27<25:48,  1.29it/s]\u001b[A\n",
            " 39%|███▉      | 1294/3298 [14:27<23:18,  1.43it/s]\u001b[A\n",
            " 39%|███▉      | 1295/3298 [14:28<21:48,  1.53it/s]\u001b[A\n",
            " 39%|███▉      | 1296/3298 [14:29<23:03,  1.45it/s]\u001b[A\n",
            " 39%|███▉      | 1297/3298 [14:29<22:39,  1.47it/s]\u001b[A\n",
            " 39%|███▉      | 1298/3298 [14:30<22:19,  1.49it/s]\u001b[A\n",
            " 39%|███▉      | 1299/3298 [14:30<20:39,  1.61it/s]\u001b[A\n",
            " 39%|███▉      | 1300/3298 [14:31<20:58,  1.59it/s]\u001b[A\n",
            " 39%|███▉      | 1301/3298 [14:32<21:26,  1.55it/s]\u001b[A\n",
            " 39%|███▉      | 1302/3298 [14:33<24:19,  1.37it/s]\u001b[A\n",
            " 40%|███▉      | 1303/3298 [14:34<27:41,  1.20it/s]\u001b[A\n",
            " 40%|███▉      | 1304/3298 [14:34<25:58,  1.28it/s]\u001b[A\n",
            " 40%|███▉      | 1305/3298 [14:35<24:44,  1.34it/s]\u001b[A\n",
            " 40%|███▉      | 1306/3298 [14:36<22:31,  1.47it/s]\u001b[A\n",
            " 40%|███▉      | 1307/3298 [14:36<22:25,  1.48it/s]\u001b[A\n",
            " 40%|███▉      | 1308/3298 [14:37<23:30,  1.41it/s]\u001b[A\n",
            " 40%|███▉      | 1309/3298 [14:38<24:12,  1.37it/s]\u001b[A\n",
            " 40%|███▉      | 1310/3298 [14:39<25:00,  1.33it/s]\u001b[A\n",
            " 40%|███▉      | 1311/3298 [14:39<24:16,  1.36it/s]\u001b[A\n",
            " 40%|███▉      | 1312/3298 [14:40<25:09,  1.32it/s]\u001b[A\n",
            " 40%|███▉      | 1313/3298 [14:41<25:35,  1.29it/s]\u001b[A\n",
            " 40%|███▉      | 1314/3298 [14:42<24:36,  1.34it/s]\u001b[A\n",
            " 40%|███▉      | 1315/3298 [14:42<26:23,  1.25it/s]\u001b[A\n",
            " 40%|███▉      | 1316/3298 [14:43<26:22,  1.25it/s]\u001b[A\n",
            " 40%|███▉      | 1317/3298 [14:44<27:44,  1.19it/s]\u001b[A\n",
            " 40%|███▉      | 1318/3298 [14:45<27:13,  1.21it/s]\u001b[A\n",
            " 40%|███▉      | 1319/3298 [14:46<28:11,  1.17it/s]\u001b[A\n",
            " 40%|████      | 1320/3298 [14:47<27:38,  1.19it/s]\u001b[A\n",
            " 40%|████      | 1321/3298 [14:48<28:36,  1.15it/s]\u001b[A\n",
            " 40%|████      | 1322/3298 [14:48<28:00,  1.18it/s]\u001b[A\n",
            " 40%|████      | 1323/3298 [14:49<24:46,  1.33it/s]\u001b[A\n",
            " 40%|████      | 1324/3298 [14:50<23:46,  1.38it/s]\u001b[A\n",
            " 40%|████      | 1325/3298 [14:50<22:54,  1.44it/s]\u001b[A\n",
            " 40%|████      | 1326/3298 [14:51<22:19,  1.47it/s]\u001b[A\n",
            " 40%|████      | 1327/3298 [14:52<24:39,  1.33it/s]\u001b[A\n",
            " 40%|████      | 1328/3298 [14:52<23:38,  1.39it/s]\u001b[A\n",
            " 40%|████      | 1329/3298 [14:53<22:46,  1.44it/s]\u001b[A\n",
            " 40%|████      | 1330/3298 [14:54<23:46,  1.38it/s]\u001b[A\n",
            " 40%|████      | 1331/3298 [14:55<23:05,  1.42it/s]\u001b[A\n",
            " 40%|████      | 1332/3298 [14:55<22:34,  1.45it/s]\u001b[A\n",
            " 40%|████      | 1333/3298 [14:56<22:02,  1.49it/s]\u001b[A\n",
            " 40%|████      | 1334/3298 [14:56<21:43,  1.51it/s]\u001b[A\n",
            " 40%|████      | 1335/3298 [14:57<21:28,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1336/3298 [14:58<21:27,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1337/3298 [14:58<21:29,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1338/3298 [15:00<26:47,  1.22it/s]\u001b[A\n",
            " 41%|████      | 1339/3298 [15:00<23:50,  1.37it/s]\u001b[A\n",
            " 41%|████      | 1340/3298 [15:01<25:48,  1.26it/s]\u001b[A\n",
            " 41%|████      | 1341/3298 [15:02<24:35,  1.33it/s]\u001b[A\n",
            " 41%|████      | 1342/3298 [15:02<23:56,  1.36it/s]\u001b[A\n",
            " 41%|████      | 1343/3298 [15:03<24:35,  1.33it/s]\u001b[A\n",
            " 41%|████      | 1344/3298 [15:04<23:39,  1.38it/s]\u001b[A\n",
            " 41%|████      | 1345/3298 [15:04<21:41,  1.50it/s]\u001b[A\n",
            " 41%|████      | 1346/3298 [15:05<21:38,  1.50it/s]\u001b[A\n",
            " 41%|████      | 1347/3298 [15:06<21:37,  1.50it/s]\u001b[A\n",
            " 41%|████      | 1348/3298 [15:06<21:24,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1349/3298 [15:07<19:55,  1.63it/s]\u001b[A\n",
            " 41%|████      | 1350/3298 [15:07<19:06,  1.70it/s]\u001b[A\n",
            " 41%|████      | 1351/3298 [15:08<19:40,  1.65it/s]\u001b[A\n",
            " 41%|████      | 1352/3298 [15:09<21:23,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1353/3298 [15:10<21:22,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1354/3298 [15:10<21:30,  1.51it/s]\u001b[A\n",
            " 41%|████      | 1355/3298 [15:11<21:22,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1356/3298 [15:12<21:15,  1.52it/s]\u001b[A\n",
            " 41%|████      | 1357/3298 [15:12<19:50,  1.63it/s]\u001b[A\n",
            " 41%|████      | 1358/3298 [15:13<19:01,  1.70it/s]\u001b[A\n",
            " 41%|████      | 1359/3298 [15:13<19:34,  1.65it/s]\u001b[A\n",
            " 41%|████      | 1360/3298 [15:14<20:18,  1.59it/s]\u001b[A\n",
            " 41%|████▏     | 1361/3298 [15:15<20:29,  1.58it/s]\u001b[A\n",
            " 41%|████▏     | 1362/3298 [15:15<20:35,  1.57it/s]\u001b[A\n",
            " 41%|████▏     | 1363/3298 [15:16<21:56,  1.47it/s]\u001b[A\n",
            " 41%|████▏     | 1364/3298 [15:17<21:44,  1.48it/s]\u001b[A\n",
            " 41%|████▏     | 1365/3298 [15:17<21:43,  1.48it/s]\u001b[A\n",
            " 41%|████▏     | 1366/3298 [15:18<22:58,  1.40it/s]\u001b[A\n",
            " 41%|████▏     | 1367/3298 [15:19<22:33,  1.43it/s]\u001b[A\n",
            " 41%|████▏     | 1368/3298 [15:20<23:29,  1.37it/s]\u001b[A\n",
            " 42%|████▏     | 1369/3298 [15:20<23:59,  1.34it/s]\u001b[A\n",
            " 42%|████▏     | 1370/3298 [15:21<23:09,  1.39it/s]\u001b[A\n",
            " 42%|████▏     | 1371/3298 [15:22<23:47,  1.35it/s]\u001b[A\n",
            " 42%|████▏     | 1372/3298 [15:23<23:18,  1.38it/s]\u001b[A\n",
            " 42%|████▏     | 1373/3298 [15:23<22:47,  1.41it/s]\u001b[A\n",
            " 42%|████▏     | 1374/3298 [15:24<22:15,  1.44it/s]\u001b[A\n",
            " 42%|████▏     | 1375/3298 [15:25<23:15,  1.38it/s]\u001b[A\n",
            " 42%|████▏     | 1376/3298 [15:25<23:53,  1.34it/s]\u001b[A\n",
            " 42%|████▏     | 1377/3298 [15:26<22:59,  1.39it/s]\u001b[A\n",
            " 42%|████▏     | 1378/3298 [15:27<22:24,  1.43it/s]\u001b[A\n",
            " 42%|████▏     | 1379/3298 [15:28<23:26,  1.36it/s]\u001b[A\n",
            " 42%|████▏     | 1380/3298 [15:28<25:28,  1.26it/s]\u001b[A\n",
            " 42%|████▏     | 1381/3298 [15:29<25:36,  1.25it/s]\u001b[A\n",
            " 42%|████▏     | 1382/3298 [15:30<27:01,  1.18it/s]\u001b[A\n",
            " 42%|████▏     | 1383/3298 [15:31<26:31,  1.20it/s]\u001b[A\n",
            " 42%|████▏     | 1384/3298 [15:32<26:32,  1.20it/s]\u001b[A\n",
            " 42%|████▏     | 1385/3298 [15:33<26:14,  1.22it/s]\u001b[A\n",
            " 42%|████▏     | 1386/3298 [15:33<25:55,  1.23it/s]\u001b[A\n",
            " 42%|████▏     | 1387/3298 [15:34<27:09,  1.17it/s]\u001b[A\n",
            " 42%|████▏     | 1388/3298 [15:35<26:36,  1.20it/s]\u001b[A\n",
            " 42%|████▏     | 1389/3298 [15:36<26:04,  1.22it/s]\u001b[A\n",
            " 42%|████▏     | 1390/3298 [15:37<25:38,  1.24it/s]\u001b[A\n",
            " 42%|████▏     | 1391/3298 [15:38<26:42,  1.19it/s]\u001b[A\n",
            " 42%|████▏     | 1392/3298 [15:38<24:57,  1.27it/s]\u001b[A\n",
            " 42%|████▏     | 1393/3298 [15:39<25:01,  1.27it/s]\u001b[A\n",
            " 42%|████▏     | 1394/3298 [15:40<23:38,  1.34it/s]\u001b[A\n",
            " 42%|████▏     | 1395/3298 [15:41<24:21,  1.30it/s]\u001b[A\n",
            " 42%|████▏     | 1396/3298 [15:42<26:08,  1.21it/s]\u001b[A\n",
            " 42%|████▏     | 1397/3298 [15:42<26:06,  1.21it/s]\u001b[A\n",
            " 42%|████▏     | 1398/3298 [15:43<25:50,  1.23it/s]\u001b[A\n",
            " 42%|████▏     | 1399/3298 [15:44<27:06,  1.17it/s]\u001b[A\n",
            " 42%|████▏     | 1400/3298 [15:45<26:35,  1.19it/s]\u001b[A\n",
            " 42%|████▏     | 1401/3298 [15:46<26:29,  1.19it/s]\u001b[A\n",
            " 43%|████▎     | 1402/3298 [15:46<24:43,  1.28it/s]\u001b[A\n",
            " 43%|████▎     | 1403/3298 [15:47<22:18,  1.42it/s]\u001b[A\n",
            " 43%|████▎     | 1404/3298 [15:47<20:36,  1.53it/s]\u001b[A\n",
            " 43%|████▎     | 1405/3298 [15:48<20:37,  1.53it/s]\u001b[A\n",
            " 43%|████▎     | 1406/3298 [15:49<20:30,  1.54it/s]\u001b[A\n",
            " 43%|████▎     | 1407/3298 [15:49<20:27,  1.54it/s]\u001b[A\n",
            " 43%|████▎     | 1408/3298 [15:50<21:39,  1.45it/s]\u001b[A\n",
            " 43%|████▎     | 1409/3298 [15:51<21:12,  1.48it/s]\u001b[A\n",
            " 43%|████▎     | 1410/3298 [15:52<22:09,  1.42it/s]\u001b[A\n",
            " 43%|████▎     | 1411/3298 [15:52<21:32,  1.46it/s]\u001b[A\n",
            " 43%|████▎     | 1412/3298 [15:53<21:05,  1.49it/s]\u001b[A\n",
            " 43%|████▎     | 1413/3298 [15:53<19:54,  1.58it/s]\u001b[A\n",
            " 43%|████▎     | 1414/3298 [15:54<19:57,  1.57it/s]\u001b[A\n",
            " 43%|████▎     | 1415/3298 [15:55<23:30,  1.34it/s]\u001b[A\n",
            " 43%|████▎     | 1416/3298 [15:56<22:34,  1.39it/s]\u001b[A\n",
            " 43%|████▎     | 1417/3298 [15:56<21:47,  1.44it/s]\u001b[A\n",
            " 43%|████▎     | 1418/3298 [15:57<22:20,  1.40it/s]\u001b[A\n",
            " 43%|████▎     | 1419/3298 [15:58<21:34,  1.45it/s]\u001b[A\n",
            " 43%|████▎     | 1420/3298 [15:58<21:12,  1.48it/s]\u001b[A\n",
            " 43%|████▎     | 1421/3298 [15:59<20:44,  1.51it/s]\u001b[A\n",
            " 43%|████▎     | 1422/3298 [16:00<19:17,  1.62it/s]\u001b[A\n",
            " 43%|████▎     | 1423/3298 [16:00<19:22,  1.61it/s]\u001b[A\n",
            " 43%|████▎     | 1424/3298 [16:01<18:10,  1.72it/s]\u001b[A\n",
            " 43%|████▎     | 1425/3298 [16:01<17:17,  1.81it/s]\u001b[A\n",
            " 43%|████▎     | 1426/3298 [16:02<18:04,  1.73it/s]\u001b[A\n",
            " 43%|████▎     | 1427/3298 [16:03<19:53,  1.57it/s]\u001b[A\n",
            " 43%|████▎     | 1428/3298 [16:03<19:58,  1.56it/s]\u001b[A\n",
            " 43%|████▎     | 1429/3298 [16:04<19:53,  1.57it/s]\u001b[A\n",
            " 43%|████▎     | 1430/3298 [16:04<18:39,  1.67it/s]\u001b[A\n",
            " 43%|████▎     | 1431/3298 [16:05<21:40,  1.44it/s]\u001b[A\n",
            " 43%|████▎     | 1432/3298 [16:06<19:48,  1.57it/s]\u001b[A\n",
            " 43%|████▎     | 1433/3298 [16:06<18:24,  1.69it/s]\u001b[A\n",
            " 43%|████▎     | 1434/3298 [16:07<19:53,  1.56it/s]\u001b[A\n",
            " 44%|████▎     | 1435/3298 [16:08<21:13,  1.46it/s]\u001b[A\n",
            " 44%|████▎     | 1436/3298 [16:08<20:51,  1.49it/s]\u001b[A\n",
            " 44%|████▎     | 1437/3298 [16:09<22:55,  1.35it/s]\u001b[A\n",
            " 44%|████▎     | 1438/3298 [16:10<21:52,  1.42it/s]\u001b[A\n",
            " 44%|████▎     | 1439/3298 [16:11<21:08,  1.47it/s]\u001b[A\n",
            " 44%|████▎     | 1440/3298 [16:11<20:40,  1.50it/s]\u001b[A\n",
            " 44%|████▎     | 1441/3298 [16:12<21:42,  1.43it/s]\u001b[A\n",
            " 44%|████▎     | 1442/3298 [16:13<21:05,  1.47it/s]\u001b[A\n",
            " 44%|████▍     | 1443/3298 [16:13<22:02,  1.40it/s]\u001b[A\n",
            " 44%|████▍     | 1444/3298 [16:14<20:08,  1.53it/s]\u001b[A\n",
            " 44%|████▍     | 1445/3298 [16:15<20:12,  1.53it/s]\u001b[A\n",
            " 44%|████▍     | 1446/3298 [16:15<21:25,  1.44it/s]\u001b[A\n",
            " 44%|████▍     | 1447/3298 [16:16<20:51,  1.48it/s]\u001b[A\n",
            " 44%|████▍     | 1448/3298 [16:17<20:32,  1.50it/s]\u001b[A\n",
            " 44%|████▍     | 1449/3298 [16:17<20:18,  1.52it/s]\u001b[A\n",
            " 44%|████▍     | 1450/3298 [16:18<18:54,  1.63it/s]\u001b[A\n",
            " 44%|████▍     | 1451/3298 [16:18<19:14,  1.60it/s]\u001b[A\n",
            " 44%|████▍     | 1452/3298 [16:19<19:15,  1.60it/s]\u001b[A\n",
            " 44%|████▍     | 1453/3298 [16:20<20:35,  1.49it/s]\u001b[A\n",
            " 44%|████▍     | 1454/3298 [16:21<20:14,  1.52it/s]\u001b[A\n",
            " 44%|████▍     | 1455/3298 [16:21<21:22,  1.44it/s]\u001b[A\n",
            " 44%|████▍     | 1456/3298 [16:22<20:45,  1.48it/s]\u001b[A\n",
            " 44%|████▍     | 1457/3298 [16:23<20:16,  1.51it/s]\u001b[A\n",
            " 44%|████▍     | 1458/3298 [16:23<22:34,  1.36it/s]\u001b[A\n",
            " 44%|████▍     | 1459/3298 [16:24<21:41,  1.41it/s]\u001b[A\n",
            " 44%|████▍     | 1460/3298 [16:25<21:00,  1.46it/s]\u001b[A\n",
            " 44%|████▍     | 1461/3298 [16:25<20:37,  1.48it/s]\u001b[A\n",
            " 44%|████▍     | 1462/3298 [16:26<20:24,  1.50it/s]\u001b[A\n",
            " 44%|████▍     | 1463/3298 [16:27<21:13,  1.44it/s]\u001b[A\n",
            " 44%|████▍     | 1464/3298 [16:27<20:44,  1.47it/s]\u001b[A\n",
            " 44%|████▍     | 1465/3298 [16:28<20:25,  1.50it/s]\u001b[A\n",
            " 44%|████▍     | 1466/3298 [16:29<20:10,  1.51it/s]\u001b[A\n",
            " 44%|████▍     | 1467/3298 [16:29<20:10,  1.51it/s]\u001b[A\n",
            " 45%|████▍     | 1468/3298 [16:30<20:00,  1.52it/s]\u001b[A\n",
            " 45%|████▍     | 1469/3298 [16:31<20:06,  1.52it/s]\u001b[A\n",
            " 45%|████▍     | 1470/3298 [16:32<21:21,  1.43it/s]\u001b[A\n",
            " 45%|████▍     | 1471/3298 [16:32<20:49,  1.46it/s]\u001b[A\n",
            " 45%|████▍     | 1472/3298 [16:33<20:21,  1.49it/s]\u001b[A\n",
            " 45%|████▍     | 1473/3298 [16:34<21:35,  1.41it/s]\u001b[A\n",
            " 45%|████▍     | 1474/3298 [16:34<21:05,  1.44it/s]\u001b[A\n",
            " 45%|████▍     | 1475/3298 [16:35<21:55,  1.39it/s]\u001b[A\n",
            " 45%|████▍     | 1476/3298 [16:36<22:44,  1.34it/s]\u001b[A\n",
            " 45%|████▍     | 1477/3298 [16:37<21:57,  1.38it/s]\u001b[A\n",
            " 45%|████▍     | 1478/3298 [16:37<21:15,  1.43it/s]\u001b[A\n",
            " 45%|████▍     | 1479/3298 [16:38<20:40,  1.47it/s]\u001b[A\n",
            " 45%|████▍     | 1480/3298 [16:39<21:38,  1.40it/s]\u001b[A\n",
            " 45%|████▍     | 1481/3298 [16:39<21:04,  1.44it/s]\u001b[A\n",
            " 45%|████▍     | 1482/3298 [16:40<20:36,  1.47it/s]\u001b[A\n",
            " 45%|████▍     | 1483/3298 [16:41<20:18,  1.49it/s]\u001b[A\n",
            " 45%|████▍     | 1484/3298 [16:41<20:00,  1.51it/s]\u001b[A\n",
            " 45%|████▌     | 1485/3298 [16:42<19:50,  1.52it/s]\u001b[A\n",
            " 45%|████▌     | 1486/3298 [16:42<19:48,  1.52it/s]\u001b[A\n",
            " 45%|████▌     | 1487/3298 [16:43<19:40,  1.53it/s]\u001b[A\n",
            " 45%|████▌     | 1488/3298 [16:44<19:42,  1.53it/s]\u001b[A\n",
            " 45%|████▌     | 1489/3298 [16:44<19:38,  1.53it/s]\u001b[A\n",
            " 45%|████▌     | 1490/3298 [16:45<19:32,  1.54it/s]\u001b[A\n",
            " 45%|████▌     | 1491/3298 [16:46<20:50,  1.45it/s]\u001b[A\n",
            " 45%|████▌     | 1492/3298 [16:47<21:39,  1.39it/s]\u001b[A\n",
            " 45%|████▌     | 1493/3298 [16:47<21:04,  1.43it/s]\u001b[A\n",
            " 45%|████▌     | 1494/3298 [16:48<19:21,  1.55it/s]\u001b[A\n",
            " 45%|████▌     | 1495/3298 [16:48<19:34,  1.53it/s]\u001b[A\n",
            " 45%|████▌     | 1496/3298 [16:49<19:22,  1.55it/s]\u001b[A\n",
            " 45%|████▌     | 1497/3298 [16:50<19:24,  1.55it/s]\u001b[A\n",
            " 45%|████▌     | 1498/3298 [16:50<19:20,  1.55it/s]\u001b[A\n",
            " 45%|████▌     | 1499/3298 [16:51<19:18,  1.55it/s]\u001b[A\n",
            " 45%|████▌     | 1500/3298 [16:52<20:28,  1.46it/s]\u001b[A\n",
            " 46%|████▌     | 1501/3298 [16:52<20:07,  1.49it/s]\u001b[A\n",
            " 46%|████▌     | 1502/3298 [16:53<21:11,  1.41it/s]\u001b[A\n",
            " 46%|████▌     | 1503/3298 [16:54<20:39,  1.45it/s]\u001b[A\n",
            " 46%|████▌     | 1504/3298 [16:55<20:22,  1.47it/s]\u001b[A\n",
            " 46%|████▌     | 1505/3298 [16:55<20:07,  1.49it/s]\u001b[A\n",
            " 46%|████▌     | 1506/3298 [16:56<19:57,  1.50it/s]\u001b[A\n",
            " 46%|████▌     | 1507/3298 [16:57<21:02,  1.42it/s]\u001b[A\n",
            " 46%|████▌     | 1508/3298 [16:57<20:21,  1.47it/s]\u001b[A\n",
            " 46%|████▌     | 1509/3298 [16:58<20:01,  1.49it/s]\u001b[A\n",
            " 46%|████▌     | 1510/3298 [16:59<22:14,  1.34it/s]\u001b[A\n",
            " 46%|████▌     | 1511/3298 [17:00<21:28,  1.39it/s]\u001b[A\n",
            " 46%|████▌     | 1512/3298 [17:00<20:45,  1.43it/s]\u001b[A\n",
            " 46%|████▌     | 1513/3298 [17:01<20:20,  1.46it/s]\u001b[A\n",
            " 46%|████▌     | 1514/3298 [17:01<20:01,  1.49it/s]\u001b[A\n",
            " 46%|████▌     | 1515/3298 [17:02<19:49,  1.50it/s]\u001b[A\n",
            " 46%|████▌     | 1516/3298 [17:03<20:53,  1.42it/s]\u001b[A\n",
            " 46%|████▌     | 1517/3298 [17:04<21:45,  1.36it/s]\u001b[A\n",
            " 46%|████▌     | 1518/3298 [17:04<19:46,  1.50it/s]\u001b[A\n",
            " 46%|████▌     | 1519/3298 [17:05<19:26,  1.53it/s]\u001b[A\n",
            " 46%|████▌     | 1520/3298 [17:06<21:51,  1.36it/s]\u001b[A\n",
            " 46%|████▌     | 1521/3298 [17:07<22:15,  1.33it/s]\u001b[A\n",
            " 46%|████▌     | 1522/3298 [17:07<22:25,  1.32it/s]\u001b[A\n",
            " 46%|████▌     | 1523/3298 [17:08<21:30,  1.38it/s]\u001b[A\n",
            " 46%|████▌     | 1524/3298 [17:09<20:43,  1.43it/s]\u001b[A\n",
            " 46%|████▌     | 1525/3298 [17:09<19:05,  1.55it/s]\u001b[A\n",
            " 46%|████▋     | 1526/3298 [17:10<19:08,  1.54it/s]\u001b[A\n",
            " 46%|████▋     | 1527/3298 [17:10<19:11,  1.54it/s]\u001b[A\n",
            " 46%|████▋     | 1528/3298 [17:11<20:40,  1.43it/s]\u001b[A\n",
            " 46%|████▋     | 1529/3298 [17:12<20:10,  1.46it/s]\u001b[A\n",
            " 46%|████▋     | 1530/3298 [17:13<19:50,  1.48it/s]\u001b[A\n",
            " 46%|████▋     | 1531/3298 [17:13<19:42,  1.49it/s]\u001b[A\n",
            " 46%|████▋     | 1532/3298 [17:14<19:35,  1.50it/s]\u001b[A\n",
            " 46%|████▋     | 1533/3298 [17:15<19:32,  1.51it/s]\u001b[A\n",
            " 47%|████▋     | 1534/3298 [17:15<18:09,  1.62it/s]\u001b[A\n",
            " 47%|████▋     | 1535/3298 [17:16<17:07,  1.72it/s]\u001b[A\n",
            " 47%|████▋     | 1536/3298 [17:16<17:55,  1.64it/s]\u001b[A\n",
            " 47%|████▋     | 1537/3298 [17:17<18:13,  1.61it/s]\u001b[A\n",
            " 47%|████▋     | 1538/3298 [17:18<18:36,  1.58it/s]\u001b[A\n",
            " 47%|████▋     | 1539/3298 [17:18<18:39,  1.57it/s]\u001b[A\n",
            " 47%|████▋     | 1540/3298 [17:19<18:47,  1.56it/s]\u001b[A\n",
            " 47%|████▋     | 1541/3298 [17:20<19:03,  1.54it/s]\u001b[A\n",
            " 47%|████▋     | 1542/3298 [17:20<19:07,  1.53it/s]\u001b[A\n",
            " 47%|████▋     | 1543/3298 [17:21<18:59,  1.54it/s]\u001b[A\n",
            " 47%|████▋     | 1544/3298 [17:22<20:13,  1.44it/s]\u001b[A\n",
            " 47%|████▋     | 1545/3298 [17:22<19:56,  1.46it/s]\u001b[A\n",
            " 47%|████▋     | 1546/3298 [17:23<19:32,  1.49it/s]\u001b[A\n",
            " 47%|████▋     | 1547/3298 [17:24<19:21,  1.51it/s]\u001b[A\n",
            " 47%|████▋     | 1548/3298 [17:24<19:18,  1.51it/s]\u001b[A\n",
            " 47%|████▋     | 1549/3298 [17:25<20:19,  1.43it/s]\u001b[A\n",
            " 47%|████▋     | 1550/3298 [17:26<20:56,  1.39it/s]\u001b[A\n",
            " 47%|████▋     | 1551/3298 [17:26<19:05,  1.53it/s]\u001b[A\n",
            " 47%|████▋     | 1552/3298 [17:27<18:53,  1.54it/s]\u001b[A\n",
            " 47%|████▋     | 1553/3298 [17:28<18:53,  1.54it/s]\u001b[A\n",
            " 47%|████▋     | 1554/3298 [17:28<18:54,  1.54it/s]\u001b[A\n",
            " 47%|████▋     | 1555/3298 [17:29<20:05,  1.45it/s]\u001b[A\n",
            " 47%|████▋     | 1556/3298 [17:30<19:50,  1.46it/s]\u001b[A\n",
            " 47%|████▋     | 1557/3298 [17:30<19:21,  1.50it/s]\u001b[A\n",
            " 47%|████▋     | 1558/3298 [17:31<17:52,  1.62it/s]\u001b[A\n",
            " 47%|████▋     | 1559/3298 [17:31<18:05,  1.60it/s]\u001b[A\n",
            " 47%|████▋     | 1560/3298 [17:32<18:22,  1.58it/s]\u001b[A\n",
            " 47%|████▋     | 1561/3298 [17:33<18:37,  1.55it/s]\u001b[A\n",
            " 47%|████▋     | 1562/3298 [17:33<18:53,  1.53it/s]\u001b[A\n",
            " 47%|████▋     | 1563/3298 [17:34<18:54,  1.53it/s]\u001b[A\n",
            " 47%|████▋     | 1564/3298 [17:35<19:08,  1.51it/s]\u001b[A\n",
            " 47%|████▋     | 1565/3298 [17:36<22:40,  1.27it/s]\u001b[A\n",
            " 47%|████▋     | 1566/3298 [17:37<22:47,  1.27it/s]\u001b[A\n",
            " 48%|████▊     | 1567/3298 [17:37<22:49,  1.26it/s]\u001b[A\n",
            " 48%|████▊     | 1568/3298 [17:38<22:47,  1.27it/s]\u001b[A\n",
            " 48%|████▊     | 1569/3298 [17:39<22:42,  1.27it/s]\u001b[A\n",
            " 48%|████▊     | 1570/3298 [17:40<20:27,  1.41it/s]\u001b[A\n",
            " 48%|████▊     | 1571/3298 [17:40<19:54,  1.45it/s]\u001b[A\n",
            " 48%|████▊     | 1572/3298 [17:41<19:37,  1.47it/s]\u001b[A\n",
            " 48%|████▊     | 1573/3298 [17:41<18:09,  1.58it/s]\u001b[A\n",
            " 48%|████▊     | 1574/3298 [17:42<19:36,  1.46it/s]\u001b[A\n",
            " 48%|████▊     | 1575/3298 [17:43<19:29,  1.47it/s]\u001b[A\n",
            " 48%|████▊     | 1576/3298 [17:43<18:00,  1.59it/s]\u001b[A\n",
            " 48%|████▊     | 1577/3298 [17:44<16:57,  1.69it/s]\u001b[A\n",
            " 48%|████▊     | 1578/3298 [17:45<19:39,  1.46it/s]\u001b[A\n",
            " 48%|████▊     | 1579/3298 [17:46<20:26,  1.40it/s]\u001b[A\n",
            " 48%|████▊     | 1580/3298 [17:46<21:59,  1.30it/s]\u001b[A\n",
            " 48%|████▊     | 1581/3298 [17:47<21:49,  1.31it/s]\u001b[A\n",
            " 48%|████▊     | 1582/3298 [17:48<21:56,  1.30it/s]\u001b[A\n",
            " 48%|████▊     | 1583/3298 [17:49<22:07,  1.29it/s]\u001b[A\n",
            " 48%|████▊     | 1584/3298 [17:50<22:17,  1.28it/s]\u001b[A\n",
            " 48%|████▊     | 1585/3298 [17:50<23:36,  1.21it/s]\u001b[A\n",
            " 48%|████▊     | 1586/3298 [17:51<23:02,  1.24it/s]\u001b[A\n",
            " 48%|████▊     | 1587/3298 [17:52<22:47,  1.25it/s]\u001b[A\n",
            " 48%|████▊     | 1588/3298 [17:53<23:38,  1.21it/s]\u001b[A\n",
            " 48%|████▊     | 1589/3298 [17:54<23:15,  1.23it/s]\u001b[A\n",
            " 48%|████▊     | 1590/3298 [17:54<22:51,  1.25it/s]\u001b[A\n",
            " 48%|████▊     | 1591/3298 [17:55<22:39,  1.26it/s]\u001b[A\n",
            " 48%|████▊     | 1592/3298 [17:56<22:22,  1.27it/s]\u001b[A\n",
            " 48%|████▊     | 1593/3298 [17:57<23:23,  1.21it/s]\u001b[A\n",
            " 48%|████▊     | 1594/3298 [17:58<22:58,  1.24it/s]\u001b[A\n",
            " 48%|████▊     | 1595/3298 [17:58<22:35,  1.26it/s]\u001b[A\n",
            " 48%|████▊     | 1596/3298 [17:59<22:22,  1.27it/s]\u001b[A\n",
            " 48%|████▊     | 1597/3298 [18:00<22:04,  1.28it/s]\u001b[A\n",
            " 48%|████▊     | 1598/3298 [18:01<22:07,  1.28it/s]\u001b[A\n",
            " 48%|████▊     | 1599/3298 [18:02<22:08,  1.28it/s]\u001b[A\n",
            " 49%|████▊     | 1600/3298 [18:02<22:04,  1.28it/s]\u001b[A\n",
            " 49%|████▊     | 1601/3298 [18:03<20:53,  1.35it/s]\u001b[A\n",
            " 49%|████▊     | 1602/3298 [18:04<22:06,  1.28it/s]\u001b[A\n",
            " 49%|████▊     | 1603/3298 [18:05<21:53,  1.29it/s]\u001b[A\n",
            " 49%|████▊     | 1604/3298 [18:05<19:33,  1.44it/s]\u001b[A\n",
            " 49%|████▊     | 1605/3298 [18:06<19:06,  1.48it/s]\u001b[A\n",
            " 49%|████▊     | 1606/3298 [18:06<18:47,  1.50it/s]\u001b[A\n",
            " 49%|████▊     | 1607/3298 [18:07<20:53,  1.35it/s]\u001b[A\n",
            " 49%|████▉     | 1608/3298 [18:08<21:26,  1.31it/s]\u001b[A\n",
            " 49%|████▉     | 1609/3298 [18:09<21:35,  1.30it/s]\u001b[A\n",
            " 49%|████▉     | 1610/3298 [18:10<24:09,  1.16it/s]\u001b[A\n",
            " 49%|████▉     | 1611/3298 [18:11<23:27,  1.20it/s]\u001b[A\n",
            " 49%|████▉     | 1612/3298 [18:12<23:13,  1.21it/s]\u001b[A\n",
            " 49%|████▉     | 1613/3298 [18:12<22:58,  1.22it/s]\u001b[A\n",
            " 49%|████▉     | 1614/3298 [18:13<22:35,  1.24it/s]\u001b[A\n",
            " 49%|████▉     | 1615/3298 [18:14<23:30,  1.19it/s]\u001b[A\n",
            " 49%|████▉     | 1616/3298 [18:15<22:51,  1.23it/s]\u001b[A\n",
            " 49%|████▉     | 1617/3298 [18:16<22:35,  1.24it/s]\u001b[A\n",
            " 49%|████▉     | 1618/3298 [18:16<21:16,  1.32it/s]\u001b[A\n",
            " 49%|████▉     | 1619/3298 [18:17<21:25,  1.31it/s]\u001b[A\n",
            " 49%|████▉     | 1620/3298 [18:18<20:19,  1.38it/s]\u001b[A\n",
            " 49%|████▉     | 1621/3298 [18:18<18:31,  1.51it/s]\u001b[A\n",
            " 49%|████▉     | 1622/3298 [18:19<18:19,  1.52it/s]\u001b[A\n",
            " 49%|████▉     | 1623/3298 [18:19<18:25,  1.52it/s]\u001b[A\n",
            " 49%|████▉     | 1624/3298 [18:20<18:17,  1.52it/s]\u001b[A\n",
            " 49%|████▉     | 1625/3298 [18:21<18:11,  1.53it/s]\u001b[A\n",
            " 49%|████▉     | 1626/3298 [18:22<19:21,  1.44it/s]\u001b[A\n",
            " 49%|████▉     | 1627/3298 [18:22<19:15,  1.45it/s]\u001b[A\n",
            " 49%|████▉     | 1628/3298 [18:23<18:43,  1.49it/s]\u001b[A\n",
            " 49%|████▉     | 1629/3298 [18:24<18:33,  1.50it/s]\u001b[A\n",
            " 49%|████▉     | 1630/3298 [18:24<18:17,  1.52it/s]\u001b[A\n",
            " 49%|████▉     | 1631/3298 [18:25<19:19,  1.44it/s]\u001b[A\n",
            " 49%|████▉     | 1632/3298 [18:26<18:52,  1.47it/s]\u001b[A\n",
            " 50%|████▉     | 1633/3298 [18:26<18:32,  1.50it/s]\u001b[A\n",
            " 50%|████▉     | 1634/3298 [18:27<19:31,  1.42it/s]\u001b[A\n",
            " 50%|████▉     | 1635/3298 [18:28<20:16,  1.37it/s]\u001b[A\n",
            " 50%|████▉     | 1636/3298 [18:29<20:46,  1.33it/s]\u001b[A\n",
            " 50%|████▉     | 1637/3298 [18:29<21:11,  1.31it/s]\u001b[A\n",
            " 50%|████▉     | 1638/3298 [18:30<21:23,  1.29it/s]\u001b[A\n",
            " 50%|████▉     | 1639/3298 [18:31<22:41,  1.22it/s]\u001b[A\n",
            " 50%|████▉     | 1640/3298 [18:32<22:23,  1.23it/s]\u001b[A\n",
            " 50%|████▉     | 1641/3298 [18:33<22:31,  1.23it/s]\u001b[A\n",
            " 50%|████▉     | 1642/3298 [18:34<23:24,  1.18it/s]\u001b[A\n",
            " 50%|████▉     | 1643/3298 [18:34<23:05,  1.19it/s]\u001b[A\n",
            " 50%|████▉     | 1644/3298 [18:35<22:37,  1.22it/s]\u001b[A\n",
            " 50%|████▉     | 1645/3298 [18:36<22:21,  1.23it/s]\u001b[A\n",
            " 50%|████▉     | 1646/3298 [18:37<22:20,  1.23it/s]\u001b[A\n",
            " 50%|████▉     | 1647/3298 [18:38<23:22,  1.18it/s]\u001b[A\n",
            " 50%|████▉     | 1648/3298 [18:39<22:57,  1.20it/s]\u001b[A\n",
            " 50%|█████     | 1649/3298 [18:39<22:37,  1.21it/s]\u001b[A\n",
            " 50%|█████     | 1650/3298 [18:40<22:20,  1.23it/s]\u001b[A\n",
            " 50%|█████     | 1651/3298 [18:41<23:06,  1.19it/s]\u001b[A\n",
            " 50%|█████     | 1652/3298 [18:42<22:36,  1.21it/s]\u001b[A\n",
            " 50%|█████     | 1653/3298 [18:43<23:21,  1.17it/s]\u001b[A\n",
            " 50%|█████     | 1654/3298 [18:44<22:56,  1.19it/s]\u001b[A\n",
            " 50%|█████     | 1655/3298 [18:44<22:24,  1.22it/s]\u001b[A\n",
            " 50%|█████     | 1656/3298 [18:45<21:01,  1.30it/s]\u001b[A\n",
            " 50%|█████     | 1657/3298 [18:46<21:10,  1.29it/s]\u001b[A\n",
            " 50%|█████     | 1658/3298 [18:47<21:19,  1.28it/s]\u001b[A\n",
            " 50%|█████     | 1659/3298 [18:48<22:30,  1.21it/s]\u001b[A\n",
            " 50%|█████     | 1660/3298 [18:48<22:08,  1.23it/s]\u001b[A\n",
            " 50%|█████     | 1661/3298 [18:49<21:54,  1.25it/s]\u001b[A\n",
            " 50%|█████     | 1662/3298 [18:50<21:48,  1.25it/s]\u001b[A\n",
            " 50%|█████     | 1663/3298 [18:51<21:43,  1.25it/s]\u001b[A\n",
            " 50%|█████     | 1664/3298 [18:51<20:43,  1.31it/s]\u001b[A\n",
            " 50%|█████     | 1665/3298 [18:52<19:48,  1.37it/s]\u001b[A\n",
            " 51%|█████     | 1666/3298 [18:53<19:07,  1.42it/s]\u001b[A\n",
            " 51%|█████     | 1667/3298 [18:53<19:57,  1.36it/s]\u001b[A\n",
            " 51%|█████     | 1668/3298 [18:54<20:29,  1.33it/s]\u001b[A\n",
            " 51%|█████     | 1669/3298 [18:55<19:35,  1.39it/s]\u001b[A\n",
            " 51%|█████     | 1670/3298 [18:56<18:52,  1.44it/s]\u001b[A\n",
            " 51%|█████     | 1671/3298 [18:56<19:37,  1.38it/s]\u001b[A\n",
            " 51%|█████     | 1672/3298 [18:57<21:04,  1.29it/s]\u001b[A\n",
            " 51%|█████     | 1673/3298 [18:58<22:21,  1.21it/s]\u001b[A\n",
            " 51%|█████     | 1674/3298 [18:59<20:52,  1.30it/s]\u001b[A\n",
            " 51%|█████     | 1675/3298 [18:59<19:54,  1.36it/s]\u001b[A\n",
            " 51%|█████     | 1676/3298 [19:00<19:10,  1.41it/s]\u001b[A\n",
            " 51%|█████     | 1677/3298 [19:01<19:37,  1.38it/s]\u001b[A\n",
            " 51%|█████     | 1678/3298 [19:02<18:53,  1.43it/s]\u001b[A\n",
            " 51%|█████     | 1679/3298 [19:02<18:29,  1.46it/s]\u001b[A\n",
            " 51%|█████     | 1680/3298 [19:03<20:21,  1.32it/s]\u001b[A\n",
            " 51%|█████     | 1681/3298 [19:04<19:23,  1.39it/s]\u001b[A\n",
            " 51%|█████     | 1682/3298 [19:05<21:02,  1.28it/s]\u001b[A\n",
            " 51%|█████     | 1683/3298 [19:05<19:55,  1.35it/s]\u001b[A\n",
            " 51%|█████     | 1684/3298 [19:06<17:57,  1.50it/s]\u001b[A\n",
            " 51%|█████     | 1685/3298 [19:06<17:48,  1.51it/s]\u001b[A\n",
            " 51%|█████     | 1686/3298 [19:07<19:47,  1.36it/s]\u001b[A\n",
            " 51%|█████     | 1687/3298 [19:08<20:06,  1.33it/s]\u001b[A\n",
            " 51%|█████     | 1688/3298 [19:09<19:15,  1.39it/s]\u001b[A\n",
            " 51%|█████     | 1689/3298 [19:09<18:41,  1.43it/s]\u001b[A\n",
            " 51%|█████     | 1690/3298 [19:10<19:19,  1.39it/s]\u001b[A\n",
            " 51%|█████▏    | 1691/3298 [19:11<18:39,  1.44it/s]\u001b[A\n",
            " 51%|█████▏    | 1692/3298 [19:11<18:08,  1.48it/s]\u001b[A\n",
            " 51%|█████▏    | 1693/3298 [19:12<18:51,  1.42it/s]\u001b[A\n",
            " 51%|█████▏    | 1694/3298 [19:13<19:25,  1.38it/s]\u001b[A\n",
            " 51%|█████▏    | 1695/3298 [19:14<19:59,  1.34it/s]\u001b[A\n",
            " 51%|█████▏    | 1696/3298 [19:14<18:10,  1.47it/s]\u001b[A\n",
            " 51%|█████▏    | 1697/3298 [19:15<18:01,  1.48it/s]\u001b[A\n",
            " 51%|█████▏    | 1698/3298 [19:16<17:44,  1.50it/s]\u001b[A\n",
            " 52%|█████▏    | 1699/3298 [19:16<17:37,  1.51it/s]\u001b[A\n",
            " 52%|█████▏    | 1700/3298 [19:17<17:30,  1.52it/s]\u001b[A\n",
            " 52%|█████▏    | 1701/3298 [19:18<17:25,  1.53it/s]\u001b[A\n",
            " 52%|█████▏    | 1702/3298 [19:18<17:24,  1.53it/s]\u001b[A\n",
            " 52%|█████▏    | 1703/3298 [19:19<18:22,  1.45it/s]\u001b[A\n",
            " 52%|█████▏    | 1704/3298 [19:20<17:55,  1.48it/s]\u001b[A\n",
            " 52%|█████▏    | 1705/3298 [19:20<17:36,  1.51it/s]\u001b[A\n",
            " 52%|█████▏    | 1706/3298 [19:21<17:25,  1.52it/s]\u001b[A\n",
            " 52%|█████▏    | 1707/3298 [19:22<17:18,  1.53it/s]\u001b[A\n",
            " 52%|█████▏    | 1708/3298 [19:22<17:14,  1.54it/s]\u001b[A\n",
            " 52%|█████▏    | 1709/3298 [19:23<17:02,  1.55it/s]\u001b[A\n",
            " 52%|█████▏    | 1710/3298 [19:24<17:05,  1.55it/s]\u001b[A\n",
            " 52%|█████▏    | 1711/3298 [19:24<18:06,  1.46it/s]\u001b[A\n",
            " 52%|█████▏    | 1712/3298 [19:25<17:43,  1.49it/s]\u001b[A\n",
            " 52%|█████▏    | 1713/3298 [19:26<17:25,  1.52it/s]\u001b[A\n",
            " 52%|█████▏    | 1714/3298 [19:26<17:11,  1.54it/s]\u001b[A\n",
            " 52%|█████▏    | 1715/3298 [19:27<17:03,  1.55it/s]\u001b[A\n",
            " 52%|█████▏    | 1716/3298 [19:27<17:00,  1.55it/s]\u001b[A\n",
            " 52%|█████▏    | 1717/3298 [19:28<18:09,  1.45it/s]\u001b[A\n",
            " 52%|█████▏    | 1718/3298 [19:29<18:52,  1.39it/s]\u001b[A\n",
            " 52%|█████▏    | 1719/3298 [19:30<19:24,  1.36it/s]\u001b[A\n",
            " 52%|█████▏    | 1720/3298 [19:31<19:45,  1.33it/s]\u001b[A\n",
            " 52%|█████▏    | 1721/3298 [19:31<19:56,  1.32it/s]\u001b[A\n",
            " 52%|█████▏    | 1722/3298 [19:32<21:04,  1.25it/s]\u001b[A\n",
            " 52%|█████▏    | 1723/3298 [19:33<21:45,  1.21it/s]\u001b[A\n",
            " 52%|█████▏    | 1724/3298 [19:34<21:22,  1.23it/s]\u001b[A\n",
            " 52%|█████▏    | 1725/3298 [19:35<21:59,  1.19it/s]\u001b[A\n",
            " 52%|█████▏    | 1726/3298 [19:36<22:32,  1.16it/s]\u001b[A\n",
            " 52%|█████▏    | 1727/3298 [19:37<22:57,  1.14it/s]\u001b[A\n",
            " 52%|█████▏    | 1728/3298 [19:37<22:13,  1.18it/s]\u001b[A\n",
            " 52%|█████▏    | 1729/3298 [19:38<22:44,  1.15it/s]\u001b[A\n",
            " 52%|█████▏    | 1730/3298 [19:39<23:03,  1.13it/s]\u001b[A\n",
            " 52%|█████▏    | 1731/3298 [19:40<21:09,  1.23it/s]\u001b[A\n",
            " 53%|█████▎    | 1732/3298 [19:41<19:44,  1.32it/s]\u001b[A\n",
            " 53%|█████▎    | 1733/3298 [19:41<18:44,  1.39it/s]\u001b[A\n",
            " 53%|█████▎    | 1734/3298 [19:42<19:10,  1.36it/s]\u001b[A\n",
            " 53%|█████▎    | 1735/3298 [19:43<20:33,  1.27it/s]\u001b[A\n",
            " 53%|█████▎    | 1736/3298 [19:44<20:24,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1737/3298 [19:44<20:29,  1.27it/s]\u001b[A\n",
            " 53%|█████▎    | 1738/3298 [19:45<19:12,  1.35it/s]\u001b[A\n",
            " 53%|█████▎    | 1739/3298 [19:46<19:30,  1.33it/s]\u001b[A\n",
            " 53%|█████▎    | 1740/3298 [19:47<20:48,  1.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1741/3298 [19:48<20:41,  1.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1742/3298 [19:48<20:30,  1.26it/s]\u001b[A\n",
            " 53%|█████▎    | 1743/3298 [19:49<20:23,  1.27it/s]\u001b[A\n",
            " 53%|█████▎    | 1744/3298 [19:50<20:16,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1745/3298 [19:51<20:14,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1746/3298 [19:51<20:09,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1747/3298 [19:52<20:11,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1748/3298 [19:53<20:06,  1.28it/s]\u001b[A\n",
            " 53%|█████▎    | 1749/3298 [19:54<21:14,  1.22it/s]\u001b[A\n",
            " 53%|█████▎    | 1750/3298 [19:55<20:48,  1.24it/s]\u001b[A\n",
            " 53%|█████▎    | 1751/3298 [19:56<20:39,  1.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1752/3298 [19:56<21:28,  1.20it/s]\u001b[A\n",
            " 53%|█████▎    | 1753/3298 [19:57<22:02,  1.17it/s]\u001b[A\n",
            " 53%|█████▎    | 1754/3298 [19:58<22:32,  1.14it/s]\u001b[A\n",
            " 53%|█████▎    | 1755/3298 [19:59<21:36,  1.19it/s]\u001b[A\n",
            " 53%|█████▎    | 1756/3298 [20:00<21:04,  1.22it/s]\u001b[A\n",
            " 53%|█████▎    | 1757/3298 [20:01<20:48,  1.23it/s]\u001b[A\n",
            " 53%|█████▎    | 1758/3298 [20:01<21:36,  1.19it/s]\u001b[A\n",
            " 53%|█████▎    | 1759/3298 [20:02<21:10,  1.21it/s]\u001b[A\n",
            " 53%|█████▎    | 1760/3298 [20:03<20:38,  1.24it/s]\u001b[A\n",
            " 53%|█████▎    | 1761/3298 [20:04<20:31,  1.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1762/3298 [20:05<20:24,  1.25it/s]\u001b[A\n",
            " 53%|█████▎    | 1763/3298 [20:05<19:12,  1.33it/s]\u001b[A\n",
            " 53%|█████▎    | 1764/3298 [20:06<19:20,  1.32it/s]\u001b[A\n",
            " 54%|█████▎    | 1765/3298 [20:07<18:23,  1.39it/s]\u001b[A\n",
            " 54%|█████▎    | 1766/3298 [20:07<18:48,  1.36it/s]\u001b[A\n",
            " 54%|█████▎    | 1767/3298 [20:08<19:13,  1.33it/s]\u001b[A\n",
            " 54%|█████▎    | 1768/3298 [20:09<19:23,  1.32it/s]\u001b[A\n",
            " 54%|█████▎    | 1769/3298 [20:10<20:33,  1.24it/s]\u001b[A\n",
            " 54%|█████▎    | 1770/3298 [20:10<18:20,  1.39it/s]\u001b[A\n",
            " 54%|█████▎    | 1771/3298 [20:11<17:41,  1.44it/s]\u001b[A\n",
            " 54%|█████▎    | 1772/3298 [20:12<17:12,  1.48it/s]\u001b[A\n",
            " 54%|█████▍    | 1773/3298 [20:12<16:54,  1.50it/s]\u001b[A\n",
            " 54%|█████▍    | 1774/3298 [20:13<16:43,  1.52it/s]\u001b[A\n",
            " 54%|█████▍    | 1775/3298 [20:14<15:42,  1.62it/s]\u001b[A\n",
            " 54%|█████▍    | 1776/3298 [20:14<15:53,  1.60it/s]\u001b[A\n",
            " 54%|█████▍    | 1777/3298 [20:15<16:02,  1.58it/s]\u001b[A\n",
            " 54%|█████▍    | 1778/3298 [20:15<16:02,  1.58it/s]\u001b[A\n",
            " 54%|█████▍    | 1779/3298 [20:16<16:04,  1.57it/s]\u001b[A\n",
            " 54%|█████▍    | 1780/3298 [20:17<16:07,  1.57it/s]\u001b[A\n",
            " 54%|█████▍    | 1781/3298 [20:17<16:20,  1.55it/s]\u001b[A\n",
            " 54%|█████▍    | 1782/3298 [20:18<17:28,  1.45it/s]\u001b[A\n",
            " 54%|█████▍    | 1783/3298 [20:19<17:07,  1.47it/s]\u001b[A\n",
            " 54%|█████▍    | 1784/3298 [20:19<15:50,  1.59it/s]\u001b[A\n",
            " 54%|█████▍    | 1785/3298 [20:20<14:53,  1.69it/s]\u001b[A\n",
            " 54%|█████▍    | 1786/3298 [20:20<15:21,  1.64it/s]\u001b[A\n",
            " 54%|█████▍    | 1787/3298 [20:21<17:33,  1.43it/s]\u001b[A\n",
            " 54%|█████▍    | 1788/3298 [20:22<19:07,  1.32it/s]\u001b[A\n",
            " 54%|█████▍    | 1789/3298 [20:23<20:19,  1.24it/s]\u001b[A\n",
            " 54%|█████▍    | 1790/3298 [20:24<18:56,  1.33it/s]\u001b[A\n",
            " 54%|█████▍    | 1791/3298 [20:24<17:59,  1.40it/s]\u001b[A\n",
            " 54%|█████▍    | 1792/3298 [20:25<17:24,  1.44it/s]\u001b[A\n",
            " 54%|█████▍    | 1793/3298 [20:26<17:00,  1.48it/s]\u001b[A\n",
            " 54%|█████▍    | 1794/3298 [20:26<16:39,  1.50it/s]\u001b[A\n",
            " 54%|█████▍    | 1795/3298 [20:27<16:22,  1.53it/s]\u001b[A\n",
            " 54%|█████▍    | 1796/3298 [20:28<16:20,  1.53it/s]\u001b[A\n",
            " 54%|█████▍    | 1797/3298 [20:28<16:10,  1.55it/s]\u001b[A\n",
            " 55%|█████▍    | 1798/3298 [20:29<17:18,  1.44it/s]\u001b[A\n",
            " 55%|█████▍    | 1799/3298 [20:30<16:52,  1.48it/s]\u001b[A\n",
            " 55%|█████▍    | 1800/3298 [20:30<16:37,  1.50it/s]\u001b[A\n",
            " 55%|█████▍    | 1801/3298 [20:31<17:19,  1.44it/s]\u001b[A\n",
            " 55%|█████▍    | 1802/3298 [20:32<17:57,  1.39it/s]\u001b[A\n",
            " 55%|█████▍    | 1803/3298 [20:33<18:19,  1.36it/s]\u001b[A\n",
            " 55%|█████▍    | 1804/3298 [20:33<18:42,  1.33it/s]\u001b[A\n",
            " 55%|█████▍    | 1805/3298 [20:34<18:51,  1.32it/s]\u001b[A\n",
            " 55%|█████▍    | 1806/3298 [20:35<18:56,  1.31it/s]\u001b[A\n",
            " 55%|█████▍    | 1807/3298 [20:36<18:02,  1.38it/s]\u001b[A\n",
            " 55%|█████▍    | 1808/3298 [20:36<17:24,  1.43it/s]\u001b[A\n",
            " 55%|█████▍    | 1809/3298 [20:37<16:56,  1.47it/s]\u001b[A\n",
            " 55%|█████▍    | 1810/3298 [20:38<16:36,  1.49it/s]\u001b[A\n",
            " 55%|█████▍    | 1811/3298 [20:38<18:21,  1.35it/s]\u001b[A\n",
            " 55%|█████▍    | 1812/3298 [20:39<19:52,  1.25it/s]\u001b[A\n",
            " 55%|█████▍    | 1813/3298 [20:40<20:41,  1.20it/s]\u001b[A\n",
            " 55%|█████▌    | 1814/3298 [20:41<21:20,  1.16it/s]\u001b[A\n",
            " 55%|█████▌    | 1815/3298 [20:42<19:40,  1.26it/s]\u001b[A\n",
            " 55%|█████▌    | 1816/3298 [20:42<17:34,  1.41it/s]\u001b[A\n",
            " 55%|█████▌    | 1817/3298 [20:43<18:58,  1.30it/s]\u001b[A\n",
            " 55%|█████▌    | 1818/3298 [20:44<19:56,  1.24it/s]\u001b[A\n",
            " 55%|█████▌    | 1819/3298 [20:45<19:49,  1.24it/s]\u001b[A\n",
            " 55%|█████▌    | 1820/3298 [20:46<19:42,  1.25it/s]\u001b[A\n",
            " 55%|█████▌    | 1821/3298 [20:47<20:33,  1.20it/s]\u001b[A\n",
            " 55%|█████▌    | 1822/3298 [20:48<20:18,  1.21it/s]\u001b[A\n",
            " 55%|█████▌    | 1823/3298 [20:48<20:55,  1.18it/s]\u001b[A\n",
            " 55%|█████▌    | 1824/3298 [20:49<20:29,  1.20it/s]\u001b[A\n",
            " 55%|█████▌    | 1825/3298 [20:50<20:16,  1.21it/s]\u001b[A\n",
            " 55%|█████▌    | 1826/3298 [20:51<19:56,  1.23it/s]\u001b[A\n",
            " 55%|█████▌    | 1827/3298 [20:51<18:40,  1.31it/s]\u001b[A\n",
            " 55%|█████▌    | 1828/3298 [20:52<17:44,  1.38it/s]\u001b[A\n",
            " 55%|█████▌    | 1829/3298 [20:53<17:12,  1.42it/s]\u001b[A\n",
            " 55%|█████▌    | 1830/3298 [20:54<19:49,  1.23it/s]\u001b[A\n",
            " 56%|█████▌    | 1831/3298 [20:54<18:40,  1.31it/s]\u001b[A\n",
            " 56%|█████▌    | 1832/3298 [20:55<17:45,  1.38it/s]\u001b[A\n",
            " 56%|█████▌    | 1833/3298 [20:56<17:16,  1.41it/s]\u001b[A\n",
            " 56%|█████▌    | 1834/3298 [20:56<16:48,  1.45it/s]\u001b[A\n",
            " 56%|█████▌    | 1835/3298 [20:57<16:28,  1.48it/s]\u001b[A\n",
            " 56%|█████▌    | 1836/3298 [20:58<16:16,  1.50it/s]\u001b[A\n",
            " 56%|█████▌    | 1837/3298 [20:58<16:12,  1.50it/s]\u001b[A\n",
            " 56%|█████▌    | 1838/3298 [20:59<16:03,  1.51it/s]\u001b[A\n",
            " 56%|█████▌    | 1839/3298 [21:00<14:56,  1.63it/s]\u001b[A\n",
            " 56%|█████▌    | 1840/3298 [21:00<15:04,  1.61it/s]\u001b[A\n",
            " 56%|█████▌    | 1841/3298 [21:01<15:21,  1.58it/s]\u001b[A\n",
            " 56%|█████▌    | 1842/3298 [21:02<15:35,  1.56it/s]\u001b[A\n",
            " 56%|█████▌    | 1843/3298 [21:02<17:43,  1.37it/s]\u001b[A\n",
            " 56%|█████▌    | 1844/3298 [21:03<18:04,  1.34it/s]\u001b[A\n",
            " 56%|█████▌    | 1845/3298 [21:04<18:20,  1.32it/s]\u001b[A\n",
            " 56%|█████▌    | 1846/3298 [21:05<17:39,  1.37it/s]\u001b[A\n",
            " 56%|█████▌    | 1847/3298 [21:05<16:59,  1.42it/s]\u001b[A\n",
            " 56%|█████▌    | 1848/3298 [21:06<16:34,  1.46it/s]\u001b[A\n",
            " 56%|█████▌    | 1849/3298 [21:07<16:14,  1.49it/s]\u001b[A\n",
            " 56%|█████▌    | 1850/3298 [21:08<17:57,  1.34it/s]\u001b[A\n",
            " 56%|█████▌    | 1851/3298 [21:08<18:17,  1.32it/s]\u001b[A\n",
            " 56%|█████▌    | 1852/3298 [21:09<18:24,  1.31it/s]\u001b[A\n",
            " 56%|█████▌    | 1853/3298 [21:10<18:25,  1.31it/s]\u001b[A\n",
            " 56%|█████▌    | 1854/3298 [21:11<18:27,  1.30it/s]\u001b[A\n",
            " 56%|█████▌    | 1855/3298 [21:11<18:38,  1.29it/s]\u001b[A\n",
            " 56%|█████▋    | 1856/3298 [21:12<18:44,  1.28it/s]\u001b[A\n",
            " 56%|█████▋    | 1857/3298 [21:13<17:47,  1.35it/s]\u001b[A\n",
            " 56%|█████▋    | 1858/3298 [21:14<18:11,  1.32it/s]\u001b[A\n",
            " 56%|█████▋    | 1859/3298 [21:14<17:25,  1.38it/s]\u001b[A\n",
            " 56%|█████▋    | 1860/3298 [21:15<16:49,  1.42it/s]\u001b[A\n",
            " 56%|█████▋    | 1861/3298 [21:16<18:24,  1.30it/s]\u001b[A\n",
            " 56%|█████▋    | 1862/3298 [21:17<17:33,  1.36it/s]\u001b[A\n",
            " 56%|█████▋    | 1863/3298 [21:17<17:51,  1.34it/s]\u001b[A\n",
            " 57%|█████▋    | 1864/3298 [21:18<17:11,  1.39it/s]\u001b[A\n",
            " 57%|█████▋    | 1865/3298 [21:19<16:31,  1.45it/s]\u001b[A\n",
            " 57%|█████▋    | 1866/3298 [21:19<18:03,  1.32it/s]\u001b[A\n",
            " 57%|█████▋    | 1867/3298 [21:20<17:21,  1.37it/s]\u001b[A\n",
            " 57%|█████▋    | 1868/3298 [21:21<16:43,  1.43it/s]\u001b[A\n",
            " 57%|█████▋    | 1869/3298 [21:21<15:23,  1.55it/s]\u001b[A\n",
            " 57%|█████▋    | 1870/3298 [21:22<15:26,  1.54it/s]\u001b[A\n",
            " 57%|█████▋    | 1871/3298 [21:23<15:24,  1.54it/s]\u001b[A\n",
            " 57%|█████▋    | 1872/3298 [21:23<14:25,  1.65it/s]\u001b[A\n",
            " 57%|█████▋    | 1873/3298 [21:24<13:39,  1.74it/s]\u001b[A\n",
            " 57%|█████▋    | 1874/3298 [21:24<15:10,  1.56it/s]\u001b[A\n",
            " 57%|█████▋    | 1875/3298 [21:25<14:07,  1.68it/s]\u001b[A\n",
            " 57%|█████▋    | 1876/3298 [21:26<14:25,  1.64it/s]\u001b[A\n",
            " 57%|█████▋    | 1877/3298 [21:26<13:38,  1.74it/s]\u001b[A\n",
            " 57%|█████▋    | 1878/3298 [21:27<14:01,  1.69it/s]\u001b[A\n",
            " 57%|█████▋    | 1879/3298 [21:27<14:15,  1.66it/s]\u001b[A\n",
            " 57%|█████▋    | 1880/3298 [21:28<14:35,  1.62it/s]\u001b[A\n",
            " 57%|█████▋    | 1881/3298 [21:29<14:44,  1.60it/s]\u001b[A\n",
            " 57%|█████▋    | 1882/3298 [21:29<14:00,  1.68it/s]\u001b[A\n",
            " 57%|█████▋    | 1883/3298 [21:30<14:24,  1.64it/s]\u001b[A\n",
            " 57%|█████▋    | 1884/3298 [21:31<16:28,  1.43it/s]\u001b[A\n",
            " 57%|█████▋    | 1885/3298 [21:31<16:59,  1.39it/s]\u001b[A\n",
            " 57%|█████▋    | 1886/3298 [21:32<18:28,  1.27it/s]\u001b[A\n",
            " 57%|█████▋    | 1887/3298 [21:33<17:31,  1.34it/s]\u001b[A\n",
            " 57%|█████▋    | 1888/3298 [21:34<17:41,  1.33it/s]\u001b[A\n",
            " 57%|█████▋    | 1889/3298 [21:35<17:57,  1.31it/s]\u001b[A\n",
            " 57%|█████▋    | 1890/3298 [21:35<18:12,  1.29it/s]\u001b[A\n",
            " 57%|█████▋    | 1891/3298 [21:36<19:19,  1.21it/s]\u001b[A\n",
            " 57%|█████▋    | 1892/3298 [21:37<18:03,  1.30it/s]\u001b[A\n",
            " 57%|█████▋    | 1893/3298 [21:38<18:09,  1.29it/s]\u001b[A\n",
            " 57%|█████▋    | 1894/3298 [21:39<18:24,  1.27it/s]\u001b[A\n",
            " 57%|█████▋    | 1895/3298 [21:39<18:22,  1.27it/s]\u001b[A\n",
            " 57%|█████▋    | 1896/3298 [21:40<18:36,  1.26it/s]\u001b[A\n",
            " 58%|█████▊    | 1897/3298 [21:41<18:31,  1.26it/s]\u001b[A\n",
            " 58%|█████▊    | 1898/3298 [21:42<18:42,  1.25it/s]\u001b[A\n",
            " 58%|█████▊    | 1899/3298 [21:42<16:48,  1.39it/s]\u001b[A\n",
            " 58%|█████▊    | 1900/3298 [21:43<16:12,  1.44it/s]\u001b[A\n",
            " 58%|█████▊    | 1901/3298 [21:44<15:52,  1.47it/s]\u001b[A\n",
            " 58%|█████▊    | 1902/3298 [21:44<16:36,  1.40it/s]\u001b[A\n",
            " 58%|█████▊    | 1903/3298 [21:45<16:13,  1.43it/s]\u001b[A\n",
            " 58%|█████▊    | 1904/3298 [21:46<17:57,  1.29it/s]\u001b[A\n",
            " 58%|█████▊    | 1905/3298 [21:47<18:06,  1.28it/s]\u001b[A\n",
            " 58%|█████▊    | 1906/3298 [21:48<18:07,  1.28it/s]\u001b[A\n",
            " 58%|█████▊    | 1907/3298 [21:48<17:20,  1.34it/s]\u001b[A\n",
            " 58%|█████▊    | 1908/3298 [21:49<17:25,  1.33it/s]\u001b[A\n",
            " 58%|█████▊    | 1909/3298 [21:50<16:41,  1.39it/s]\u001b[A\n",
            " 58%|█████▊    | 1910/3298 [21:50<16:20,  1.42it/s]\u001b[A\n",
            " 58%|█████▊    | 1911/3298 [21:51<15:57,  1.45it/s]\u001b[A\n",
            " 58%|█████▊    | 1912/3298 [21:52<15:38,  1.48it/s]\u001b[A\n",
            " 58%|█████▊    | 1913/3298 [21:52<16:23,  1.41it/s]\u001b[A\n",
            " 58%|█████▊    | 1914/3298 [21:53<14:57,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1915/3298 [21:54<14:59,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1916/3298 [21:54<13:58,  1.65it/s]\u001b[A\n",
            " 58%|█████▊    | 1917/3298 [21:55<13:19,  1.73it/s]\u001b[A\n",
            " 58%|█████▊    | 1918/3298 [21:56<17:26,  1.32it/s]\u001b[A\n",
            " 58%|█████▊    | 1919/3298 [21:56<15:42,  1.46it/s]\u001b[A\n",
            " 58%|█████▊    | 1920/3298 [21:57<15:25,  1.49it/s]\u001b[A\n",
            " 58%|█████▊    | 1921/3298 [21:58<15:11,  1.51it/s]\u001b[A\n",
            " 58%|█████▊    | 1922/3298 [21:58<15:02,  1.52it/s]\u001b[A\n",
            " 58%|█████▊    | 1923/3298 [21:59<14:56,  1.53it/s]\u001b[A\n",
            " 58%|█████▊    | 1924/3298 [22:00<14:54,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1925/3298 [22:00<14:50,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1926/3298 [22:01<14:51,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1927/3298 [22:01<14:47,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1928/3298 [22:02<14:50,  1.54it/s]\u001b[A\n",
            " 58%|█████▊    | 1929/3298 [22:03<14:50,  1.54it/s]\u001b[A\n",
            " 59%|█████▊    | 1930/3298 [22:03<14:43,  1.55it/s]\u001b[A\n",
            " 59%|█████▊    | 1931/3298 [22:04<14:41,  1.55it/s]\u001b[A\n",
            " 59%|█████▊    | 1932/3298 [22:05<14:53,  1.53it/s]\u001b[A\n",
            " 59%|█████▊    | 1933/3298 [22:06<16:45,  1.36it/s]\u001b[A\n",
            " 59%|█████▊    | 1934/3298 [22:06<17:04,  1.33it/s]\u001b[A\n",
            " 59%|█████▊    | 1935/3298 [22:07<16:17,  1.39it/s]\u001b[A\n",
            " 59%|█████▊    | 1936/3298 [22:08<14:52,  1.53it/s]\u001b[A\n",
            " 59%|█████▊    | 1937/3298 [22:09<17:28,  1.30it/s]\u001b[A\n",
            " 59%|█████▉    | 1938/3298 [22:09<17:28,  1.30it/s]\u001b[A\n",
            " 59%|█████▉    | 1939/3298 [22:10<19:14,  1.18it/s]\u001b[A\n",
            " 59%|█████▉    | 1940/3298 [22:11<17:49,  1.27it/s]\u001b[A\n",
            " 59%|█████▉    | 1941/3298 [22:12<16:47,  1.35it/s]\u001b[A\n",
            " 59%|█████▉    | 1942/3298 [22:12<16:59,  1.33it/s]\u001b[A\n",
            " 59%|█████▉    | 1943/3298 [22:13<17:18,  1.30it/s]\u001b[A\n",
            " 59%|█████▉    | 1944/3298 [22:14<16:30,  1.37it/s]\u001b[A\n",
            " 59%|█████▉    | 1945/3298 [22:15<15:53,  1.42it/s]\u001b[A\n",
            " 59%|█████▉    | 1946/3298 [22:15<17:16,  1.30it/s]\u001b[A\n",
            " 59%|█████▉    | 1947/3298 [22:16<16:25,  1.37it/s]\u001b[A\n",
            " 59%|█████▉    | 1948/3298 [22:17<16:49,  1.34it/s]\u001b[A\n",
            " 59%|█████▉    | 1949/3298 [22:18<17:00,  1.32it/s]\u001b[A\n",
            " 59%|█████▉    | 1950/3298 [22:18<16:18,  1.38it/s]\u001b[A\n",
            " 59%|█████▉    | 1951/3298 [22:19<14:46,  1.52it/s]\u001b[A\n",
            " 59%|█████▉    | 1952/3298 [22:19<14:38,  1.53it/s]\u001b[A\n",
            " 59%|█████▉    | 1953/3298 [22:20<14:35,  1.54it/s]\u001b[A\n",
            " 59%|█████▉    | 1954/3298 [22:21<14:29,  1.55it/s]\u001b[A\n",
            " 59%|█████▉    | 1955/3298 [22:21<14:31,  1.54it/s]\u001b[A\n",
            " 59%|█████▉    | 1956/3298 [22:22<14:27,  1.55it/s]\u001b[A\n",
            " 59%|█████▉    | 1957/3298 [22:23<14:26,  1.55it/s]\u001b[A\n",
            " 59%|█████▉    | 1958/3298 [22:23<14:27,  1.54it/s]\u001b[A\n",
            " 59%|█████▉    | 1959/3298 [22:24<13:32,  1.65it/s]\u001b[A\n",
            " 59%|█████▉    | 1960/3298 [22:25<13:45,  1.62it/s]\u001b[A\n",
            " 59%|█████▉    | 1961/3298 [22:25<15:08,  1.47it/s]\u001b[A\n",
            " 59%|█████▉    | 1962/3298 [22:26<15:51,  1.40it/s]\u001b[A\n",
            " 60%|█████▉    | 1963/3298 [22:27<15:21,  1.45it/s]\u001b[A\n",
            " 60%|█████▉    | 1964/3298 [22:27<15:04,  1.47it/s]\u001b[A\n",
            " 60%|█████▉    | 1965/3298 [22:28<14:54,  1.49it/s]\u001b[A\n",
            " 60%|█████▉    | 1966/3298 [22:29<14:43,  1.51it/s]\u001b[A\n",
            " 60%|█████▉    | 1967/3298 [22:29<14:34,  1.52it/s]\u001b[A\n",
            " 60%|█████▉    | 1968/3298 [22:30<14:25,  1.54it/s]\u001b[A\n",
            " 60%|█████▉    | 1969/3298 [22:31<17:00,  1.30it/s]\u001b[A\n",
            " 60%|█████▉    | 1970/3298 [22:32<16:13,  1.36it/s]\u001b[A\n",
            " 60%|█████▉    | 1971/3298 [22:32<15:31,  1.42it/s]\u001b[A\n",
            " 60%|█████▉    | 1972/3298 [22:33<15:59,  1.38it/s]\u001b[A\n",
            " 60%|█████▉    | 1973/3298 [22:34<16:29,  1.34it/s]\u001b[A\n",
            " 60%|█████▉    | 1974/3298 [22:35<15:47,  1.40it/s]\u001b[A\n",
            " 60%|█████▉    | 1975/3298 [22:35<14:21,  1.54it/s]\u001b[A\n",
            " 60%|█████▉    | 1976/3298 [22:36<14:24,  1.53it/s]\u001b[A\n",
            " 60%|█████▉    | 1977/3298 [22:36<13:21,  1.65it/s]\u001b[A\n",
            " 60%|█████▉    | 1978/3298 [22:37<12:38,  1.74it/s]\u001b[A\n",
            " 60%|██████    | 1979/3298 [22:37<13:53,  1.58it/s]\u001b[A\n",
            " 60%|██████    | 1980/3298 [22:39<16:40,  1.32it/s]\u001b[A\n",
            " 60%|██████    | 1981/3298 [22:39<16:46,  1.31it/s]\u001b[A\n",
            " 60%|██████    | 1982/3298 [22:40<17:46,  1.23it/s]\u001b[A\n",
            " 60%|██████    | 1983/3298 [22:41<17:32,  1.25it/s]\u001b[A\n",
            " 60%|██████    | 1984/3298 [22:42<17:27,  1.25it/s]\u001b[A\n",
            " 60%|██████    | 1985/3298 [22:43<18:04,  1.21it/s]\u001b[A\n",
            " 60%|██████    | 1986/3298 [22:43<17:44,  1.23it/s]\u001b[A\n",
            " 60%|██████    | 1987/3298 [22:44<17:37,  1.24it/s]\u001b[A\n",
            " 60%|██████    | 1988/3298 [22:45<16:32,  1.32it/s]\u001b[A\n",
            " 60%|██████    | 1989/3298 [22:46<15:52,  1.37it/s]\u001b[A\n",
            " 60%|██████    | 1990/3298 [22:46<15:24,  1.41it/s]\u001b[A\n",
            " 60%|██████    | 1991/3298 [22:47<15:01,  1.45it/s]\u001b[A\n",
            " 60%|██████    | 1992/3298 [22:47<14:46,  1.47it/s]\u001b[A\n",
            " 60%|██████    | 1993/3298 [22:48<14:33,  1.49it/s]\u001b[A\n",
            " 60%|██████    | 1994/3298 [22:49<14:26,  1.50it/s]\u001b[A\n",
            " 60%|██████    | 1995/3298 [22:50<15:10,  1.43it/s]\u001b[A\n",
            " 61%|██████    | 1996/3298 [22:50<14:51,  1.46it/s]\u001b[A\n",
            " 61%|██████    | 1997/3298 [22:51<14:37,  1.48it/s]\u001b[A\n",
            " 61%|██████    | 1998/3298 [22:52<14:29,  1.49it/s]\u001b[A\n",
            " 61%|██████    | 1999/3298 [22:52<15:10,  1.43it/s]\u001b[A\n",
            " 61%|██████    | 2000/3298 [22:53<15:40,  1.38it/s]\u001b[A\n",
            " 61%|██████    | 2001/3298 [22:54<16:04,  1.34it/s]\u001b[A\n",
            " 61%|██████    | 2002/3298 [22:55<15:27,  1.40it/s]\u001b[A\n",
            " 61%|██████    | 2003/3298 [22:55<14:57,  1.44it/s]\u001b[A\n",
            " 61%|██████    | 2004/3298 [22:56<15:25,  1.40it/s]\u001b[A\n",
            " 61%|██████    | 2005/3298 [22:57<15:04,  1.43it/s]\u001b[A\n",
            " 61%|██████    | 2006/3298 [22:57<14:51,  1.45it/s]\u001b[A\n",
            " 61%|██████    | 2007/3298 [22:58<15:26,  1.39it/s]\u001b[A\n",
            " 61%|██████    | 2008/3298 [22:59<16:43,  1.29it/s]\u001b[A\n",
            " 61%|██████    | 2009/3298 [23:00<17:25,  1.23it/s]\u001b[A\n",
            " 61%|██████    | 2010/3298 [23:01<17:14,  1.25it/s]\u001b[A\n",
            " 61%|██████    | 2011/3298 [23:02<17:55,  1.20it/s]\u001b[A\n",
            " 61%|██████    | 2012/3298 [23:02<17:30,  1.22it/s]\u001b[A\n",
            " 61%|██████    | 2013/3298 [23:03<18:06,  1.18it/s]\u001b[A\n",
            " 61%|██████    | 2014/3298 [23:04<17:38,  1.21it/s]\u001b[A\n",
            " 61%|██████    | 2015/3298 [23:05<16:24,  1.30it/s]\u001b[A\n",
            " 61%|██████    | 2016/3298 [23:05<16:26,  1.30it/s]\u001b[A\n",
            " 61%|██████    | 2017/3298 [23:06<16:29,  1.30it/s]\u001b[A\n",
            " 61%|██████    | 2018/3298 [23:07<16:31,  1.29it/s]\u001b[A\n",
            " 61%|██████    | 2019/3298 [23:08<15:42,  1.36it/s]\u001b[A\n",
            " 61%|██████    | 2020/3298 [23:09<16:41,  1.28it/s]\u001b[A\n",
            " 61%|██████▏   | 2021/3298 [23:09<15:42,  1.36it/s]\u001b[A\n",
            " 61%|██████▏   | 2022/3298 [23:10<15:01,  1.42it/s]\u001b[A\n",
            " 61%|██████▏   | 2023/3298 [23:10<14:39,  1.45it/s]\u001b[A\n",
            " 61%|██████▏   | 2024/3298 [23:11<13:29,  1.57it/s]\u001b[A\n",
            " 61%|██████▏   | 2025/3298 [23:12<13:29,  1.57it/s]\u001b[A\n",
            " 61%|██████▏   | 2026/3298 [23:12<13:28,  1.57it/s]\u001b[A\n",
            " 61%|██████▏   | 2027/3298 [23:13<13:27,  1.57it/s]\u001b[A\n",
            " 61%|██████▏   | 2028/3298 [23:13<13:27,  1.57it/s]\u001b[A\n",
            " 62%|██████▏   | 2029/3298 [23:14<13:37,  1.55it/s]\u001b[A\n",
            " 62%|██████▏   | 2030/3298 [23:15<13:38,  1.55it/s]\u001b[A\n",
            " 62%|██████▏   | 2031/3298 [23:16<14:30,  1.46it/s]\u001b[A\n",
            " 62%|██████▏   | 2032/3298 [23:16<14:17,  1.48it/s]\u001b[A\n",
            " 62%|██████▏   | 2033/3298 [23:17<14:12,  1.48it/s]\u001b[A\n",
            " 62%|██████▏   | 2034/3298 [23:18<14:05,  1.49it/s]\u001b[A\n",
            " 62%|██████▏   | 2035/3298 [23:18<14:56,  1.41it/s]\u001b[A\n",
            " 62%|██████▏   | 2036/3298 [23:19<14:39,  1.44it/s]\u001b[A\n",
            " 62%|██████▏   | 2037/3298 [23:20<14:24,  1.46it/s]\u001b[A\n",
            " 62%|██████▏   | 2038/3298 [23:20<13:22,  1.57it/s]\u001b[A\n",
            " 62%|██████▏   | 2039/3298 [23:21<12:32,  1.67it/s]\u001b[A\n",
            " 62%|██████▏   | 2040/3298 [23:21<12:08,  1.73it/s]\u001b[A\n",
            " 62%|██████▏   | 2041/3298 [23:22<12:30,  1.68it/s]\u001b[A\n",
            " 62%|██████▏   | 2042/3298 [23:22<12:09,  1.72it/s]\u001b[A\n",
            " 62%|██████▏   | 2043/3298 [23:23<11:45,  1.78it/s]\u001b[A\n",
            " 62%|██████▏   | 2044/3298 [23:23<11:30,  1.82it/s]\u001b[A\n",
            " 62%|██████▏   | 2045/3298 [23:24<12:08,  1.72it/s]\u001b[A\n",
            " 62%|██████▏   | 2046/3298 [23:25<14:20,  1.45it/s]\u001b[A\n",
            " 62%|██████▏   | 2047/3298 [23:26<15:41,  1.33it/s]\u001b[A\n",
            " 62%|██████▏   | 2048/3298 [23:27<15:05,  1.38it/s]\u001b[A\n",
            " 62%|██████▏   | 2049/3298 [23:27<15:41,  1.33it/s]\u001b[A\n",
            " 62%|██████▏   | 2050/3298 [23:28<16:48,  1.24it/s]\u001b[A\n",
            " 62%|██████▏   | 2051/3298 [23:29<15:49,  1.31it/s]\u001b[A\n",
            " 62%|██████▏   | 2052/3298 [23:30<15:08,  1.37it/s]\u001b[A\n",
            " 62%|██████▏   | 2053/3298 [23:30<14:37,  1.42it/s]\u001b[A\n",
            " 62%|██████▏   | 2054/3298 [23:31<13:31,  1.53it/s]\u001b[A\n",
            " 62%|██████▏   | 2055/3298 [23:32<13:33,  1.53it/s]\u001b[A\n",
            " 62%|██████▏   | 2056/3298 [23:32<14:22,  1.44it/s]\u001b[A\n",
            " 62%|██████▏   | 2057/3298 [23:33<14:09,  1.46it/s]\u001b[A\n",
            " 62%|██████▏   | 2058/3298 [23:34<14:07,  1.46it/s]\u001b[A\n",
            " 62%|██████▏   | 2059/3298 [23:34<14:04,  1.47it/s]\u001b[A\n",
            " 62%|██████▏   | 2060/3298 [23:35<13:06,  1.57it/s]\u001b[A\n",
            " 62%|██████▏   | 2061/3298 [23:36<13:20,  1.55it/s]\u001b[A\n",
            " 63%|██████▎   | 2062/3298 [23:36<13:28,  1.53it/s]\u001b[A\n",
            " 63%|██████▎   | 2063/3298 [23:37<13:30,  1.52it/s]\u001b[A\n",
            " 63%|██████▎   | 2064/3298 [23:38<14:23,  1.43it/s]\u001b[A\n",
            " 63%|██████▎   | 2065/3298 [23:39<16:28,  1.25it/s]\u001b[A\n",
            " 63%|██████▎   | 2066/3298 [23:39<14:44,  1.39it/s]\u001b[A\n",
            " 63%|██████▎   | 2067/3298 [23:40<14:20,  1.43it/s]\u001b[A\n",
            " 63%|██████▎   | 2068/3298 [23:41<14:00,  1.46it/s]\u001b[A\n",
            " 63%|██████▎   | 2069/3298 [23:41<14:46,  1.39it/s]\u001b[A\n",
            " 63%|██████▎   | 2070/3298 [23:42<14:22,  1.42it/s]\u001b[A\n",
            " 63%|██████▎   | 2071/3298 [23:43<14:08,  1.45it/s]\u001b[A\n",
            " 63%|██████▎   | 2072/3298 [23:43<13:58,  1.46it/s]\u001b[A\n",
            " 63%|██████▎   | 2073/3298 [23:44<13:50,  1.48it/s]\u001b[A\n",
            " 63%|██████▎   | 2074/3298 [23:45<13:44,  1.48it/s]\u001b[A\n",
            " 63%|██████▎   | 2075/3298 [23:45<14:35,  1.40it/s]\u001b[A\n",
            " 63%|██████▎   | 2076/3298 [23:46<14:20,  1.42it/s]\u001b[A\n",
            " 63%|██████▎   | 2077/3298 [23:47<14:12,  1.43it/s]\u001b[A\n",
            " 63%|██████▎   | 2078/3298 [23:48<14:04,  1.44it/s]\u001b[A\n",
            " 63%|██████▎   | 2079/3298 [23:48<14:52,  1.37it/s]\u001b[A\n",
            " 63%|██████▎   | 2080/3298 [23:49<15:16,  1.33it/s]\u001b[A\n",
            " 63%|██████▎   | 2081/3298 [23:50<15:33,  1.30it/s]\u001b[A\n",
            " 63%|██████▎   | 2082/3298 [23:51<16:25,  1.23it/s]\u001b[A\n",
            " 63%|██████▎   | 2083/3298 [23:52<16:21,  1.24it/s]\u001b[A\n",
            " 63%|██████▎   | 2084/3298 [23:53<17:09,  1.18it/s]\u001b[A\n",
            " 63%|██████▎   | 2085/3298 [23:53<16:50,  1.20it/s]\u001b[A\n",
            " 63%|██████▎   | 2086/3298 [23:54<15:45,  1.28it/s]\u001b[A\n",
            " 63%|██████▎   | 2087/3298 [23:55<15:04,  1.34it/s]\u001b[A\n",
            " 63%|██████▎   | 2088/3298 [23:56<15:23,  1.31it/s]\u001b[A\n",
            " 63%|██████▎   | 2089/3298 [23:56<15:36,  1.29it/s]\u001b[A\n",
            " 63%|██████▎   | 2090/3298 [23:57<15:46,  1.28it/s]\u001b[A\n",
            " 63%|██████▎   | 2091/3298 [23:58<16:48,  1.20it/s]\u001b[A\n",
            " 63%|██████▎   | 2092/3298 [23:59<15:43,  1.28it/s]\u001b[A\n",
            " 63%|██████▎   | 2093/3298 [24:00<16:40,  1.20it/s]\u001b[A\n",
            " 63%|██████▎   | 2094/3298 [24:01<17:19,  1.16it/s]\u001b[A\n",
            " 64%|██████▎   | 2095/3298 [24:01<16:56,  1.18it/s]\u001b[A\n",
            " 64%|██████▎   | 2096/3298 [24:02<16:42,  1.20it/s]\u001b[A\n",
            " 64%|██████▎   | 2097/3298 [24:03<16:28,  1.22it/s]\u001b[A\n",
            " 64%|██████▎   | 2098/3298 [24:04<16:18,  1.23it/s]\u001b[A\n",
            " 64%|██████▎   | 2099/3298 [24:04<15:22,  1.30it/s]\u001b[A\n",
            " 64%|██████▎   | 2100/3298 [24:05<15:34,  1.28it/s]\u001b[A\n",
            " 64%|██████▎   | 2101/3298 [24:06<15:38,  1.28it/s]\u001b[A\n",
            " 64%|██████▎   | 2102/3298 [24:07<15:44,  1.27it/s]\u001b[A\n",
            " 64%|██████▍   | 2103/3298 [24:08<15:44,  1.27it/s]\u001b[A\n",
            " 64%|██████▍   | 2104/3298 [24:09<16:34,  1.20it/s]\u001b[A\n",
            " 64%|██████▍   | 2105/3298 [24:09<16:27,  1.21it/s]\u001b[A\n",
            " 64%|██████▍   | 2106/3298 [24:10<16:16,  1.22it/s]\u001b[A\n",
            " 64%|██████▍   | 2107/3298 [24:11<18:02,  1.10it/s]\u001b[A\n",
            " 64%|██████▍   | 2108/3298 [24:12<17:26,  1.14it/s]\u001b[A\n",
            " 64%|██████▍   | 2109/3298 [24:13<16:53,  1.17it/s]\u001b[A\n",
            " 64%|██████▍   | 2110/3298 [24:14<16:35,  1.19it/s]\u001b[A\n",
            " 64%|██████▍   | 2111/3298 [24:15<16:22,  1.21it/s]\u001b[A\n",
            " 64%|██████▍   | 2112/3298 [24:15<16:19,  1.21it/s]\u001b[A\n",
            " 64%|██████▍   | 2113/3298 [24:16<16:10,  1.22it/s]\u001b[A\n",
            " 64%|██████▍   | 2114/3298 [24:17<16:09,  1.22it/s]\u001b[A\n",
            " 64%|██████▍   | 2115/3298 [24:18<16:50,  1.17it/s]\u001b[A\n",
            " 64%|██████▍   | 2116/3298 [24:19<16:26,  1.20it/s]\u001b[A\n",
            " 64%|██████▍   | 2117/3298 [24:20<16:17,  1.21it/s]\u001b[A\n",
            " 64%|██████▍   | 2118/3298 [24:20<16:03,  1.22it/s]\u001b[A\n",
            " 64%|██████▍   | 2119/3298 [24:21<15:52,  1.24it/s]\u001b[A\n",
            " 64%|██████▍   | 2120/3298 [24:22<15:48,  1.24it/s]\u001b[A\n",
            " 64%|██████▍   | 2121/3298 [24:23<14:54,  1.32it/s]\u001b[A\n",
            " 64%|██████▍   | 2122/3298 [24:23<14:21,  1.36it/s]\u001b[A\n",
            " 64%|██████▍   | 2123/3298 [24:24<13:56,  1.41it/s]\u001b[A\n",
            " 64%|██████▍   | 2124/3298 [24:25<14:13,  1.38it/s]\u001b[A\n",
            " 64%|██████▍   | 2125/3298 [24:25<13:50,  1.41it/s]\u001b[A\n",
            " 64%|██████▍   | 2126/3298 [24:26<13:19,  1.47it/s]\u001b[A\n",
            " 64%|██████▍   | 2127/3298 [24:27<13:04,  1.49it/s]\u001b[A\n",
            " 65%|██████▍   | 2128/3298 [24:27<12:56,  1.51it/s]\u001b[A\n",
            " 65%|██████▍   | 2129/3298 [24:28<15:29,  1.26it/s]\u001b[A\n",
            " 65%|██████▍   | 2130/3298 [24:29<14:38,  1.33it/s]\u001b[A\n",
            " 65%|██████▍   | 2131/3298 [24:30<13:19,  1.46it/s]\u001b[A\n",
            " 65%|██████▍   | 2132/3298 [24:30<13:51,  1.40it/s]\u001b[A\n",
            " 65%|██████▍   | 2133/3298 [24:31<14:15,  1.36it/s]\u001b[A\n",
            " 65%|██████▍   | 2134/3298 [24:32<13:59,  1.39it/s]\u001b[A\n",
            " 65%|██████▍   | 2135/3298 [24:32<13:34,  1.43it/s]\u001b[A\n",
            " 65%|██████▍   | 2136/3298 [24:33<14:14,  1.36it/s]\u001b[A\n",
            " 65%|██████▍   | 2137/3298 [24:34<13:40,  1.42it/s]\u001b[A\n",
            " 65%|██████▍   | 2138/3298 [24:35<13:17,  1.45it/s]\u001b[A\n",
            " 65%|██████▍   | 2139/3298 [24:35<13:07,  1.47it/s]\u001b[A\n",
            " 65%|██████▍   | 2140/3298 [24:36<12:59,  1.49it/s]\u001b[A\n",
            " 65%|██████▍   | 2141/3298 [24:36<12:47,  1.51it/s]\u001b[A\n",
            " 65%|██████▍   | 2142/3298 [24:37<12:45,  1.51it/s]\u001b[A\n",
            " 65%|██████▍   | 2143/3298 [24:38<12:37,  1.52it/s]\u001b[A\n",
            " 65%|██████▌   | 2144/3298 [24:38<12:34,  1.53it/s]\u001b[A\n",
            " 65%|██████▌   | 2145/3298 [24:39<13:12,  1.46it/s]\u001b[A\n",
            " 65%|██████▌   | 2146/3298 [24:40<12:52,  1.49it/s]\u001b[A\n",
            " 65%|██████▌   | 2147/3298 [24:40<11:53,  1.61it/s]\u001b[A\n",
            " 65%|██████▌   | 2148/3298 [24:41<12:01,  1.59it/s]\u001b[A\n",
            " 65%|██████▌   | 2149/3298 [24:42<12:03,  1.59it/s]\u001b[A\n",
            " 65%|██████▌   | 2150/3298 [24:42<12:08,  1.57it/s]\u001b[A\n",
            " 65%|██████▌   | 2151/3298 [24:43<12:05,  1.58it/s]\u001b[A\n",
            " 65%|██████▌   | 2152/3298 [24:43<11:17,  1.69it/s]\u001b[A\n",
            " 65%|██████▌   | 2153/3298 [24:44<11:36,  1.64it/s]\u001b[A\n",
            " 65%|██████▌   | 2154/3298 [24:45<11:43,  1.63it/s]\u001b[A\n",
            " 65%|██████▌   | 2155/3298 [24:45<11:53,  1.60it/s]\u001b[A\n",
            " 65%|██████▌   | 2156/3298 [24:46<11:12,  1.70it/s]\u001b[A\n",
            " 65%|██████▌   | 2157/3298 [24:46<11:37,  1.64it/s]\u001b[A\n",
            " 65%|██████▌   | 2158/3298 [24:47<11:53,  1.60it/s]\u001b[A\n",
            " 65%|██████▌   | 2159/3298 [24:48<12:46,  1.49it/s]\u001b[A\n",
            " 65%|██████▌   | 2160/3298 [24:49<12:36,  1.50it/s]\u001b[A\n",
            " 66%|██████▌   | 2161/3298 [24:49<12:30,  1.51it/s]\u001b[A\n",
            " 66%|██████▌   | 2162/3298 [24:50<12:23,  1.53it/s]\u001b[A\n",
            " 66%|██████▌   | 2163/3298 [24:51<13:52,  1.36it/s]\u001b[A\n",
            " 66%|██████▌   | 2164/3298 [24:51<13:19,  1.42it/s]\u001b[A\n",
            " 66%|██████▌   | 2165/3298 [24:52<13:41,  1.38it/s]\u001b[A\n",
            " 66%|██████▌   | 2166/3298 [24:53<14:03,  1.34it/s]\u001b[A\n",
            " 66%|██████▌   | 2167/3298 [24:54<13:30,  1.40it/s]\u001b[A\n",
            " 66%|██████▌   | 2168/3298 [24:54<13:51,  1.36it/s]\u001b[A\n",
            " 66%|██████▌   | 2169/3298 [24:55<13:21,  1.41it/s]\u001b[A\n",
            " 66%|██████▌   | 2170/3298 [24:56<13:02,  1.44it/s]\u001b[A\n",
            " 66%|██████▌   | 2171/3298 [24:57<14:22,  1.31it/s]\u001b[A\n",
            " 66%|██████▌   | 2172/3298 [24:57<14:28,  1.30it/s]\u001b[A\n",
            " 66%|██████▌   | 2173/3298 [24:58<13:45,  1.36it/s]\u001b[A\n",
            " 66%|██████▌   | 2174/3298 [24:59<13:14,  1.42it/s]\u001b[A\n",
            " 66%|██████▌   | 2175/3298 [25:00<13:36,  1.38it/s]\u001b[A\n",
            " 66%|██████▌   | 2176/3298 [25:00<13:53,  1.35it/s]\u001b[A\n",
            " 66%|██████▌   | 2177/3298 [25:01<14:02,  1.33it/s]\u001b[A\n",
            " 66%|██████▌   | 2178/3298 [25:02<13:26,  1.39it/s]\u001b[A\n",
            " 66%|██████▌   | 2179/3298 [25:02<13:06,  1.42it/s]\u001b[A\n",
            " 66%|██████▌   | 2180/3298 [25:03<12:49,  1.45it/s]\u001b[A\n",
            " 66%|██████▌   | 2181/3298 [25:04<12:37,  1.48it/s]\u001b[A\n",
            " 66%|██████▌   | 2182/3298 [25:04<13:10,  1.41it/s]\u001b[A\n",
            " 66%|██████▌   | 2183/3298 [25:05<12:48,  1.45it/s]\u001b[A\n",
            " 66%|██████▌   | 2184/3298 [25:06<12:36,  1.47it/s]\u001b[A\n",
            " 66%|██████▋   | 2185/3298 [25:06<12:28,  1.49it/s]\u001b[A\n",
            " 66%|██████▋   | 2186/3298 [25:07<12:18,  1.51it/s]\u001b[A\n",
            " 66%|██████▋   | 2187/3298 [25:08<12:16,  1.51it/s]\u001b[A\n",
            " 66%|██████▋   | 2188/3298 [25:08<12:55,  1.43it/s]\u001b[A\n",
            " 66%|██████▋   | 2189/3298 [25:09<13:25,  1.38it/s]\u001b[A\n",
            " 66%|██████▋   | 2190/3298 [25:10<13:39,  1.35it/s]\u001b[A\n",
            " 66%|██████▋   | 2191/3298 [25:11<14:41,  1.26it/s]\u001b[A\n",
            " 66%|██████▋   | 2192/3298 [25:12<15:28,  1.19it/s]\u001b[A\n",
            " 66%|██████▋   | 2193/3298 [25:13<15:09,  1.22it/s]\u001b[A\n",
            " 67%|██████▋   | 2194/3298 [25:14<14:59,  1.23it/s]\u001b[A\n",
            " 67%|██████▋   | 2195/3298 [25:14<14:54,  1.23it/s]\u001b[A\n",
            " 67%|██████▋   | 2196/3298 [25:15<15:23,  1.19it/s]\u001b[A\n",
            " 67%|██████▋   | 2197/3298 [25:16<14:58,  1.23it/s]\u001b[A\n",
            " 67%|██████▋   | 2198/3298 [25:17<14:46,  1.24it/s]\u001b[A\n",
            " 67%|██████▋   | 2199/3298 [25:18<14:31,  1.26it/s]\u001b[A\n",
            " 67%|██████▋   | 2200/3298 [25:18<14:24,  1.27it/s]\u001b[A\n",
            " 67%|██████▋   | 2201/3298 [25:19<13:42,  1.33it/s]\u001b[A\n",
            " 67%|██████▋   | 2202/3298 [25:20<13:51,  1.32it/s]\u001b[A\n",
            " 67%|██████▋   | 2203/3298 [25:21<13:56,  1.31it/s]\u001b[A\n",
            " 67%|██████▋   | 2204/3298 [25:21<14:00,  1.30it/s]\u001b[A\n",
            " 67%|██████▋   | 2205/3298 [25:22<13:16,  1.37it/s]\u001b[A\n",
            " 67%|██████▋   | 2206/3298 [25:23<13:30,  1.35it/s]\u001b[A\n",
            " 67%|██████▋   | 2207/3298 [25:23<13:37,  1.34it/s]\u001b[A\n",
            " 67%|██████▋   | 2208/3298 [25:24<13:48,  1.32it/s]\u001b[A\n",
            " 67%|██████▋   | 2209/3298 [25:25<14:41,  1.24it/s]\u001b[A\n",
            " 67%|██████▋   | 2210/3298 [25:26<14:34,  1.24it/s]\u001b[A\n",
            " 67%|██████▋   | 2211/3298 [25:27<13:41,  1.32it/s]\u001b[A\n",
            " 67%|██████▋   | 2212/3298 [25:27<13:45,  1.32it/s]\u001b[A\n",
            " 67%|██████▋   | 2213/3298 [25:28<13:06,  1.38it/s]\u001b[A\n",
            " 67%|██████▋   | 2214/3298 [25:29<12:43,  1.42it/s]\u001b[A\n",
            " 67%|██████▋   | 2215/3298 [25:29<12:20,  1.46it/s]\u001b[A\n",
            " 67%|██████▋   | 2216/3298 [25:30<12:06,  1.49it/s]\u001b[A\n",
            " 67%|██████▋   | 2217/3298 [25:31<11:50,  1.52it/s]\u001b[A\n",
            " 67%|██████▋   | 2218/3298 [25:31<11:42,  1.54it/s]\u001b[A\n",
            " 67%|██████▋   | 2219/3298 [25:32<10:54,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 2220/3298 [25:32<11:05,  1.62it/s]\u001b[A\n",
            " 67%|██████▋   | 2221/3298 [25:33<11:13,  1.60it/s]\u001b[A\n",
            " 67%|██████▋   | 2222/3298 [25:34<11:21,  1.58it/s]\u001b[A\n",
            " 67%|██████▋   | 2223/3298 [25:34<11:34,  1.55it/s]\u001b[A\n",
            " 67%|██████▋   | 2224/3298 [25:35<10:51,  1.65it/s]\u001b[A\n",
            " 67%|██████▋   | 2225/3298 [25:36<11:45,  1.52it/s]\u001b[A\n",
            " 67%|██████▋   | 2226/3298 [25:36<11:01,  1.62it/s]\u001b[A\n",
            " 68%|██████▊   | 2227/3298 [25:37<11:07,  1.60it/s]\u001b[A\n",
            " 68%|██████▊   | 2228/3298 [25:37<10:33,  1.69it/s]\u001b[A\n",
            " 68%|██████▊   | 2229/3298 [25:38<10:08,  1.76it/s]\u001b[A\n",
            " 68%|██████▊   | 2230/3298 [25:38<10:34,  1.68it/s]\u001b[A\n",
            " 68%|██████▊   | 2231/3298 [25:39<10:53,  1.63it/s]\u001b[A\n",
            " 68%|██████▊   | 2232/3298 [25:40<11:00,  1.61it/s]\u001b[A\n",
            " 68%|██████▊   | 2233/3298 [25:40<11:03,  1.61it/s]\u001b[A\n",
            " 68%|██████▊   | 2234/3298 [25:41<11:11,  1.58it/s]\u001b[A\n",
            " 68%|██████▊   | 2235/3298 [25:42<11:55,  1.49it/s]\u001b[A\n",
            " 68%|██████▊   | 2236/3298 [25:43<12:27,  1.42it/s]\u001b[A\n",
            " 68%|██████▊   | 2237/3298 [25:43<12:51,  1.38it/s]\u001b[A\n",
            " 68%|██████▊   | 2238/3298 [25:44<12:22,  1.43it/s]\u001b[A\n",
            " 68%|██████▊   | 2239/3298 [25:45<12:45,  1.38it/s]\u001b[A\n",
            " 68%|██████▊   | 2240/3298 [25:45<12:23,  1.42it/s]\u001b[A\n",
            " 68%|██████▊   | 2241/3298 [25:46<12:06,  1.45it/s]\u001b[A\n",
            " 68%|██████▊   | 2242/3298 [25:47<11:53,  1.48it/s]\u001b[A\n",
            " 68%|██████▊   | 2243/3298 [25:47<11:45,  1.50it/s]\u001b[A\n",
            " 68%|██████▊   | 2244/3298 [25:48<11:34,  1.52it/s]\u001b[A\n",
            " 68%|██████▊   | 2245/3298 [25:49<11:26,  1.53it/s]\u001b[A\n",
            " 68%|██████▊   | 2246/3298 [25:49<12:12,  1.44it/s]\u001b[A\n",
            " 68%|██████▊   | 2247/3298 [25:50<13:23,  1.31it/s]\u001b[A\n",
            " 68%|██████▊   | 2248/3298 [25:51<12:42,  1.38it/s]\u001b[A\n",
            " 68%|██████▊   | 2249/3298 [25:52<12:24,  1.41it/s]\u001b[A\n",
            " 68%|██████▊   | 2250/3298 [25:52<12:05,  1.44it/s]\u001b[A\n",
            " 68%|██████▊   | 2251/3298 [25:53<12:30,  1.39it/s]\u001b[A\n",
            " 68%|██████▊   | 2252/3298 [25:54<12:52,  1.35it/s]\u001b[A\n",
            " 68%|██████▊   | 2253/3298 [25:55<13:03,  1.33it/s]\u001b[A\n",
            " 68%|██████▊   | 2254/3298 [25:55<12:30,  1.39it/s]\u001b[A\n",
            " 68%|██████▊   | 2255/3298 [25:56<12:10,  1.43it/s]\u001b[A\n",
            " 68%|██████▊   | 2256/3298 [25:57<11:55,  1.46it/s]\u001b[A\n",
            " 68%|██████▊   | 2257/3298 [25:57<11:40,  1.49it/s]\u001b[A\n",
            " 68%|██████▊   | 2258/3298 [25:58<11:29,  1.51it/s]\u001b[A\n",
            " 68%|██████▊   | 2259/3298 [25:59<12:09,  1.43it/s]\u001b[A\n",
            " 69%|██████▊   | 2260/3298 [25:59<11:51,  1.46it/s]\u001b[A\n",
            " 69%|██████▊   | 2261/3298 [26:00<11:38,  1.49it/s]\u001b[A\n",
            " 69%|██████▊   | 2262/3298 [26:01<11:33,  1.49it/s]\u001b[A\n",
            " 69%|██████▊   | 2263/3298 [26:01<11:29,  1.50it/s]\u001b[A\n",
            " 69%|██████▊   | 2264/3298 [26:02<12:02,  1.43it/s]\u001b[A\n",
            " 69%|██████▊   | 2265/3298 [26:03<12:24,  1.39it/s]\u001b[A\n",
            " 69%|██████▊   | 2266/3298 [26:04<12:02,  1.43it/s]\u001b[A\n",
            " 69%|██████▊   | 2267/3298 [26:04<11:47,  1.46it/s]\u001b[A\n",
            " 69%|██████▉   | 2268/3298 [26:05<10:50,  1.58it/s]\u001b[A\n",
            " 69%|██████▉   | 2269/3298 [26:05<10:49,  1.58it/s]\u001b[A\n",
            " 69%|██████▉   | 2270/3298 [26:06<10:54,  1.57it/s]\u001b[A\n",
            " 69%|██████▉   | 2271/3298 [26:07<11:00,  1.56it/s]\u001b[A\n",
            " 69%|██████▉   | 2272/3298 [26:07<11:43,  1.46it/s]\u001b[A\n",
            " 69%|██████▉   | 2273/3298 [26:08<11:33,  1.48it/s]\u001b[A\n",
            " 69%|██████▉   | 2274/3298 [26:09<12:43,  1.34it/s]\u001b[A\n",
            " 69%|██████▉   | 2275/3298 [26:10<13:29,  1.26it/s]\u001b[A\n",
            " 69%|██████▉   | 2276/3298 [26:11<14:09,  1.20it/s]\u001b[A\n",
            " 69%|██████▉   | 2277/3298 [26:12<14:34,  1.17it/s]\u001b[A\n",
            " 69%|██████▉   | 2278/3298 [26:12<14:10,  1.20it/s]\u001b[A\n",
            " 69%|██████▉   | 2279/3298 [26:13<14:37,  1.16it/s]\u001b[A\n",
            " 69%|██████▉   | 2280/3298 [26:14<14:59,  1.13it/s]\u001b[A\n",
            " 69%|██████▉   | 2281/3298 [26:15<15:07,  1.12it/s]\u001b[A\n",
            " 69%|██████▉   | 2282/3298 [26:16<14:28,  1.17it/s]\u001b[A\n",
            " 69%|██████▉   | 2283/3298 [26:17<14:48,  1.14it/s]\u001b[A\n",
            " 69%|██████▉   | 2284/3298 [26:18<13:06,  1.29it/s]\u001b[A\n",
            " 69%|██████▉   | 2285/3298 [26:18<12:33,  1.34it/s]\u001b[A\n",
            " 69%|██████▉   | 2286/3298 [26:19<12:05,  1.40it/s]\u001b[A\n",
            " 69%|██████▉   | 2287/3298 [26:19<11:44,  1.43it/s]\u001b[A\n",
            " 69%|██████▉   | 2288/3298 [26:20<11:28,  1.47it/s]\u001b[A\n",
            " 69%|██████▉   | 2289/3298 [26:21<11:16,  1.49it/s]\u001b[A\n",
            " 69%|██████▉   | 2290/3298 [26:21<11:13,  1.50it/s]\u001b[A\n",
            " 69%|██████▉   | 2291/3298 [26:22<11:10,  1.50it/s]\u001b[A\n",
            " 69%|██████▉   | 2292/3298 [26:23<11:45,  1.43it/s]\u001b[A\n",
            " 70%|██████▉   | 2293/3298 [26:24<11:30,  1.46it/s]\u001b[A\n",
            " 70%|██████▉   | 2294/3298 [26:24<11:57,  1.40it/s]\u001b[A\n",
            " 70%|██████▉   | 2295/3298 [26:25<12:19,  1.36it/s]\u001b[A\n",
            " 70%|██████▉   | 2296/3298 [26:26<12:28,  1.34it/s]\u001b[A\n",
            " 70%|██████▉   | 2297/3298 [26:27<12:38,  1.32it/s]\u001b[A\n",
            " 70%|██████▉   | 2298/3298 [26:27<12:04,  1.38it/s]\u001b[A\n",
            " 70%|██████▉   | 2299/3298 [26:28<12:18,  1.35it/s]\u001b[A\n",
            " 70%|██████▉   | 2300/3298 [26:29<12:32,  1.33it/s]\u001b[A\n",
            " 70%|██████▉   | 2301/3298 [26:30<12:04,  1.38it/s]\u001b[A\n",
            " 70%|██████▉   | 2302/3298 [26:30<11:39,  1.42it/s]\u001b[A\n",
            " 70%|██████▉   | 2303/3298 [26:31<11:22,  1.46it/s]\u001b[A\n",
            " 70%|██████▉   | 2304/3298 [26:31<11:11,  1.48it/s]\u001b[A\n",
            " 70%|██████▉   | 2305/3298 [26:32<11:01,  1.50it/s]\u001b[A\n",
            " 70%|██████▉   | 2306/3298 [26:33<12:11,  1.36it/s]\u001b[A\n",
            " 70%|██████▉   | 2307/3298 [26:34<11:42,  1.41it/s]\u001b[A\n",
            " 70%|██████▉   | 2308/3298 [26:34<11:59,  1.38it/s]\u001b[A\n",
            " 70%|███████   | 2309/3298 [26:35<11:35,  1.42it/s]\u001b[A\n",
            " 70%|███████   | 2310/3298 [26:36<11:18,  1.46it/s]\u001b[A\n",
            " 70%|███████   | 2311/3298 [26:36<11:04,  1.49it/s]\u001b[A\n",
            " 70%|███████   | 2312/3298 [26:37<10:49,  1.52it/s]\u001b[A\n",
            " 70%|███████   | 2313/3298 [26:38<11:24,  1.44it/s]\u001b[A\n",
            " 70%|███████   | 2314/3298 [26:38<11:16,  1.45it/s]\u001b[A\n",
            " 70%|███████   | 2315/3298 [26:39<10:22,  1.58it/s]\u001b[A\n",
            " 70%|███████   | 2316/3298 [26:40<10:23,  1.57it/s]\u001b[A\n",
            " 70%|███████   | 2317/3298 [26:40<09:44,  1.68it/s]\u001b[A\n",
            " 70%|███████   | 2318/3298 [26:41<10:00,  1.63it/s]\u001b[A\n",
            " 70%|███████   | 2319/3298 [26:41<10:09,  1.61it/s]\u001b[A\n",
            " 70%|███████   | 2320/3298 [26:42<10:14,  1.59it/s]\u001b[A\n",
            " 70%|███████   | 2321/3298 [26:43<10:18,  1.58it/s]\u001b[A\n",
            " 70%|███████   | 2322/3298 [26:43<10:59,  1.48it/s]\u001b[A\n",
            " 70%|███████   | 2323/3298 [26:44<11:32,  1.41it/s]\u001b[A\n",
            " 70%|███████   | 2324/3298 [26:45<11:08,  1.46it/s]\u001b[A\n",
            " 70%|███████   | 2325/3298 [26:46<10:56,  1.48it/s]\u001b[A\n",
            " 71%|███████   | 2326/3298 [26:46<10:41,  1.52it/s]\u001b[A\n",
            " 71%|███████   | 2327/3298 [26:47<10:34,  1.53it/s]\u001b[A\n",
            " 71%|███████   | 2328/3298 [26:47<10:28,  1.54it/s]\u001b[A\n",
            " 71%|███████   | 2329/3298 [26:48<10:26,  1.55it/s]\u001b[A\n",
            " 71%|███████   | 2330/3298 [26:49<10:27,  1.54it/s]\u001b[A\n",
            " 71%|███████   | 2331/3298 [26:49<10:25,  1.55it/s]\u001b[A\n",
            " 71%|███████   | 2332/3298 [26:50<10:17,  1.56it/s]\u001b[A\n",
            " 71%|███████   | 2333/3298 [26:51<10:23,  1.55it/s]\u001b[A\n",
            " 71%|███████   | 2334/3298 [26:51<10:20,  1.55it/s]\u001b[A\n",
            " 71%|███████   | 2335/3298 [26:52<10:14,  1.57it/s]\u001b[A\n",
            " 71%|███████   | 2336/3298 [26:53<10:13,  1.57it/s]\u001b[A\n",
            " 71%|███████   | 2337/3298 [26:53<11:28,  1.40it/s]\u001b[A\n",
            " 71%|███████   | 2338/3298 [26:54<11:44,  1.36it/s]\u001b[A\n",
            " 71%|███████   | 2339/3298 [26:55<10:35,  1.51it/s]\u001b[A\n",
            " 71%|███████   | 2340/3298 [26:55<10:27,  1.53it/s]\u001b[A\n",
            " 71%|███████   | 2341/3298 [26:56<11:05,  1.44it/s]\u001b[A\n",
            " 71%|███████   | 2342/3298 [26:57<12:02,  1.32it/s]\u001b[A\n",
            " 71%|███████   | 2343/3298 [26:58<11:29,  1.38it/s]\u001b[A\n",
            " 71%|███████   | 2344/3298 [26:58<10:25,  1.52it/s]\u001b[A\n",
            " 71%|███████   | 2345/3298 [26:59<09:41,  1.64it/s]\u001b[A\n",
            " 71%|███████   | 2346/3298 [26:59<09:56,  1.60it/s]\u001b[A\n",
            " 71%|███████   | 2347/3298 [27:00<09:57,  1.59it/s]\u001b[A\n",
            " 71%|███████   | 2348/3298 [27:00<09:20,  1.69it/s]\u001b[A\n",
            " 71%|███████   | 2349/3298 [27:01<09:34,  1.65it/s]\u001b[A\n",
            " 71%|███████▏  | 2350/3298 [27:02<09:45,  1.62it/s]\u001b[A\n",
            " 71%|███████▏  | 2351/3298 [27:02<09:11,  1.72it/s]\u001b[A\n",
            " 71%|███████▏  | 2352/3298 [27:03<09:31,  1.66it/s]\u001b[A\n",
            " 71%|███████▏  | 2353/3298 [27:04<09:44,  1.62it/s]\u001b[A\n",
            " 71%|███████▏  | 2354/3298 [27:04<09:51,  1.60it/s]\u001b[A\n",
            " 71%|███████▏  | 2355/3298 [27:05<10:33,  1.49it/s]\u001b[A\n",
            " 71%|███████▏  | 2356/3298 [27:06<10:30,  1.49it/s]\u001b[A\n",
            " 71%|███████▏  | 2357/3298 [27:06<10:25,  1.51it/s]\u001b[A\n",
            " 71%|███████▏  | 2358/3298 [27:07<11:05,  1.41it/s]\u001b[A\n",
            " 72%|███████▏  | 2359/3298 [27:08<12:02,  1.30it/s]\u001b[A\n",
            " 72%|███████▏  | 2360/3298 [27:09<11:26,  1.37it/s]\u001b[A\n",
            " 72%|███████▏  | 2361/3298 [27:09<11:35,  1.35it/s]\u001b[A\n",
            " 72%|███████▏  | 2362/3298 [27:10<12:24,  1.26it/s]\u001b[A\n",
            " 72%|███████▏  | 2363/3298 [27:11<12:13,  1.28it/s]\u001b[A\n",
            " 72%|███████▏  | 2364/3298 [27:12<12:54,  1.21it/s]\u001b[A\n",
            " 72%|███████▏  | 2365/3298 [27:13<12:38,  1.23it/s]\u001b[A\n",
            " 72%|███████▏  | 2366/3298 [27:14<12:00,  1.29it/s]\u001b[A\n",
            " 72%|███████▏  | 2367/3298 [27:14<12:06,  1.28it/s]\u001b[A\n",
            " 72%|███████▏  | 2368/3298 [27:15<12:41,  1.22it/s]\u001b[A\n",
            " 72%|███████▏  | 2369/3298 [27:16<12:29,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2370/3298 [27:17<12:23,  1.25it/s]\u001b[A\n",
            " 72%|███████▏  | 2371/3298 [27:18<12:14,  1.26it/s]\u001b[A\n",
            " 72%|███████▏  | 2372/3298 [27:18<12:08,  1.27it/s]\u001b[A\n",
            " 72%|███████▏  | 2373/3298 [27:19<12:48,  1.20it/s]\u001b[A\n",
            " 72%|███████▏  | 2374/3298 [27:20<12:38,  1.22it/s]\u001b[A\n",
            " 72%|███████▏  | 2375/3298 [27:21<12:26,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2376/3298 [27:22<12:27,  1.23it/s]\u001b[A\n",
            " 72%|███████▏  | 2377/3298 [27:22<12:22,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2378/3298 [27:23<12:19,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2379/3298 [27:24<12:09,  1.26it/s]\u001b[A\n",
            " 72%|███████▏  | 2380/3298 [27:25<12:05,  1.27it/s]\u001b[A\n",
            " 72%|███████▏  | 2381/3298 [27:26<12:44,  1.20it/s]\u001b[A\n",
            " 72%|███████▏  | 2382/3298 [27:27<12:29,  1.22it/s]\u001b[A\n",
            " 72%|███████▏  | 2383/3298 [27:27<12:24,  1.23it/s]\u001b[A\n",
            " 72%|███████▏  | 2384/3298 [27:28<11:36,  1.31it/s]\u001b[A\n",
            " 72%|███████▏  | 2385/3298 [27:29<11:42,  1.30it/s]\u001b[A\n",
            " 72%|███████▏  | 2386/3298 [27:30<12:24,  1.23it/s]\u001b[A\n",
            " 72%|███████▏  | 2387/3298 [27:30<12:13,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2388/3298 [27:31<12:12,  1.24it/s]\u001b[A\n",
            " 72%|███████▏  | 2389/3298 [27:32<12:01,  1.26it/s]\u001b[A\n",
            " 72%|███████▏  | 2390/3298 [27:33<11:59,  1.26it/s]\u001b[A\n",
            " 72%|███████▏  | 2391/3298 [27:34<12:08,  1.24it/s]\u001b[A\n",
            " 73%|███████▎  | 2392/3298 [27:34<12:00,  1.26it/s]\u001b[A\n",
            " 73%|███████▎  | 2393/3298 [27:35<11:52,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2394/3298 [27:36<11:46,  1.28it/s]\u001b[A\n",
            " 73%|███████▎  | 2395/3298 [27:37<11:47,  1.28it/s]\u001b[A\n",
            " 73%|███████▎  | 2396/3298 [27:38<11:52,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2397/3298 [27:38<11:50,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2398/3298 [27:39<11:46,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2399/3298 [27:40<11:42,  1.28it/s]\u001b[A\n",
            " 73%|███████▎  | 2400/3298 [27:41<11:45,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2401/3298 [27:41<11:44,  1.27it/s]\u001b[A\n",
            " 73%|███████▎  | 2402/3298 [27:42<12:12,  1.22it/s]\u001b[A\n",
            " 73%|███████▎  | 2403/3298 [27:43<12:00,  1.24it/s]\u001b[A\n",
            " 73%|███████▎  | 2404/3298 [27:44<12:21,  1.21it/s]\u001b[A\n",
            " 73%|███████▎  | 2405/3298 [27:45<11:37,  1.28it/s]\u001b[A\n",
            " 73%|███████▎  | 2406/3298 [27:45<10:58,  1.35it/s]\u001b[A\n",
            " 73%|███████▎  | 2407/3298 [27:46<11:08,  1.33it/s]\u001b[A\n",
            " 73%|███████▎  | 2408/3298 [27:47<10:46,  1.38it/s]\u001b[A\n",
            " 73%|███████▎  | 2409/3298 [27:47<09:46,  1.52it/s]\u001b[A\n",
            " 73%|███████▎  | 2410/3298 [27:48<09:40,  1.53it/s]\u001b[A\n",
            " 73%|███████▎  | 2411/3298 [27:49<09:42,  1.52it/s]\u001b[A\n",
            " 73%|███████▎  | 2412/3298 [27:49<10:22,  1.42it/s]\u001b[A\n",
            " 73%|███████▎  | 2413/3298 [27:50<10:07,  1.46it/s]\u001b[A\n",
            " 73%|███████▎  | 2414/3298 [27:51<09:23,  1.57it/s]\u001b[A\n",
            " 73%|███████▎  | 2415/3298 [27:51<09:32,  1.54it/s]\u001b[A\n",
            " 73%|███████▎  | 2416/3298 [27:52<09:35,  1.53it/s]\u001b[A\n",
            " 73%|███████▎  | 2417/3298 [27:53<09:36,  1.53it/s]\u001b[A\n",
            " 73%|███████▎  | 2418/3298 [27:53<09:37,  1.52it/s]\u001b[A\n",
            " 73%|███████▎  | 2419/3298 [27:54<09:32,  1.54it/s]\u001b[A\n",
            " 73%|███████▎  | 2420/3298 [27:55<09:30,  1.54it/s]\u001b[A\n",
            " 73%|███████▎  | 2421/3298 [27:55<09:30,  1.54it/s]\u001b[A\n",
            " 73%|███████▎  | 2422/3298 [27:56<09:26,  1.55it/s]\u001b[A\n",
            " 73%|███████▎  | 2423/3298 [27:56<09:26,  1.54it/s]\u001b[A\n",
            " 73%|███████▎  | 2424/3298 [27:57<09:26,  1.54it/s]\u001b[A\n",
            " 74%|███████▎  | 2425/3298 [27:58<09:26,  1.54it/s]\u001b[A\n",
            " 74%|███████▎  | 2426/3298 [27:58<09:23,  1.55it/s]\u001b[A\n",
            " 74%|███████▎  | 2427/3298 [27:59<09:21,  1.55it/s]\u001b[A\n",
            " 74%|███████▎  | 2428/3298 [28:00<09:19,  1.55it/s]\u001b[A\n",
            " 74%|███████▎  | 2429/3298 [28:00<09:19,  1.55it/s]\u001b[A\n",
            " 74%|███████▎  | 2430/3298 [28:01<09:16,  1.56it/s]\u001b[A\n",
            " 74%|███████▎  | 2431/3298 [28:02<09:11,  1.57it/s]\u001b[A\n",
            " 74%|███████▎  | 2432/3298 [28:02<09:09,  1.58it/s]\u001b[A\n",
            " 74%|███████▍  | 2433/3298 [28:03<09:12,  1.56it/s]\u001b[A\n",
            " 74%|███████▍  | 2434/3298 [28:04<09:13,  1.56it/s]\u001b[A\n",
            " 74%|███████▍  | 2435/3298 [28:04<09:10,  1.57it/s]\u001b[A\n",
            " 74%|███████▍  | 2436/3298 [28:05<09:11,  1.56it/s]\u001b[A\n",
            " 74%|███████▍  | 2437/3298 [28:05<08:35,  1.67it/s]\u001b[A\n",
            " 74%|███████▍  | 2438/3298 [28:06<08:46,  1.63it/s]\u001b[A\n",
            " 74%|███████▍  | 2439/3298 [28:07<08:54,  1.61it/s]\u001b[A\n",
            " 74%|███████▍  | 2440/3298 [28:07<08:55,  1.60it/s]\u001b[A\n",
            " 74%|███████▍  | 2441/3298 [28:08<09:02,  1.58it/s]\u001b[A\n",
            " 74%|███████▍  | 2442/3298 [28:08<09:01,  1.58it/s]\u001b[A\n",
            " 74%|███████▍  | 2443/3298 [28:09<09:01,  1.58it/s]\u001b[A\n",
            " 74%|███████▍  | 2444/3298 [28:10<09:38,  1.48it/s]\u001b[A\n",
            " 74%|███████▍  | 2445/3298 [28:10<08:53,  1.60it/s]\u001b[A\n",
            " 74%|███████▍  | 2446/3298 [28:11<09:01,  1.57it/s]\u001b[A\n",
            " 74%|███████▍  | 2447/3298 [28:12<09:06,  1.56it/s]\u001b[A\n",
            " 74%|███████▍  | 2448/3298 [28:13<09:44,  1.45it/s]\u001b[A\n",
            " 74%|███████▍  | 2449/3298 [28:13<10:14,  1.38it/s]\u001b[A\n",
            " 74%|███████▍  | 2450/3298 [28:14<09:57,  1.42it/s]\u001b[A\n",
            " 74%|███████▍  | 2451/3298 [28:15<09:43,  1.45it/s]\u001b[A\n",
            " 74%|███████▍  | 2452/3298 [28:15<09:36,  1.47it/s]\u001b[A\n",
            " 74%|███████▍  | 2453/3298 [28:16<10:00,  1.41it/s]\u001b[A\n",
            " 74%|███████▍  | 2454/3298 [28:17<11:21,  1.24it/s]\u001b[A\n",
            " 74%|███████▍  | 2455/3298 [28:18<10:39,  1.32it/s]\u001b[A\n",
            " 74%|███████▍  | 2456/3298 [28:18<10:09,  1.38it/s]\u001b[A\n",
            " 74%|███████▍  | 2457/3298 [28:19<09:12,  1.52it/s]\u001b[A\n",
            " 75%|███████▍  | 2458/3298 [28:20<09:04,  1.54it/s]\u001b[A\n",
            " 75%|███████▍  | 2459/3298 [28:20<09:40,  1.45it/s]\u001b[A\n",
            " 75%|███████▍  | 2460/3298 [28:21<09:29,  1.47it/s]\u001b[A\n",
            " 75%|███████▍  | 2461/3298 [28:21<08:49,  1.58it/s]\u001b[A\n",
            " 75%|███████▍  | 2462/3298 [28:22<09:30,  1.47it/s]\u001b[A\n",
            " 75%|███████▍  | 2463/3298 [28:23<09:21,  1.49it/s]\u001b[A\n",
            " 75%|███████▍  | 2464/3298 [28:24<09:49,  1.42it/s]\u001b[A\n",
            " 75%|███████▍  | 2465/3298 [28:24<09:35,  1.45it/s]\u001b[A\n",
            " 75%|███████▍  | 2466/3298 [28:25<09:55,  1.40it/s]\u001b[A\n",
            " 75%|███████▍  | 2467/3298 [28:26<09:36,  1.44it/s]\u001b[A\n",
            " 75%|███████▍  | 2468/3298 [28:27<09:55,  1.39it/s]\u001b[A\n",
            " 75%|███████▍  | 2469/3298 [28:27<09:39,  1.43it/s]\u001b[A\n",
            " 75%|███████▍  | 2470/3298 [28:28<09:21,  1.48it/s]\u001b[A\n",
            " 75%|███████▍  | 2471/3298 [28:28<09:12,  1.50it/s]\u001b[A\n",
            " 75%|███████▍  | 2472/3298 [28:29<09:06,  1.51it/s]\u001b[A\n",
            " 75%|███████▍  | 2473/3298 [28:30<09:04,  1.51it/s]\u001b[A\n",
            " 75%|███████▌  | 2474/3298 [28:30<08:58,  1.53it/s]\u001b[A\n",
            " 75%|███████▌  | 2475/3298 [28:31<08:55,  1.54it/s]\u001b[A\n",
            " 75%|███████▌  | 2476/3298 [28:32<08:56,  1.53it/s]\u001b[A\n",
            " 75%|███████▌  | 2477/3298 [28:32<08:54,  1.54it/s]\u001b[A\n",
            " 75%|███████▌  | 2478/3298 [28:33<09:26,  1.45it/s]\u001b[A\n",
            " 75%|███████▌  | 2479/3298 [28:34<09:48,  1.39it/s]\u001b[A\n",
            " 75%|███████▌  | 2480/3298 [28:35<10:38,  1.28it/s]\u001b[A\n",
            " 75%|███████▌  | 2481/3298 [28:36<10:41,  1.27it/s]\u001b[A\n",
            " 75%|███████▌  | 2482/3298 [28:36<10:44,  1.27it/s]\u001b[A\n",
            " 75%|███████▌  | 2483/3298 [28:37<10:10,  1.34it/s]\u001b[A\n",
            " 75%|███████▌  | 2484/3298 [28:38<09:45,  1.39it/s]\u001b[A\n",
            " 75%|███████▌  | 2485/3298 [28:38<08:56,  1.52it/s]\u001b[A\n",
            " 75%|███████▌  | 2486/3298 [28:39<08:53,  1.52it/s]\u001b[A\n",
            " 75%|███████▌  | 2487/3298 [28:40<08:50,  1.53it/s]\u001b[A\n",
            " 75%|███████▌  | 2488/3298 [28:40<08:59,  1.50it/s]\u001b[A\n",
            " 75%|███████▌  | 2489/3298 [28:41<08:57,  1.51it/s]\u001b[A\n",
            " 76%|███████▌  | 2490/3298 [28:42<08:54,  1.51it/s]\u001b[A\n",
            " 76%|███████▌  | 2491/3298 [28:42<08:50,  1.52it/s]\u001b[A\n",
            " 76%|███████▌  | 2492/3298 [28:43<08:43,  1.54it/s]\u001b[A\n",
            " 76%|███████▌  | 2493/3298 [28:44<09:47,  1.37it/s]\u001b[A\n",
            " 76%|███████▌  | 2494/3298 [28:44<09:24,  1.42it/s]\u001b[A\n",
            " 76%|███████▌  | 2495/3298 [28:45<09:11,  1.46it/s]\u001b[A\n",
            " 76%|███████▌  | 2496/3298 [28:46<09:04,  1.47it/s]\u001b[A\n",
            " 76%|███████▌  | 2497/3298 [28:46<08:55,  1.50it/s]\u001b[A\n",
            " 76%|███████▌  | 2498/3298 [28:47<08:17,  1.61it/s]\u001b[A\n",
            " 76%|███████▌  | 2499/3298 [28:48<09:31,  1.40it/s]\u001b[A\n",
            " 76%|███████▌  | 2500/3298 [28:48<08:42,  1.53it/s]\u001b[A\n",
            " 76%|███████▌  | 2501/3298 [28:49<08:43,  1.52it/s]\u001b[A\n",
            " 76%|███████▌  | 2502/3298 [28:50<09:18,  1.43it/s]\u001b[A\n",
            " 76%|███████▌  | 2503/3298 [28:50<09:04,  1.46it/s]\u001b[A\n",
            " 76%|███████▌  | 2504/3298 [28:51<08:53,  1.49it/s]\u001b[A\n",
            " 76%|███████▌  | 2505/3298 [28:52<10:25,  1.27it/s]\u001b[A\n",
            " 76%|███████▌  | 2506/3298 [28:53<09:14,  1.43it/s]\u001b[A\n",
            " 76%|███████▌  | 2507/3298 [28:53<09:03,  1.45it/s]\u001b[A\n",
            " 76%|███████▌  | 2508/3298 [28:54<08:20,  1.58it/s]\u001b[A\n",
            " 76%|███████▌  | 2509/3298 [28:55<08:52,  1.48it/s]\u001b[A\n",
            " 76%|███████▌  | 2510/3298 [28:55<08:15,  1.59it/s]\u001b[A\n",
            " 76%|███████▌  | 2511/3298 [28:56<08:22,  1.57it/s]\u001b[A\n",
            " 76%|███████▌  | 2512/3298 [28:56<08:23,  1.56it/s]\u001b[A\n",
            " 76%|███████▌  | 2513/3298 [28:57<08:23,  1.56it/s]\u001b[A\n",
            " 76%|███████▌  | 2514/3298 [28:58<08:24,  1.55it/s]\u001b[A\n",
            " 76%|███████▋  | 2515/3298 [28:58<08:24,  1.55it/s]\u001b[A\n",
            " 76%|███████▋  | 2516/3298 [28:59<08:25,  1.55it/s]\u001b[A\n",
            " 76%|███████▋  | 2517/3298 [29:00<08:24,  1.55it/s]\u001b[A\n",
            " 76%|███████▋  | 2518/3298 [29:01<09:30,  1.37it/s]\u001b[A\n",
            " 76%|███████▋  | 2519/3298 [29:02<10:50,  1.20it/s]\u001b[A\n",
            " 76%|███████▋  | 2520/3298 [29:02<10:41,  1.21it/s]\u001b[A\n",
            " 76%|███████▋  | 2521/3298 [29:03<10:01,  1.29it/s]\u001b[A\n",
            " 76%|███████▋  | 2522/3298 [29:04<09:32,  1.35it/s]\u001b[A\n",
            " 77%|███████▋  | 2523/3298 [29:04<08:41,  1.49it/s]\u001b[A\n",
            " 77%|███████▋  | 2524/3298 [29:05<09:06,  1.42it/s]\u001b[A\n",
            " 77%|███████▋  | 2525/3298 [29:06<09:23,  1.37it/s]\u001b[A\n",
            " 77%|███████▋  | 2526/3298 [29:07<09:10,  1.40it/s]\u001b[A\n",
            " 77%|███████▋  | 2527/3298 [29:07<09:25,  1.36it/s]\u001b[A\n",
            " 77%|███████▋  | 2528/3298 [29:08<09:33,  1.34it/s]\u001b[A\n",
            " 77%|███████▋  | 2529/3298 [29:09<09:37,  1.33it/s]\u001b[A\n",
            " 77%|███████▋  | 2530/3298 [29:10<09:44,  1.31it/s]\u001b[A\n",
            " 77%|███████▋  | 2531/3298 [29:10<09:51,  1.30it/s]\u001b[A\n",
            " 77%|███████▋  | 2532/3298 [29:11<09:22,  1.36it/s]\u001b[A\n",
            " 77%|███████▋  | 2533/3298 [29:12<09:08,  1.40it/s]\u001b[A\n",
            " 77%|███████▋  | 2534/3298 [29:12<08:57,  1.42it/s]\u001b[A\n",
            " 77%|███████▋  | 2535/3298 [29:13<09:16,  1.37it/s]\u001b[A\n",
            " 77%|███████▋  | 2536/3298 [29:14<08:29,  1.50it/s]\u001b[A\n",
            " 77%|███████▋  | 2537/3298 [29:14<08:22,  1.51it/s]\u001b[A\n",
            " 77%|███████▋  | 2538/3298 [29:15<08:15,  1.53it/s]\u001b[A\n",
            " 77%|███████▋  | 2539/3298 [29:16<08:13,  1.54it/s]\u001b[A\n",
            " 77%|███████▋  | 2540/3298 [29:16<08:45,  1.44it/s]\u001b[A\n",
            " 77%|███████▋  | 2541/3298 [29:17<08:36,  1.47it/s]\u001b[A\n",
            " 77%|███████▋  | 2542/3298 [29:18<08:28,  1.49it/s]\u001b[A\n",
            " 77%|███████▋  | 2543/3298 [29:18<08:22,  1.50it/s]\u001b[A\n",
            " 77%|███████▋  | 2544/3298 [29:19<09:23,  1.34it/s]\u001b[A\n",
            " 77%|███████▋  | 2545/3298 [29:20<08:58,  1.40it/s]\u001b[A\n",
            " 77%|███████▋  | 2546/3298 [29:21<09:46,  1.28it/s]\u001b[A\n",
            " 77%|███████▋  | 2547/3298 [29:22<09:49,  1.27it/s]\u001b[A\n",
            " 77%|███████▋  | 2548/3298 [29:23<09:48,  1.27it/s]\u001b[A\n",
            " 77%|███████▋  | 2549/3298 [29:23<09:16,  1.35it/s]\u001b[A\n",
            " 77%|███████▋  | 2550/3298 [29:24<09:54,  1.26it/s]\u001b[A\n",
            " 77%|███████▋  | 2551/3298 [29:25<09:50,  1.26it/s]\u001b[A\n",
            " 77%|███████▋  | 2552/3298 [29:26<09:53,  1.26it/s]\u001b[A\n",
            " 77%|███████▋  | 2553/3298 [29:26<09:49,  1.26it/s]\u001b[A\n",
            " 77%|███████▋  | 2554/3298 [29:27<10:13,  1.21it/s]\u001b[A\n",
            " 77%|███████▋  | 2555/3298 [29:28<10:34,  1.17it/s]\u001b[A\n",
            " 78%|███████▊  | 2556/3298 [29:29<09:48,  1.26it/s]\u001b[A\n",
            " 78%|███████▊  | 2557/3298 [29:29<08:44,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 2558/3298 [29:30<08:58,  1.37it/s]\u001b[A\n",
            " 78%|███████▊  | 2559/3298 [29:31<08:35,  1.43it/s]\u001b[A\n",
            " 78%|███████▊  | 2560/3298 [29:31<08:25,  1.46it/s]\u001b[A\n",
            " 78%|███████▊  | 2561/3298 [29:32<08:13,  1.49it/s]\u001b[A\n",
            " 78%|███████▊  | 2562/3298 [29:33<08:11,  1.50it/s]\u001b[A\n",
            " 78%|███████▊  | 2563/3298 [29:33<07:35,  1.61it/s]\u001b[A\n",
            " 78%|███████▊  | 2564/3298 [29:34<07:09,  1.71it/s]\u001b[A\n",
            " 78%|███████▊  | 2565/3298 [29:34<07:21,  1.66it/s]\u001b[A\n",
            " 78%|███████▊  | 2566/3298 [29:35<08:03,  1.51it/s]\u001b[A\n",
            " 78%|███████▊  | 2567/3298 [29:36<08:24,  1.45it/s]\u001b[A\n",
            " 78%|███████▊  | 2568/3298 [29:37<09:09,  1.33it/s]\u001b[A\n",
            " 78%|███████▊  | 2569/3298 [29:38<09:12,  1.32it/s]\u001b[A\n",
            " 78%|███████▊  | 2570/3298 [29:38<08:45,  1.39it/s]\u001b[A\n",
            " 78%|███████▊  | 2571/3298 [29:39<09:29,  1.28it/s]\u001b[A\n",
            " 78%|███████▊  | 2572/3298 [29:40<09:25,  1.28it/s]\u001b[A\n",
            " 78%|███████▊  | 2573/3298 [29:41<08:52,  1.36it/s]\u001b[A\n",
            " 78%|███████▊  | 2574/3298 [29:41<08:36,  1.40it/s]\u001b[A\n",
            " 78%|███████▊  | 2575/3298 [29:42<08:20,  1.45it/s]\u001b[A\n",
            " 78%|███████▊  | 2576/3298 [29:42<07:38,  1.57it/s]\u001b[A\n",
            " 78%|███████▊  | 2577/3298 [29:43<08:08,  1.48it/s]\u001b[A\n",
            " 78%|███████▊  | 2578/3298 [29:44<08:03,  1.49it/s]\u001b[A\n",
            " 78%|███████▊  | 2579/3298 [29:45<07:56,  1.51it/s]\u001b[A\n",
            " 78%|███████▊  | 2580/3298 [29:45<07:53,  1.52it/s]\u001b[A\n",
            " 78%|███████▊  | 2581/3298 [29:46<08:48,  1.36it/s]\u001b[A\n",
            " 78%|███████▊  | 2582/3298 [29:47<08:28,  1.41it/s]\u001b[A\n",
            " 78%|███████▊  | 2583/3298 [29:47<08:14,  1.45it/s]\u001b[A\n",
            " 78%|███████▊  | 2584/3298 [29:48<08:04,  1.47it/s]\u001b[A\n",
            " 78%|███████▊  | 2585/3298 [29:49<07:56,  1.50it/s]\u001b[A\n",
            " 78%|███████▊  | 2586/3298 [29:49<07:51,  1.51it/s]\u001b[A\n",
            " 78%|███████▊  | 2587/3298 [29:50<07:47,  1.52it/s]\u001b[A\n",
            " 78%|███████▊  | 2588/3298 [29:51<08:14,  1.44it/s]\u001b[A\n",
            " 79%|███████▊  | 2589/3298 [29:52<08:34,  1.38it/s]\u001b[A\n",
            " 79%|███████▊  | 2590/3298 [29:52<08:15,  1.43it/s]\u001b[A\n",
            " 79%|███████▊  | 2591/3298 [29:53<08:03,  1.46it/s]\u001b[A\n",
            " 79%|███████▊  | 2592/3298 [29:53<07:54,  1.49it/s]\u001b[A\n",
            " 79%|███████▊  | 2593/3298 [29:54<08:17,  1.42it/s]\u001b[A\n",
            " 79%|███████▊  | 2594/3298 [29:55<08:31,  1.38it/s]\u001b[A\n",
            " 79%|███████▊  | 2595/3298 [29:56<08:12,  1.43it/s]\u001b[A\n",
            " 79%|███████▊  | 2596/3298 [29:57<08:57,  1.31it/s]\u001b[A\n",
            " 79%|███████▊  | 2597/3298 [29:57<08:35,  1.36it/s]\u001b[A\n",
            " 79%|███████▉  | 2598/3298 [29:58<07:48,  1.49it/s]\u001b[A\n",
            " 79%|███████▉  | 2599/3298 [29:58<07:41,  1.51it/s]\u001b[A\n",
            " 79%|███████▉  | 2600/3298 [29:59<07:08,  1.63it/s]\u001b[A\n",
            " 79%|███████▉  | 2601/3298 [30:00<07:15,  1.60it/s]\u001b[A\n",
            " 79%|███████▉  | 2602/3298 [30:00<07:19,  1.58it/s]\u001b[A\n",
            " 79%|███████▉  | 2603/3298 [30:01<08:19,  1.39it/s]\u001b[A\n",
            " 79%|███████▉  | 2604/3298 [30:02<08:56,  1.29it/s]\u001b[A\n",
            " 79%|███████▉  | 2605/3298 [30:03<08:55,  1.29it/s]\u001b[A\n",
            " 79%|███████▉  | 2606/3298 [30:03<08:24,  1.37it/s]\u001b[A\n",
            " 79%|███████▉  | 2607/3298 [30:04<08:04,  1.43it/s]\u001b[A\n",
            " 79%|███████▉  | 2608/3298 [30:05<07:53,  1.46it/s]\u001b[A\n",
            " 79%|███████▉  | 2609/3298 [30:05<07:44,  1.48it/s]\u001b[A\n",
            " 79%|███████▉  | 2610/3298 [30:06<07:35,  1.51it/s]\u001b[A\n",
            " 79%|███████▉  | 2611/3298 [30:07<07:32,  1.52it/s]\u001b[A\n",
            " 79%|███████▉  | 2612/3298 [30:07<07:01,  1.63it/s]\u001b[A\n",
            " 79%|███████▉  | 2613/3298 [30:08<07:35,  1.50it/s]\u001b[A\n",
            " 79%|███████▉  | 2614/3298 [30:09<07:56,  1.44it/s]\u001b[A\n",
            " 79%|███████▉  | 2615/3298 [30:10<08:33,  1.33it/s]\u001b[A\n",
            " 79%|███████▉  | 2616/3298 [30:10<08:35,  1.32it/s]\u001b[A\n",
            " 79%|███████▉  | 2617/3298 [30:11<08:06,  1.40it/s]\u001b[A\n",
            " 79%|███████▉  | 2618/3298 [30:12<07:50,  1.45it/s]\u001b[A\n",
            " 79%|███████▉  | 2619/3298 [30:12<08:05,  1.40it/s]\u001b[A\n",
            " 79%|███████▉  | 2620/3298 [30:13<07:52,  1.44it/s]\u001b[A\n",
            " 79%|███████▉  | 2621/3298 [30:14<07:42,  1.46it/s]\u001b[A\n",
            " 80%|███████▉  | 2622/3298 [30:14<07:33,  1.49it/s]\u001b[A\n",
            " 80%|███████▉  | 2623/3298 [30:15<07:25,  1.52it/s]\u001b[A\n",
            " 80%|███████▉  | 2624/3298 [30:15<06:54,  1.63it/s]\u001b[A\n",
            " 80%|███████▉  | 2625/3298 [30:16<06:57,  1.61it/s]\u001b[A\n",
            " 80%|███████▉  | 2626/3298 [30:17<06:34,  1.70it/s]\u001b[A\n",
            " 80%|███████▉  | 2627/3298 [30:18<07:36,  1.47it/s]\u001b[A\n",
            " 80%|███████▉  | 2628/3298 [30:18<07:57,  1.40it/s]\u001b[A\n",
            " 80%|███████▉  | 2629/3298 [30:19<08:39,  1.29it/s]\u001b[A\n",
            " 80%|███████▉  | 2630/3298 [30:20<08:40,  1.28it/s]\u001b[A\n",
            " 80%|███████▉  | 2631/3298 [30:21<08:16,  1.34it/s]\u001b[A\n",
            " 80%|███████▉  | 2632/3298 [30:21<07:54,  1.40it/s]\u001b[A\n",
            " 80%|███████▉  | 2633/3298 [30:23<09:26,  1.17it/s]\u001b[A\n",
            " 80%|███████▉  | 2634/3298 [30:23<09:13,  1.20it/s]\u001b[A\n",
            " 80%|███████▉  | 2635/3298 [30:24<09:07,  1.21it/s]\u001b[A\n",
            " 80%|███████▉  | 2636/3298 [30:25<08:31,  1.29it/s]\u001b[A\n",
            " 80%|███████▉  | 2637/3298 [30:26<10:23,  1.06it/s]\u001b[A\n",
            " 80%|███████▉  | 2638/3298 [30:27<11:36,  1.06s/it]\u001b[A\n",
            " 80%|████████  | 2639/3298 [30:28<10:39,  1.03it/s]\u001b[A\n",
            " 80%|████████  | 2640/3298 [30:29<09:59,  1.10it/s]\u001b[A\n",
            " 80%|████████  | 2641/3298 [30:30<09:10,  1.19it/s]\u001b[A\n",
            " 80%|████████  | 2642/3298 [30:31<10:21,  1.06it/s]\u001b[A\n",
            " 80%|████████  | 2643/3298 [30:32<09:45,  1.12it/s]\u001b[A\n",
            " 80%|████████  | 2644/3298 [30:33<10:42,  1.02it/s]\u001b[A\n",
            " 80%|████████  | 2645/3298 [30:34<10:34,  1.03it/s]\u001b[A\n",
            " 80%|████████  | 2646/3298 [30:35<09:57,  1.09it/s]\u001b[A\n",
            " 80%|████████  | 2647/3298 [30:36<10:23,  1.04it/s]\u001b[A\n",
            " 80%|████████  | 2648/3298 [30:37<10:40,  1.01it/s]\u001b[A\n",
            " 80%|████████  | 2649/3298 [30:38<10:30,  1.03it/s]\u001b[A\n",
            " 80%|████████  | 2650/3298 [30:39<11:42,  1.08s/it]\u001b[A\n",
            " 80%|████████  | 2651/3298 [30:40<11:07,  1.03s/it]\u001b[A\n",
            " 80%|████████  | 2652/3298 [30:41<11:57,  1.11s/it]\u001b[A\n",
            " 80%|████████  | 2653/3298 [30:42<10:30,  1.02it/s]\u001b[A\n",
            " 80%|████████  | 2654/3298 [30:42<09:26,  1.14it/s]\u001b[A\n",
            " 81%|████████  | 2655/3298 [30:43<09:07,  1.17it/s]\u001b[A\n",
            " 81%|████████  | 2656/3298 [30:44<09:16,  1.15it/s]\u001b[A\n",
            " 81%|████████  | 2657/3298 [30:45<08:30,  1.26it/s]\u001b[A\n",
            " 81%|████████  | 2658/3298 [30:46<08:24,  1.27it/s]\u001b[A\n",
            " 81%|████████  | 2659/3298 [30:46<07:55,  1.34it/s]\u001b[A\n",
            " 81%|████████  | 2660/3298 [30:47<08:04,  1.32it/s]\u001b[A\n",
            " 81%|████████  | 2661/3298 [30:48<07:46,  1.37it/s]\u001b[A\n",
            " 81%|████████  | 2662/3298 [30:48<07:29,  1.42it/s]\u001b[A\n",
            " 81%|████████  | 2663/3298 [30:49<07:40,  1.38it/s]\u001b[A\n",
            " 81%|████████  | 2664/3298 [30:50<07:55,  1.33it/s]\u001b[A\n",
            " 81%|████████  | 2665/3298 [30:50<07:36,  1.39it/s]\u001b[A\n",
            " 81%|████████  | 2666/3298 [30:51<07:18,  1.44it/s]\u001b[A\n",
            " 81%|████████  | 2667/3298 [30:52<07:09,  1.47it/s]\u001b[A\n",
            " 81%|████████  | 2668/3298 [30:53<07:55,  1.33it/s]\u001b[A\n",
            " 81%|████████  | 2669/3298 [30:53<07:34,  1.38it/s]\u001b[A\n",
            " 81%|████████  | 2670/3298 [30:54<07:42,  1.36it/s]\u001b[A\n",
            " 81%|████████  | 2671/3298 [30:55<07:50,  1.33it/s]\u001b[A\n",
            " 81%|████████  | 2672/3298 [30:56<07:32,  1.38it/s]\u001b[A\n",
            " 81%|████████  | 2673/3298 [30:56<07:16,  1.43it/s]\u001b[A\n",
            " 81%|████████  | 2674/3298 [30:57<07:02,  1.48it/s]\u001b[A\n",
            " 81%|████████  | 2675/3298 [30:58<07:19,  1.42it/s]\u001b[A\n",
            " 81%|████████  | 2676/3298 [30:59<07:57,  1.30it/s]\u001b[A\n",
            " 81%|████████  | 2677/3298 [30:59<07:34,  1.37it/s]\u001b[A\n",
            " 81%|████████  | 2678/3298 [31:00<08:33,  1.21it/s]\u001b[A\n",
            " 81%|████████  | 2679/3298 [31:01<09:15,  1.11it/s]\u001b[A\n",
            " 81%|████████▏ | 2680/3298 [31:02<09:42,  1.06it/s]\u001b[A\n",
            " 81%|████████▏ | 2681/3298 [31:03<10:03,  1.02it/s]\u001b[A\n",
            " 81%|████████▏ | 2682/3298 [31:04<09:52,  1.04it/s]\u001b[A\n",
            " 81%|████████▏ | 2683/3298 [31:05<09:41,  1.06it/s]\u001b[A\n",
            " 81%|████████▏ | 2684/3298 [31:06<09:09,  1.12it/s]\u001b[A\n",
            " 81%|████████▏ | 2685/3298 [31:07<09:11,  1.11it/s]\u001b[A\n",
            " 81%|████████▏ | 2686/3298 [31:08<09:37,  1.06it/s]\u001b[A\n",
            " 81%|████████▏ | 2687/3298 [31:09<09:30,  1.07it/s]\u001b[A\n",
            " 82%|████████▏ | 2688/3298 [31:10<09:01,  1.13it/s]\u001b[A\n",
            " 82%|████████▏ | 2689/3298 [31:11<09:04,  1.12it/s]\u001b[A\n",
            " 82%|████████▏ | 2690/3298 [31:11<08:40,  1.17it/s]\u001b[A\n",
            " 82%|████████▏ | 2691/3298 [31:12<08:51,  1.14it/s]\u001b[A\n",
            " 82%|████████▏ | 2692/3298 [31:13<08:59,  1.12it/s]\u001b[A\n",
            " 82%|████████▏ | 2693/3298 [31:14<08:19,  1.21it/s]\u001b[A\n",
            " 82%|████████▏ | 2694/3298 [31:14<07:20,  1.37it/s]\u001b[A\n",
            " 82%|████████▏ | 2695/3298 [31:15<07:01,  1.43it/s]\u001b[A\n",
            " 82%|████████▏ | 2696/3298 [31:15<06:27,  1.55it/s]\u001b[A\n",
            " 82%|████████▏ | 2697/3298 [31:16<07:17,  1.37it/s]\u001b[A\n",
            " 82%|████████▏ | 2698/3298 [31:17<08:14,  1.21it/s]\u001b[A\n",
            " 82%|████████▏ | 2699/3298 [31:18<08:51,  1.13it/s]\u001b[A\n",
            " 82%|████████▏ | 2700/3298 [31:20<10:27,  1.05s/it]\u001b[A\n",
            " 82%|████████▏ | 2701/3298 [31:21<11:38,  1.17s/it]\u001b[A\n",
            " 82%|████████▏ | 2702/3298 [31:22<10:24,  1.05s/it]\u001b[A\n",
            " 82%|████████▏ | 2703/3298 [31:23<10:00,  1.01s/it]\u001b[A\n",
            " 82%|████████▏ | 2704/3298 [31:24<09:21,  1.06it/s]\u001b[A\n",
            " 82%|████████▏ | 2705/3298 [31:25<08:49,  1.12it/s]\u001b[A\n",
            " 82%|████████▏ | 2706/3298 [31:25<08:03,  1.22it/s]\u001b[A\n",
            " 82%|████████▏ | 2707/3298 [31:26<08:19,  1.18it/s]\u001b[A\n",
            " 82%|████████▏ | 2708/3298 [31:27<08:27,  1.16it/s]\u001b[A\n",
            " 82%|████████▏ | 2709/3298 [31:28<08:10,  1.20it/s]\u001b[A\n",
            " 82%|████████▏ | 2710/3298 [31:29<08:46,  1.12it/s]\u001b[A\n",
            " 82%|████████▏ | 2711/3298 [31:30<08:24,  1.16it/s]\u001b[A\n",
            " 82%|████████▏ | 2712/3298 [31:30<07:49,  1.25it/s]\u001b[A\n",
            " 82%|████████▏ | 2713/3298 [31:31<07:21,  1.32it/s]\u001b[A\n",
            " 82%|████████▏ | 2714/3298 [31:32<07:01,  1.39it/s]\u001b[A\n",
            " 82%|████████▏ | 2715/3298 [31:32<06:50,  1.42it/s]\u001b[A\n",
            " 82%|████████▏ | 2716/3298 [31:33<06:38,  1.46it/s]\u001b[A\n",
            " 82%|████████▏ | 2717/3298 [31:34<06:30,  1.49it/s]\u001b[A\n",
            " 82%|████████▏ | 2718/3298 [31:34<07:15,  1.33it/s]\u001b[A\n",
            " 82%|████████▏ | 2719/3298 [31:35<06:56,  1.39it/s]\u001b[A\n",
            " 82%|████████▏ | 2720/3298 [31:36<06:40,  1.44it/s]\u001b[A\n",
            " 83%|████████▎ | 2721/3298 [31:37<07:17,  1.32it/s]\u001b[A\n",
            " 83%|████████▎ | 2722/3298 [31:38<08:06,  1.18it/s]\u001b[A\n",
            " 83%|████████▎ | 2723/3298 [31:38<07:31,  1.27it/s]\u001b[A\n",
            " 83%|████████▎ | 2724/3298 [31:39<07:31,  1.27it/s]\u001b[A\n",
            " 83%|████████▎ | 2725/3298 [31:40<07:27,  1.28it/s]\u001b[A\n",
            " 83%|████████▎ | 2726/3298 [31:41<07:24,  1.29it/s]\u001b[A\n",
            " 83%|████████▎ | 2727/3298 [31:42<08:29,  1.12it/s]\u001b[A\n",
            " 83%|████████▎ | 2728/3298 [31:43<08:54,  1.07it/s]\u001b[A\n",
            " 83%|████████▎ | 2729/3298 [31:44<08:04,  1.17it/s]\u001b[A\n",
            " 83%|████████▎ | 2730/3298 [31:44<07:48,  1.21it/s]\u001b[A\n",
            " 83%|████████▎ | 2731/3298 [31:45<08:23,  1.13it/s]\u001b[A\n",
            " 83%|████████▎ | 2732/3298 [31:46<07:36,  1.24it/s]\u001b[A\n",
            " 83%|████████▎ | 2733/3298 [31:48<09:47,  1.04s/it]\u001b[A\n",
            " 83%|████████▎ | 2734/3298 [31:49<11:41,  1.24s/it]\u001b[A\n",
            " 83%|████████▎ | 2735/3298 [31:51<12:12,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 2736/3298 [31:52<12:10,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 2737/3298 [31:53<12:37,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 2738/3298 [31:55<12:33,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 2739/3298 [31:56<12:29,  1.34s/it]\u001b[A\n",
            " 83%|████████▎ | 2740/3298 [31:58<12:50,  1.38s/it]\u001b[A\n",
            " 83%|████████▎ | 2741/3298 [31:59<12:33,  1.35s/it]\u001b[A\n",
            " 83%|████████▎ | 2742/3298 [32:00<12:02,  1.30s/it]\u001b[A\n",
            " 83%|████████▎ | 2743/3298 [32:01<10:35,  1.14s/it]\u001b[A\n",
            " 83%|████████▎ | 2744/3298 [32:02<09:32,  1.03s/it]\u001b[A\n",
            " 83%|████████▎ | 2745/3298 [32:02<08:47,  1.05it/s]\u001b[A\n",
            " 83%|████████▎ | 2746/3298 [32:03<07:32,  1.22it/s]\u001b[A\n",
            " 83%|████████▎ | 2747/3298 [32:03<06:39,  1.38it/s]\u001b[A\n",
            " 83%|████████▎ | 2748/3298 [32:04<06:25,  1.43it/s]\u001b[A\n",
            " 83%|████████▎ | 2749/3298 [32:05<06:14,  1.47it/s]\u001b[A\n",
            " 83%|████████▎ | 2750/3298 [32:05<06:08,  1.49it/s]\u001b[A\n",
            " 83%|████████▎ | 2751/3298 [32:06<06:06,  1.49it/s]\u001b[A\n",
            " 83%|████████▎ | 2752/3298 [32:07<06:26,  1.41it/s]\u001b[A\n",
            " 83%|████████▎ | 2753/3298 [32:08<06:37,  1.37it/s]\u001b[A\n",
            " 84%|████████▎ | 2754/3298 [32:08<06:45,  1.34it/s]\u001b[A\n",
            " 84%|████████▎ | 2755/3298 [32:09<06:51,  1.32it/s]\u001b[A\n",
            " 84%|████████▎ | 2756/3298 [32:10<07:35,  1.19it/s]\u001b[A\n",
            " 84%|████████▎ | 2757/3298 [32:11<07:03,  1.28it/s]\u001b[A\n",
            " 84%|████████▎ | 2758/3298 [32:11<06:39,  1.35it/s]\u001b[A\n",
            " 84%|████████▎ | 2759/3298 [32:12<06:47,  1.32it/s]\u001b[A\n",
            " 84%|████████▎ | 2760/3298 [32:13<06:50,  1.31it/s]\u001b[A\n",
            " 84%|████████▎ | 2761/3298 [32:14<07:14,  1.24it/s]\u001b[A\n",
            " 84%|████████▎ | 2762/3298 [32:15<07:32,  1.18it/s]\u001b[A\n",
            " 84%|████████▍ | 2763/3298 [32:16<07:45,  1.15it/s]\u001b[A\n",
            " 84%|████████▍ | 2764/3298 [32:17<07:52,  1.13it/s]\u001b[A\n",
            " 84%|████████▍ | 2765/3298 [32:18<08:19,  1.07it/s]\u001b[A\n",
            " 84%|████████▍ | 2766/3298 [32:19<07:53,  1.12it/s]\u001b[A\n",
            " 84%|████████▍ | 2767/3298 [32:19<07:38,  1.16it/s]\u001b[A\n",
            " 84%|████████▍ | 2768/3298 [32:21<09:57,  1.13s/it]\u001b[A\n",
            " 84%|████████▍ | 2769/3298 [32:22<09:19,  1.06s/it]\u001b[A\n",
            " 84%|████████▍ | 2770/3298 [32:24<10:41,  1.22s/it]\u001b[A\n",
            " 84%|████████▍ | 2771/3298 [32:25<11:38,  1.33s/it]\u001b[A\n",
            " 84%|████████▍ | 2772/3298 [32:26<10:09,  1.16s/it]\u001b[A\n",
            " 84%|████████▍ | 2773/3298 [32:27<08:45,  1.00s/it]\u001b[A\n",
            " 84%|████████▍ | 2774/3298 [32:27<08:12,  1.06it/s]\u001b[A\n",
            " 84%|████████▍ | 2775/3298 [32:28<08:08,  1.07it/s]\u001b[A\n",
            " 84%|████████▍ | 2776/3298 [32:29<06:58,  1.25it/s]\u001b[A\n",
            " 84%|████████▍ | 2777/3298 [32:29<06:10,  1.40it/s]\u001b[A\n",
            " 84%|████████▍ | 2778/3298 [32:30<05:58,  1.45it/s]\u001b[A\n",
            " 84%|████████▍ | 2779/3298 [32:31<05:49,  1.49it/s]\u001b[A\n",
            " 84%|████████▍ | 2780/3298 [32:31<05:44,  1.50it/s]\u001b[A\n",
            " 84%|████████▍ | 2781/3298 [32:32<05:17,  1.63it/s]\u001b[A\n",
            " 84%|████████▍ | 2782/3298 [32:32<05:19,  1.61it/s]\u001b[A\n",
            " 84%|████████▍ | 2783/3298 [32:33<05:19,  1.61it/s]\u001b[A\n",
            " 84%|████████▍ | 2784/3298 [32:34<05:42,  1.50it/s]\u001b[A\n",
            " 84%|████████▍ | 2785/3298 [32:34<05:37,  1.52it/s]\u001b[A\n",
            " 84%|████████▍ | 2786/3298 [32:35<05:36,  1.52it/s]\u001b[A\n",
            " 85%|████████▍ | 2787/3298 [32:36<06:12,  1.37it/s]\u001b[A\n",
            " 85%|████████▍ | 2788/3298 [32:37<05:58,  1.42it/s]\u001b[A\n",
            " 85%|████████▍ | 2789/3298 [32:37<05:47,  1.46it/s]\u001b[A\n",
            " 85%|████████▍ | 2790/3298 [32:38<06:22,  1.33it/s]\u001b[A\n",
            " 85%|████████▍ | 2791/3298 [32:39<06:42,  1.26it/s]\u001b[A\n",
            " 85%|████████▍ | 2792/3298 [32:40<06:42,  1.26it/s]\u001b[A\n",
            " 85%|████████▍ | 2793/3298 [32:40<06:20,  1.33it/s]\u001b[A\n",
            " 85%|████████▍ | 2794/3298 [32:41<06:02,  1.39it/s]\u001b[A\n",
            " 85%|████████▍ | 2795/3298 [32:42<05:51,  1.43it/s]\u001b[A\n",
            " 85%|████████▍ | 2796/3298 [32:43<06:22,  1.31it/s]\u001b[A\n",
            " 85%|████████▍ | 2797/3298 [32:43<06:24,  1.30it/s]\u001b[A\n",
            " 85%|████████▍ | 2798/3298 [32:44<06:03,  1.38it/s]\u001b[A\n",
            " 85%|████████▍ | 2799/3298 [32:45<05:53,  1.41it/s]\u001b[A\n",
            " 85%|████████▍ | 2800/3298 [32:45<05:43,  1.45it/s]\u001b[A\n",
            " 85%|████████▍ | 2801/3298 [32:46<05:17,  1.57it/s]\u001b[A\n",
            " 85%|████████▍ | 2802/3298 [32:47<05:19,  1.55it/s]\u001b[A\n",
            " 85%|████████▍ | 2803/3298 [32:47<05:18,  1.55it/s]\u001b[A\n",
            " 85%|████████▌ | 2804/3298 [32:48<05:18,  1.55it/s]\u001b[A\n",
            " 85%|████████▌ | 2805/3298 [32:49<05:18,  1.55it/s]\u001b[A\n",
            " 85%|████████▌ | 2806/3298 [32:49<05:40,  1.44it/s]\u001b[A\n",
            " 85%|████████▌ | 2807/3298 [32:50<05:34,  1.47it/s]\u001b[A\n",
            " 85%|████████▌ | 2808/3298 [32:51<05:31,  1.48it/s]\u001b[A\n",
            " 85%|████████▌ | 2809/3298 [32:51<05:48,  1.40it/s]\u001b[A\n",
            " 85%|████████▌ | 2810/3298 [32:52<05:59,  1.36it/s]\u001b[A\n",
            " 85%|████████▌ | 2811/3298 [32:53<06:03,  1.34it/s]\u001b[A\n",
            " 85%|████████▌ | 2812/3298 [32:54<06:12,  1.31it/s]\u001b[A\n",
            " 85%|████████▌ | 2813/3298 [32:55<06:13,  1.30it/s]\u001b[A\n",
            " 85%|████████▌ | 2814/3298 [32:55<06:12,  1.30it/s]\u001b[A\n",
            " 85%|████████▌ | 2815/3298 [32:56<05:53,  1.37it/s]\u001b[A\n",
            " 85%|████████▌ | 2816/3298 [32:57<06:40,  1.20it/s]\u001b[A\n",
            " 85%|████████▌ | 2817/3298 [32:58<06:52,  1.17it/s]\u001b[A\n",
            " 85%|████████▌ | 2818/3298 [32:59<06:40,  1.20it/s]\u001b[A\n",
            " 85%|████████▌ | 2819/3298 [33:00<06:35,  1.21it/s]\u001b[A\n",
            " 86%|████████▌ | 2820/3298 [33:00<06:47,  1.17it/s]\u001b[A\n",
            " 86%|████████▌ | 2821/3298 [33:01<06:56,  1.15it/s]\u001b[A\n",
            " 86%|████████▌ | 2822/3298 [33:02<06:22,  1.24it/s]\u001b[A\n",
            " 86%|████████▌ | 2823/3298 [33:03<06:36,  1.20it/s]\u001b[A\n",
            " 86%|████████▌ | 2824/3298 [33:04<06:11,  1.28it/s]\u001b[A\n",
            " 86%|████████▌ | 2825/3298 [33:04<06:25,  1.23it/s]\u001b[A\n",
            " 86%|████████▌ | 2826/3298 [33:05<05:59,  1.31it/s]\u001b[A\n",
            " 86%|████████▌ | 2827/3298 [33:06<06:21,  1.24it/s]\u001b[A\n",
            " 86%|████████▌ | 2828/3298 [33:07<06:15,  1.25it/s]\u001b[A\n",
            " 86%|████████▌ | 2829/3298 [33:08<06:12,  1.26it/s]\u001b[A\n",
            " 86%|████████▌ | 2830/3298 [33:08<05:50,  1.34it/s]\u001b[A\n",
            " 86%|████████▌ | 2831/3298 [33:09<05:52,  1.32it/s]\u001b[A\n",
            " 86%|████████▌ | 2832/3298 [33:10<05:57,  1.30it/s]\u001b[A\n",
            " 86%|████████▌ | 2833/3298 [33:11<05:58,  1.30it/s]\u001b[A\n",
            " 86%|████████▌ | 2834/3298 [33:12<06:16,  1.23it/s]\u001b[A\n",
            " 86%|████████▌ | 2835/3298 [33:12<05:54,  1.31it/s]\u001b[A\n",
            " 86%|████████▌ | 2836/3298 [33:13<05:35,  1.38it/s]\u001b[A\n",
            " 86%|████████▌ | 2837/3298 [33:13<05:23,  1.43it/s]\u001b[A\n",
            " 86%|████████▌ | 2838/3298 [33:14<05:34,  1.37it/s]\u001b[A\n",
            " 86%|████████▌ | 2839/3298 [33:15<05:20,  1.43it/s]\u001b[A\n",
            " 86%|████████▌ | 2840/3298 [33:16<05:28,  1.39it/s]\u001b[A\n",
            " 86%|████████▌ | 2841/3298 [33:16<05:35,  1.36it/s]\u001b[A\n",
            " 86%|████████▌ | 2842/3298 [33:17<05:21,  1.42it/s]\u001b[A\n",
            " 86%|████████▌ | 2843/3298 [33:18<05:29,  1.38it/s]\u001b[A\n",
            " 86%|████████▌ | 2844/3298 [33:19<05:34,  1.36it/s]\u001b[A\n",
            " 86%|████████▋ | 2845/3298 [33:19<05:39,  1.33it/s]\u001b[A\n",
            " 86%|████████▋ | 2846/3298 [33:20<05:43,  1.32it/s]\u001b[A\n",
            " 86%|████████▋ | 2847/3298 [33:21<05:59,  1.25it/s]\u001b[A\n",
            " 86%|████████▋ | 2848/3298 [33:22<05:34,  1.34it/s]\u001b[A\n",
            " 86%|████████▋ | 2849/3298 [33:22<05:40,  1.32it/s]\u001b[A\n",
            " 86%|████████▋ | 2850/3298 [33:23<05:42,  1.31it/s]\u001b[A\n",
            " 86%|████████▋ | 2851/3298 [33:24<06:17,  1.19it/s]\u001b[A\n",
            " 86%|████████▋ | 2852/3298 [33:25<06:05,  1.22it/s]\u001b[A\n",
            " 87%|████████▋ | 2853/3298 [33:26<05:39,  1.31it/s]\u001b[A\n",
            " 87%|████████▋ | 2854/3298 [33:26<05:25,  1.37it/s]\u001b[A\n",
            " 87%|████████▋ | 2855/3298 [33:27<05:11,  1.42it/s]\u001b[A\n",
            " 87%|████████▋ | 2856/3298 [33:28<05:20,  1.38it/s]\u001b[A\n",
            " 87%|████████▋ | 2857/3298 [33:29<05:45,  1.28it/s]\u001b[A\n",
            " 87%|████████▋ | 2858/3298 [33:30<06:01,  1.22it/s]\u001b[A\n",
            " 87%|████████▋ | 2859/3298 [33:30<05:54,  1.24it/s]\u001b[A\n",
            " 87%|████████▋ | 2860/3298 [33:31<05:30,  1.32it/s]\u001b[A\n",
            " 87%|████████▋ | 2861/3298 [33:32<05:15,  1.39it/s]\u001b[A\n",
            " 87%|████████▋ | 2862/3298 [33:33<05:56,  1.22it/s]\u001b[A\n",
            " 87%|████████▋ | 2863/3298 [33:33<05:50,  1.24it/s]\u001b[A\n",
            " 87%|████████▋ | 2864/3298 [33:34<06:03,  1.19it/s]\u001b[A\n",
            " 87%|████████▋ | 2865/3298 [33:35<05:55,  1.22it/s]\u001b[A\n",
            " 87%|████████▋ | 2866/3298 [33:36<05:50,  1.23it/s]\u001b[A\n",
            " 87%|████████▋ | 2867/3298 [33:37<06:00,  1.19it/s]\u001b[A\n",
            " 87%|████████▋ | 2868/3298 [33:38<06:09,  1.16it/s]\u001b[A\n",
            " 87%|████████▋ | 2869/3298 [33:39<06:16,  1.14it/s]\u001b[A\n",
            " 87%|████████▋ | 2870/3298 [33:40<06:19,  1.13it/s]\u001b[A\n",
            " 87%|████████▋ | 2871/3298 [33:40<06:04,  1.17it/s]\u001b[A\n",
            " 87%|████████▋ | 2872/3298 [33:41<06:27,  1.10it/s]\u001b[A\n",
            " 87%|████████▋ | 2873/3298 [33:42<06:09,  1.15it/s]\u001b[A\n",
            " 87%|████████▋ | 2874/3298 [33:43<06:10,  1.14it/s]\u001b[A\n",
            " 87%|████████▋ | 2875/3298 [33:44<05:40,  1.24it/s]\u001b[A\n",
            " 87%|████████▋ | 2876/3298 [33:44<05:20,  1.32it/s]\u001b[A\n",
            " 87%|████████▋ | 2877/3298 [33:45<05:02,  1.39it/s]\u001b[A\n",
            " 87%|████████▋ | 2878/3298 [33:46<05:43,  1.22it/s]\u001b[A\n",
            " 87%|████████▋ | 2879/3298 [33:47<05:36,  1.24it/s]\u001b[A\n",
            " 87%|████████▋ | 2880/3298 [33:47<05:15,  1.33it/s]\u001b[A\n",
            " 87%|████████▋ | 2881/3298 [33:48<05:18,  1.31it/s]\u001b[A\n",
            " 87%|████████▋ | 2882/3298 [33:49<05:02,  1.38it/s]\u001b[A\n",
            " 87%|████████▋ | 2883/3298 [33:50<05:25,  1.27it/s]\u001b[A\n",
            " 87%|████████▋ | 2884/3298 [33:50<05:08,  1.34it/s]\u001b[A\n",
            " 87%|████████▋ | 2885/3298 [33:51<05:13,  1.32it/s]\u001b[A\n",
            " 88%|████████▊ | 2886/3298 [33:52<05:37,  1.22it/s]\u001b[A\n",
            " 88%|████████▊ | 2887/3298 [33:53<05:33,  1.23it/s]\u001b[A\n",
            " 88%|████████▊ | 2888/3298 [33:54<05:30,  1.24it/s]\u001b[A\n",
            " 88%|████████▊ | 2889/3298 [33:55<05:43,  1.19it/s]\u001b[A\n",
            " 88%|████████▊ | 2890/3298 [33:55<05:35,  1.22it/s]\u001b[A\n",
            " 88%|████████▊ | 2891/3298 [33:56<05:46,  1.17it/s]\u001b[A\n",
            " 88%|████████▊ | 2892/3298 [33:57<05:52,  1.15it/s]\u001b[A\n",
            " 88%|████████▊ | 2893/3298 [33:58<05:38,  1.20it/s]\u001b[A\n",
            " 88%|████████▊ | 2894/3298 [33:59<05:13,  1.29it/s]\u001b[A\n",
            " 88%|████████▊ | 2895/3298 [34:00<05:29,  1.22it/s]\u001b[A\n",
            " 88%|████████▊ | 2896/3298 [34:00<05:41,  1.18it/s]\u001b[A\n",
            " 88%|████████▊ | 2897/3298 [34:01<05:51,  1.14it/s]\u001b[A\n",
            " 88%|████████▊ | 2898/3298 [34:02<05:23,  1.24it/s]\u001b[A\n",
            " 88%|████████▊ | 2899/3298 [34:03<05:36,  1.19it/s]\u001b[A\n",
            " 88%|████████▊ | 2900/3298 [34:04<05:27,  1.22it/s]\u001b[A\n",
            " 88%|████████▊ | 2901/3298 [34:05<05:21,  1.24it/s]\u001b[A\n",
            " 88%|████████▊ | 2902/3298 [34:05<05:01,  1.31it/s]\u001b[A\n",
            " 88%|████████▊ | 2903/3298 [34:06<05:02,  1.31it/s]\u001b[A\n",
            " 88%|████████▊ | 2904/3298 [34:07<05:22,  1.22it/s]\u001b[A\n",
            " 88%|████████▊ | 2905/3298 [34:08<05:00,  1.31it/s]\u001b[A\n",
            " 88%|████████▊ | 2906/3298 [34:08<04:46,  1.37it/s]\u001b[A\n",
            " 88%|████████▊ | 2907/3298 [34:09<04:33,  1.43it/s]\u001b[A\n",
            " 88%|████████▊ | 2908/3298 [34:10<04:57,  1.31it/s]\u001b[A\n",
            " 88%|████████▊ | 2909/3298 [34:10<04:44,  1.37it/s]\u001b[A\n",
            " 88%|████████▊ | 2910/3298 [34:11<04:49,  1.34it/s]\u001b[A\n",
            " 88%|████████▊ | 2911/3298 [34:12<04:35,  1.41it/s]\u001b[A\n",
            " 88%|████████▊ | 2912/3298 [34:13<04:39,  1.38it/s]\u001b[A\n",
            " 88%|████████▊ | 2913/3298 [34:13<04:45,  1.35it/s]\u001b[A\n",
            " 88%|████████▊ | 2914/3298 [34:14<04:49,  1.33it/s]\u001b[A\n",
            " 88%|████████▊ | 2915/3298 [34:15<04:36,  1.39it/s]\u001b[A\n",
            " 88%|████████▊ | 2916/3298 [34:16<04:44,  1.34it/s]\u001b[A\n",
            " 88%|████████▊ | 2917/3298 [34:16<04:31,  1.41it/s]\u001b[A\n",
            " 88%|████████▊ | 2918/3298 [34:17<04:37,  1.37it/s]\u001b[A\n",
            " 89%|████████▊ | 2919/3298 [34:18<05:11,  1.22it/s]\u001b[A\n",
            " 89%|████████▊ | 2920/3298 [34:19<05:05,  1.24it/s]\u001b[A\n",
            " 89%|████████▊ | 2921/3298 [34:19<04:45,  1.32it/s]\u001b[A\n",
            " 89%|████████▊ | 2922/3298 [34:20<04:31,  1.38it/s]\u001b[A\n",
            " 89%|████████▊ | 2923/3298 [34:21<04:37,  1.35it/s]\u001b[A\n",
            " 89%|████████▊ | 2924/3298 [34:21<04:26,  1.40it/s]\u001b[A\n",
            " 89%|████████▊ | 2925/3298 [34:22<04:18,  1.44it/s]\u001b[A\n",
            " 89%|████████▊ | 2926/3298 [34:23<04:11,  1.48it/s]\u001b[A\n",
            " 89%|████████▉ | 2927/3298 [34:24<04:22,  1.41it/s]\u001b[A\n",
            " 89%|████████▉ | 2928/3298 [34:25<05:00,  1.23it/s]\u001b[A\n",
            " 89%|████████▉ | 2929/3298 [34:25<04:55,  1.25it/s]\u001b[A\n",
            " 89%|████████▉ | 2930/3298 [34:26<04:49,  1.27it/s]\u001b[A\n",
            " 89%|████████▉ | 2931/3298 [34:27<04:47,  1.27it/s]\u001b[A\n",
            " 89%|████████▉ | 2932/3298 [34:28<04:46,  1.28it/s]\u001b[A\n",
            " 89%|████████▉ | 2933/3298 [34:29<04:47,  1.27it/s]\u001b[A\n",
            " 89%|████████▉ | 2934/3298 [34:29<04:30,  1.35it/s]\u001b[A\n",
            " 89%|████████▉ | 2935/3298 [34:30<04:35,  1.32it/s]\u001b[A\n",
            " 89%|████████▉ | 2936/3298 [34:31<04:23,  1.37it/s]\u001b[A\n",
            " 89%|████████▉ | 2937/3298 [34:31<04:13,  1.42it/s]\u001b[A\n",
            " 89%|████████▉ | 2938/3298 [34:32<04:21,  1.38it/s]\u001b[A\n",
            " 89%|████████▉ | 2939/3298 [34:33<04:11,  1.42it/s]\u001b[A\n",
            " 89%|████████▉ | 2940/3298 [34:33<04:04,  1.46it/s]\u001b[A\n",
            " 89%|████████▉ | 2941/3298 [34:34<04:16,  1.39it/s]\u001b[A\n",
            " 89%|████████▉ | 2942/3298 [34:35<04:35,  1.29it/s]\u001b[A\n",
            " 89%|████████▉ | 2943/3298 [34:36<04:19,  1.37it/s]\u001b[A\n",
            " 89%|████████▉ | 2944/3298 [34:36<04:07,  1.43it/s]\u001b[A\n",
            " 89%|████████▉ | 2945/3298 [34:37<04:00,  1.47it/s]\u001b[A\n",
            " 89%|████████▉ | 2946/3298 [34:38<03:56,  1.49it/s]\u001b[A\n",
            " 89%|████████▉ | 2947/3298 [34:38<03:50,  1.52it/s]\u001b[A\n",
            " 89%|████████▉ | 2948/3298 [34:39<03:48,  1.53it/s]\u001b[A\n",
            " 89%|████████▉ | 2949/3298 [34:39<03:49,  1.52it/s]\u001b[A\n",
            " 89%|████████▉ | 2950/3298 [34:40<03:46,  1.53it/s]\u001b[A\n",
            " 89%|████████▉ | 2951/3298 [34:41<03:59,  1.45it/s]\u001b[A\n",
            " 90%|████████▉ | 2952/3298 [34:42<04:06,  1.40it/s]\u001b[A\n",
            " 90%|████████▉ | 2953/3298 [34:42<04:11,  1.37it/s]\u001b[A\n",
            " 90%|████████▉ | 2954/3298 [34:43<04:31,  1.27it/s]\u001b[A\n",
            " 90%|████████▉ | 2955/3298 [34:44<04:16,  1.34it/s]\u001b[A\n",
            " 90%|████████▉ | 2956/3298 [34:45<04:07,  1.38it/s]\u001b[A\n",
            " 90%|████████▉ | 2957/3298 [34:45<04:13,  1.34it/s]\u001b[A\n",
            " 90%|████████▉ | 2958/3298 [34:46<04:16,  1.32it/s]\u001b[A\n",
            " 90%|████████▉ | 2959/3298 [34:47<04:04,  1.39it/s]\u001b[A\n",
            " 90%|████████▉ | 2960/3298 [34:48<04:24,  1.28it/s]\u001b[A\n",
            " 90%|████████▉ | 2961/3298 [34:49<04:36,  1.22it/s]\u001b[A\n",
            " 90%|████████▉ | 2962/3298 [34:50<04:31,  1.24it/s]\u001b[A\n",
            " 90%|████████▉ | 2963/3298 [34:50<04:41,  1.19it/s]\u001b[A\n",
            " 90%|████████▉ | 2964/3298 [34:51<04:36,  1.21it/s]\u001b[A\n",
            " 90%|████████▉ | 2965/3298 [34:52<04:17,  1.29it/s]\u001b[A\n",
            " 90%|████████▉ | 2966/3298 [34:53<04:18,  1.28it/s]\u001b[A\n",
            " 90%|████████▉ | 2967/3298 [34:53<04:18,  1.28it/s]\u001b[A\n",
            " 90%|████████▉ | 2968/3298 [34:54<04:17,  1.28it/s]\u001b[A\n",
            " 90%|█████████ | 2969/3298 [34:55<04:15,  1.29it/s]\u001b[A\n",
            " 90%|█████████ | 2970/3298 [34:56<04:27,  1.22it/s]\u001b[A\n",
            " 90%|█████████ | 2971/3298 [34:57<04:09,  1.31it/s]\u001b[A\n",
            " 90%|█████████ | 2972/3298 [34:57<04:11,  1.30it/s]\u001b[A\n",
            " 90%|█████████ | 2973/3298 [34:58<04:10,  1.30it/s]\u001b[A\n",
            " 90%|█████████ | 2974/3298 [34:59<04:11,  1.29it/s]\u001b[A\n",
            " 90%|█████████ | 2975/3298 [35:00<04:23,  1.23it/s]\u001b[A\n",
            " 90%|█████████ | 2976/3298 [35:01<04:32,  1.18it/s]\u001b[A\n",
            " 90%|█████████ | 2977/3298 [35:02<04:37,  1.16it/s]\u001b[A\n",
            " 90%|█████████ | 2978/3298 [35:02<04:02,  1.32it/s]\u001b[A\n",
            " 90%|█████████ | 2979/3298 [35:03<03:50,  1.38it/s]\u001b[A\n",
            " 90%|█████████ | 2980/3298 [35:04<03:53,  1.36it/s]\u001b[A\n",
            " 90%|█████████ | 2981/3298 [35:04<03:55,  1.35it/s]\u001b[A\n",
            " 90%|█████████ | 2982/3298 [35:05<03:58,  1.32it/s]\u001b[A\n",
            " 90%|█████████ | 2983/3298 [35:06<03:47,  1.39it/s]\u001b[A\n",
            " 90%|█████████ | 2984/3298 [35:07<03:52,  1.35it/s]\u001b[A\n",
            " 91%|█████████ | 2985/3298 [35:07<03:43,  1.40it/s]\u001b[A\n",
            " 91%|█████████ | 2986/3298 [35:08<03:37,  1.44it/s]\u001b[A\n",
            " 91%|█████████ | 2987/3298 [35:08<03:19,  1.56it/s]\u001b[A\n",
            " 91%|█████████ | 2988/3298 [35:09<03:17,  1.57it/s]\u001b[A\n",
            " 91%|█████████ | 2989/3298 [35:09<03:05,  1.66it/s]\u001b[A\n",
            " 91%|█████████ | 2990/3298 [35:10<03:08,  1.64it/s]\u001b[A\n",
            " 91%|█████████ | 2991/3298 [35:11<03:09,  1.62it/s]\u001b[A\n",
            " 91%|█████████ | 2992/3298 [35:11<03:10,  1.60it/s]\u001b[A\n",
            " 91%|█████████ | 2993/3298 [35:12<03:11,  1.59it/s]\u001b[A\n",
            " 91%|█████████ | 2994/3298 [35:13<03:11,  1.58it/s]\u001b[A\n",
            " 91%|█████████ | 2995/3298 [35:13<03:14,  1.56it/s]\u001b[A\n",
            " 91%|█████████ | 2996/3298 [35:14<03:14,  1.55it/s]\u001b[A\n",
            " 91%|█████████ | 2997/3298 [35:15<03:26,  1.46it/s]\u001b[A\n",
            " 91%|█████████ | 2998/3298 [35:16<03:35,  1.39it/s]\u001b[A\n",
            " 91%|█████████ | 2999/3298 [35:16<03:41,  1.35it/s]\u001b[A\n",
            " 91%|█████████ | 3000/3298 [35:17<03:44,  1.33it/s]\u001b[A\n",
            " 91%|█████████ | 3001/3298 [35:18<03:47,  1.31it/s]\u001b[A\n",
            " 91%|█████████ | 3002/3298 [35:19<03:59,  1.23it/s]\u001b[A\n",
            " 91%|█████████ | 3003/3298 [35:20<03:58,  1.24it/s]\u001b[A\n",
            " 91%|█████████ | 3004/3298 [35:20<03:56,  1.24it/s]\u001b[A\n",
            " 91%|█████████ | 3005/3298 [35:21<03:53,  1.26it/s]\u001b[A\n",
            " 91%|█████████ | 3006/3298 [35:22<03:51,  1.26it/s]\u001b[A\n",
            " 91%|█████████ | 3007/3298 [35:23<03:49,  1.27it/s]\u001b[A\n",
            " 91%|█████████ | 3008/3298 [35:24<03:48,  1.27it/s]\u001b[A\n",
            " 91%|█████████ | 3009/3298 [35:24<03:46,  1.27it/s]\u001b[A\n",
            " 91%|█████████▏| 3010/3298 [35:25<03:57,  1.21it/s]\u001b[A\n",
            " 91%|█████████▏| 3011/3298 [35:26<04:03,  1.18it/s]\u001b[A\n",
            " 91%|█████████▏| 3012/3298 [35:27<04:08,  1.15it/s]\u001b[A\n",
            " 91%|█████████▏| 3013/3298 [35:28<04:13,  1.12it/s]\u001b[A\n",
            " 91%|█████████▏| 3014/3298 [35:29<04:27,  1.06it/s]\u001b[A\n",
            " 91%|█████████▏| 3015/3298 [35:30<04:00,  1.18it/s]\u001b[A\n",
            " 91%|█████████▏| 3016/3298 [35:31<04:19,  1.09it/s]\u001b[A\n",
            " 91%|█████████▏| 3017/3298 [35:31<03:55,  1.20it/s]\u001b[A\n",
            " 92%|█████████▏| 3018/3298 [35:32<03:50,  1.21it/s]\u001b[A\n",
            " 92%|█████████▏| 3019/3298 [35:33<03:34,  1.30it/s]\u001b[A\n",
            " 92%|█████████▏| 3020/3298 [35:34<03:24,  1.36it/s]\u001b[A\n",
            " 92%|█████████▏| 3021/3298 [35:34<03:16,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 3022/3298 [35:35<03:10,  1.45it/s]\u001b[A\n",
            " 92%|█████████▏| 3023/3298 [35:35<03:05,  1.48it/s]\u001b[A\n",
            " 92%|█████████▏| 3024/3298 [35:36<03:01,  1.51it/s]\u001b[A\n",
            " 92%|█████████▏| 3025/3298 [35:37<02:59,  1.52it/s]\u001b[A\n",
            " 92%|█████████▏| 3026/3298 [35:37<02:57,  1.53it/s]\u001b[A\n",
            " 92%|█████████▏| 3027/3298 [35:38<03:06,  1.45it/s]\u001b[A\n",
            " 92%|█████████▏| 3028/3298 [35:39<03:12,  1.40it/s]\u001b[A\n",
            " 92%|█████████▏| 3029/3298 [35:40<03:28,  1.29it/s]\u001b[A\n",
            " 92%|█████████▏| 3030/3298 [35:41<03:30,  1.28it/s]\u001b[A\n",
            " 92%|█████████▏| 3031/3298 [35:41<03:09,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 3032/3298 [35:42<03:15,  1.36it/s]\u001b[A\n",
            " 92%|█████████▏| 3033/3298 [35:43<03:18,  1.33it/s]\u001b[A\n",
            " 92%|█████████▏| 3034/3298 [35:44<03:21,  1.31it/s]\u001b[A\n",
            " 92%|█████████▏| 3035/3298 [35:44<03:12,  1.37it/s]\u001b[A\n",
            " 92%|█████████▏| 3036/3298 [35:45<03:03,  1.43it/s]\u001b[A\n",
            " 92%|█████████▏| 3037/3298 [35:46<03:01,  1.44it/s]\u001b[A\n",
            " 92%|█████████▏| 3038/3298 [35:46<02:57,  1.46it/s]\u001b[A\n",
            " 92%|█████████▏| 3039/3298 [35:47<02:55,  1.47it/s]\u001b[A\n",
            " 92%|█████████▏| 3040/3298 [35:48<02:53,  1.49it/s]\u001b[A\n",
            " 92%|█████████▏| 3041/3298 [35:48<03:02,  1.41it/s]\u001b[A\n",
            " 92%|█████████▏| 3042/3298 [35:49<03:06,  1.37it/s]\u001b[A\n",
            " 92%|█████████▏| 3043/3298 [35:50<03:09,  1.35it/s]\u001b[A\n",
            " 92%|█████████▏| 3044/3298 [35:51<03:13,  1.31it/s]\u001b[A\n",
            " 92%|█████████▏| 3045/3298 [35:51<03:15,  1.30it/s]\u001b[A\n",
            " 92%|█████████▏| 3046/3298 [35:52<03:16,  1.28it/s]\u001b[A\n",
            " 92%|█████████▏| 3047/3298 [35:53<03:17,  1.27it/s]\u001b[A\n",
            " 92%|█████████▏| 3048/3298 [35:54<03:26,  1.21it/s]\u001b[A\n",
            " 92%|█████████▏| 3049/3298 [35:55<03:21,  1.24it/s]\u001b[A\n",
            " 92%|█████████▏| 3050/3298 [35:56<03:26,  1.20it/s]\u001b[A\n",
            " 93%|█████████▎| 3051/3298 [35:56<03:11,  1.29it/s]\u001b[A\n",
            " 93%|█████████▎| 3052/3298 [35:57<03:21,  1.22it/s]\u001b[A\n",
            " 93%|█████████▎| 3053/3298 [35:58<03:16,  1.25it/s]\u001b[A\n",
            " 93%|█████████▎| 3054/3298 [35:59<03:14,  1.25it/s]\u001b[A\n",
            " 93%|█████████▎| 3055/3298 [35:59<03:03,  1.33it/s]\u001b[A\n",
            " 93%|█████████▎| 3056/3298 [36:00<02:54,  1.39it/s]\u001b[A\n",
            " 93%|█████████▎| 3057/3298 [36:01<02:48,  1.43it/s]\u001b[A\n",
            " 93%|█████████▎| 3058/3298 [36:01<02:43,  1.47it/s]\u001b[A\n",
            " 93%|█████████▎| 3059/3298 [36:02<02:41,  1.48it/s]\u001b[A\n",
            " 93%|█████████▎| 3060/3298 [36:03<02:37,  1.51it/s]\u001b[A\n",
            " 93%|█████████▎| 3061/3298 [36:03<02:37,  1.50it/s]\u001b[A\n",
            " 93%|█████████▎| 3062/3298 [36:04<02:35,  1.52it/s]\u001b[A\n",
            " 93%|█████████▎| 3063/3298 [36:05<02:33,  1.53it/s]\u001b[A\n",
            " 93%|█████████▎| 3064/3298 [36:05<02:34,  1.52it/s]\u001b[A\n",
            " 93%|█████████▎| 3065/3298 [36:06<02:32,  1.53it/s]\u001b[A\n",
            " 93%|█████████▎| 3066/3298 [36:07<02:31,  1.53it/s]\u001b[A\n",
            " 93%|█████████▎| 3067/3298 [36:07<02:30,  1.53it/s]\u001b[A\n",
            " 93%|█████████▎| 3068/3298 [36:08<02:28,  1.55it/s]\u001b[A\n",
            " 93%|█████████▎| 3069/3298 [36:08<02:27,  1.55it/s]\u001b[A\n",
            " 93%|█████████▎| 3070/3298 [36:09<02:26,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 3071/3298 [36:10<02:25,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 3072/3298 [36:10<02:24,  1.57it/s]\u001b[A\n",
            " 93%|█████████▎| 3073/3298 [36:11<02:23,  1.57it/s]\u001b[A\n",
            " 93%|█████████▎| 3074/3298 [36:12<02:23,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 3075/3298 [36:12<02:22,  1.57it/s]\u001b[A\n",
            " 93%|█████████▎| 3076/3298 [36:13<02:22,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 3077/3298 [36:14<02:22,  1.55it/s]\u001b[A\n",
            " 93%|█████████▎| 3078/3298 [36:14<02:21,  1.56it/s]\u001b[A\n",
            " 93%|█████████▎| 3079/3298 [36:15<02:37,  1.39it/s]\u001b[A\n",
            " 93%|█████████▎| 3080/3298 [36:16<02:49,  1.29it/s]\u001b[A\n",
            " 93%|█████████▎| 3081/3298 [36:17<02:56,  1.23it/s]\u001b[A\n",
            " 93%|█████████▎| 3082/3298 [36:18<03:01,  1.19it/s]\u001b[A\n",
            " 93%|█████████▎| 3083/3298 [36:19<03:04,  1.16it/s]\u001b[A\n",
            " 94%|█████████▎| 3084/3298 [36:20<03:08,  1.14it/s]\u001b[A\n",
            " 94%|█████████▎| 3085/3298 [36:21<03:10,  1.12it/s]\u001b[A\n",
            " 94%|█████████▎| 3086/3298 [36:22<03:12,  1.10it/s]\u001b[A\n",
            " 94%|█████████▎| 3087/3298 [36:22<03:12,  1.10it/s]\u001b[A\n",
            " 94%|█████████▎| 3088/3298 [36:23<03:12,  1.09it/s]\u001b[A\n",
            " 94%|█████████▎| 3089/3298 [36:24<03:02,  1.14it/s]\u001b[A\n",
            " 94%|█████████▎| 3090/3298 [36:25<02:56,  1.18it/s]\u001b[A\n",
            " 94%|█████████▎| 3091/3298 [36:26<02:52,  1.20it/s]\u001b[A\n",
            " 94%|█████████▍| 3092/3298 [36:27<02:48,  1.22it/s]\u001b[A\n",
            " 94%|█████████▍| 3093/3298 [36:27<02:53,  1.18it/s]\u001b[A\n",
            " 94%|█████████▍| 3094/3298 [36:28<02:56,  1.16it/s]\u001b[A\n",
            " 94%|█████████▍| 3095/3298 [36:29<02:58,  1.14it/s]\u001b[A\n",
            " 94%|█████████▍| 3096/3298 [36:30<02:59,  1.12it/s]\u001b[A\n",
            " 94%|█████████▍| 3097/3298 [36:31<03:01,  1.11it/s]\u001b[A\n",
            " 94%|█████████▍| 3098/3298 [36:32<03:02,  1.09it/s]\u001b[A\n",
            " 94%|█████████▍| 3099/3298 [36:33<03:02,  1.09it/s]\u001b[A\n",
            " 94%|█████████▍| 3100/3298 [36:34<03:03,  1.08it/s]\u001b[A\n",
            " 94%|█████████▍| 3101/3298 [36:35<03:01,  1.09it/s]\u001b[A\n",
            " 94%|█████████▍| 3102/3298 [36:36<02:59,  1.09it/s]\u001b[A\n",
            " 94%|█████████▍| 3103/3298 [36:36<02:35,  1.26it/s]\u001b[A\n",
            " 94%|█████████▍| 3104/3298 [36:37<02:26,  1.33it/s]\u001b[A\n",
            " 94%|█████████▍| 3105/3298 [36:38<02:27,  1.31it/s]\u001b[A\n",
            " 94%|█████████▍| 3106/3298 [36:38<02:19,  1.37it/s]\u001b[A\n",
            " 94%|█████████▍| 3107/3298 [36:39<02:14,  1.42it/s]\u001b[A\n",
            " 94%|█████████▍| 3108/3298 [36:40<02:11,  1.45it/s]\u001b[A\n",
            " 94%|█████████▍| 3109/3298 [36:40<02:09,  1.46it/s]\u001b[A\n",
            " 94%|█████████▍| 3110/3298 [36:41<02:06,  1.48it/s]\u001b[A\n",
            " 94%|█████████▍| 3111/3298 [36:42<02:04,  1.50it/s]\u001b[A\n",
            " 94%|█████████▍| 3112/3298 [36:42<02:02,  1.52it/s]\u001b[A\n",
            " 94%|█████████▍| 3113/3298 [36:43<02:01,  1.53it/s]\u001b[A\n",
            " 94%|█████████▍| 3114/3298 [36:44<02:00,  1.53it/s]\u001b[A\n",
            " 94%|█████████▍| 3115/3298 [36:44<01:59,  1.53it/s]\u001b[A\n",
            " 94%|█████████▍| 3116/3298 [36:45<01:59,  1.52it/s]\u001b[A\n",
            " 95%|█████████▍| 3117/3298 [36:46<02:13,  1.36it/s]\u001b[A\n",
            " 95%|█████████▍| 3118/3298 [36:47<02:23,  1.26it/s]\u001b[A\n",
            " 95%|█████████▍| 3119/3298 [36:47<02:15,  1.32it/s]\u001b[A\n",
            " 95%|█████████▍| 3120/3298 [36:48<02:08,  1.38it/s]\u001b[A\n",
            " 95%|█████████▍| 3121/3298 [36:49<02:12,  1.34it/s]\u001b[A\n",
            " 95%|█████████▍| 3122/3298 [36:50<02:15,  1.30it/s]\u001b[A\n",
            " 95%|█████████▍| 3123/3298 [36:50<02:16,  1.28it/s]\u001b[A\n",
            " 95%|█████████▍| 3124/3298 [36:51<02:15,  1.28it/s]\u001b[A\n",
            " 95%|█████████▍| 3125/3298 [36:52<02:14,  1.28it/s]\u001b[A\n",
            " 95%|█████████▍| 3126/3298 [36:53<02:14,  1.28it/s]\u001b[A\n",
            " 95%|█████████▍| 3127/3298 [36:54<02:14,  1.27it/s]\u001b[A\n",
            " 95%|█████████▍| 3128/3298 [36:54<02:14,  1.27it/s]\u001b[A\n",
            " 95%|█████████▍| 3129/3298 [36:55<02:14,  1.26it/s]\u001b[A\n",
            " 95%|█████████▍| 3130/3298 [36:56<02:12,  1.26it/s]\u001b[A\n",
            " 95%|█████████▍| 3131/3298 [36:57<02:11,  1.27it/s]\u001b[A\n",
            " 95%|█████████▍| 3132/3298 [36:58<02:10,  1.28it/s]\u001b[A\n",
            " 95%|█████████▍| 3133/3298 [36:58<02:02,  1.35it/s]\u001b[A\n",
            " 95%|█████████▌| 3134/3298 [36:59<01:56,  1.41it/s]\u001b[A\n",
            " 95%|█████████▌| 3135/3298 [37:00<01:53,  1.43it/s]\u001b[A\n",
            " 95%|█████████▌| 3136/3298 [37:00<01:50,  1.46it/s]\u001b[A\n",
            " 95%|█████████▌| 3137/3298 [37:01<01:47,  1.50it/s]\u001b[A\n",
            " 95%|█████████▌| 3138/3298 [37:01<01:45,  1.51it/s]\u001b[A\n",
            " 95%|█████████▌| 3139/3298 [37:02<01:44,  1.52it/s]\u001b[A\n",
            " 95%|█████████▌| 3140/3298 [37:03<01:43,  1.53it/s]\u001b[A\n",
            " 95%|█████████▌| 3141/3298 [37:03<01:42,  1.53it/s]\u001b[A\n",
            " 95%|█████████▌| 3142/3298 [37:04<01:41,  1.54it/s]\u001b[A\n",
            " 95%|█████████▌| 3143/3298 [37:05<01:40,  1.54it/s]\u001b[A\n",
            " 95%|█████████▌| 3144/3298 [37:05<01:40,  1.54it/s]\u001b[A\n",
            " 95%|█████████▌| 3145/3298 [37:06<01:38,  1.55it/s]\u001b[A\n",
            " 95%|█████████▌| 3146/3298 [37:07<01:44,  1.45it/s]\u001b[A\n",
            " 95%|█████████▌| 3147/3298 [37:08<01:48,  1.39it/s]\u001b[A\n",
            " 95%|█████████▌| 3148/3298 [37:08<01:56,  1.28it/s]\u001b[A\n",
            " 95%|█████████▌| 3149/3298 [37:09<01:49,  1.36it/s]\u001b[A\n",
            " 96%|█████████▌| 3150/3298 [37:10<01:50,  1.33it/s]\u001b[A\n",
            " 96%|█████████▌| 3151/3298 [37:11<01:56,  1.26it/s]\u001b[A\n",
            " 96%|█████████▌| 3152/3298 [37:11<01:43,  1.41it/s]\u001b[A\n",
            " 96%|█████████▌| 3153/3298 [37:12<01:33,  1.55it/s]\u001b[A\n",
            " 96%|█████████▌| 3154/3298 [37:12<01:26,  1.67it/s]\u001b[A\n",
            " 96%|█████████▌| 3155/3298 [37:13<01:21,  1.76it/s]\u001b[A\n",
            " 96%|█████████▌| 3156/3298 [37:13<01:23,  1.69it/s]\u001b[A\n",
            " 96%|█████████▌| 3157/3298 [37:14<01:25,  1.65it/s]\u001b[A\n",
            " 96%|█████████▌| 3158/3298 [37:15<01:26,  1.63it/s]\u001b[A\n",
            " 96%|█████████▌| 3159/3298 [37:16<01:37,  1.42it/s]\u001b[A\n",
            " 96%|█████████▌| 3160/3298 [37:17<01:46,  1.30it/s]\u001b[A\n",
            " 96%|█████████▌| 3161/3298 [37:17<01:45,  1.30it/s]\u001b[A\n",
            " 96%|█████████▌| 3162/3298 [37:18<01:44,  1.30it/s]\u001b[A\n",
            " 96%|█████████▌| 3163/3298 [37:19<01:43,  1.30it/s]\u001b[A\n",
            " 96%|█████████▌| 3164/3298 [37:20<01:43,  1.29it/s]\u001b[A\n",
            " 96%|█████████▌| 3165/3298 [37:20<01:42,  1.29it/s]\u001b[A\n",
            " 96%|█████████▌| 3166/3298 [37:21<01:42,  1.29it/s]\u001b[A\n",
            " 96%|█████████▌| 3167/3298 [37:22<01:41,  1.29it/s]\u001b[A\n",
            " 96%|█████████▌| 3168/3298 [37:22<01:30,  1.44it/s]\u001b[A\n",
            " 96%|█████████▌| 3169/3298 [37:23<01:22,  1.56it/s]\u001b[A\n",
            " 96%|█████████▌| 3170/3298 [37:24<01:22,  1.55it/s]\u001b[A\n",
            " 96%|█████████▌| 3171/3298 [37:24<01:16,  1.65it/s]\u001b[A\n",
            " 96%|█████████▌| 3172/3298 [37:25<01:22,  1.53it/s]\u001b[A\n",
            " 96%|█████████▌| 3173/3298 [37:26<01:21,  1.54it/s]\u001b[A\n",
            " 96%|█████████▌| 3174/3298 [37:26<01:25,  1.44it/s]\u001b[A\n",
            " 96%|█████████▋| 3175/3298 [37:27<01:18,  1.56it/s]\u001b[A\n",
            " 96%|█████████▋| 3176/3298 [37:27<01:14,  1.64it/s]\u001b[A\n",
            " 96%|█████████▋| 3177/3298 [37:28<01:14,  1.62it/s]\u001b[A\n",
            " 96%|█████████▋| 3178/3298 [37:29<01:14,  1.61it/s]\u001b[A\n",
            " 96%|█████████▋| 3179/3298 [37:29<01:15,  1.58it/s]\u001b[A\n",
            " 96%|█████████▋| 3180/3298 [37:30<01:19,  1.48it/s]\u001b[A\n",
            " 96%|█████████▋| 3181/3298 [37:31<01:17,  1.51it/s]\u001b[A\n",
            " 96%|█████████▋| 3182/3298 [37:31<01:16,  1.53it/s]\u001b[A\n",
            " 97%|█████████▋| 3183/3298 [37:32<01:15,  1.53it/s]\u001b[A\n",
            " 97%|█████████▋| 3184/3298 [37:33<01:14,  1.54it/s]\u001b[A\n",
            " 97%|█████████▋| 3185/3298 [37:33<01:08,  1.65it/s]\u001b[A\n",
            " 97%|█████████▋| 3186/3298 [37:34<01:14,  1.51it/s]\u001b[A\n",
            " 97%|█████████▋| 3187/3298 [37:35<01:17,  1.42it/s]\u001b[A\n",
            " 97%|█████████▋| 3188/3298 [37:36<01:19,  1.38it/s]\u001b[A\n",
            " 97%|█████████▋| 3189/3298 [37:36<01:16,  1.43it/s]\u001b[A\n",
            " 97%|█████████▋| 3190/3298 [37:37<01:08,  1.57it/s]\u001b[A\n",
            " 97%|█████████▋| 3191/3298 [37:37<01:04,  1.66it/s]\u001b[A\n",
            " 97%|█████████▋| 3192/3298 [37:38<01:05,  1.62it/s]\u001b[A\n",
            " 97%|█████████▋| 3193/3298 [37:38<01:05,  1.60it/s]\u001b[A\n",
            " 97%|█████████▋| 3194/3298 [37:39<01:01,  1.69it/s]\u001b[A\n",
            " 97%|█████████▋| 3195/3298 [37:40<00:58,  1.75it/s]\u001b[A\n",
            " 97%|█████████▋| 3196/3298 [37:40<01:04,  1.58it/s]\u001b[A\n",
            " 97%|█████████▋| 3197/3298 [37:41<01:08,  1.48it/s]\u001b[A\n",
            " 97%|█████████▋| 3198/3298 [37:42<01:10,  1.42it/s]\u001b[A\n",
            " 97%|█████████▋| 3199/3298 [37:42<01:07,  1.46it/s]\u001b[A\n",
            " 97%|█████████▋| 3200/3298 [37:43<01:06,  1.48it/s]\u001b[A\n",
            " 97%|█████████▋| 3201/3298 [37:44<01:00,  1.61it/s]\u001b[A\n",
            " 97%|█████████▋| 3202/3298 [37:44<01:00,  1.59it/s]\u001b[A\n",
            " 97%|█████████▋| 3203/3298 [37:45<00:59,  1.59it/s]\u001b[A\n",
            " 97%|█████████▋| 3204/3298 [37:46<01:03,  1.49it/s]\u001b[A\n",
            " 97%|█████████▋| 3205/3298 [37:46<01:01,  1.51it/s]\u001b[A\n",
            " 97%|█████████▋| 3206/3298 [37:47<00:59,  1.53it/s]\u001b[A\n",
            " 97%|█████████▋| 3207/3298 [37:48<00:58,  1.55it/s]\u001b[A\n",
            " 97%|█████████▋| 3208/3298 [37:48<00:57,  1.55it/s]\u001b[A\n",
            " 97%|█████████▋| 3209/3298 [37:49<01:00,  1.47it/s]\u001b[A\n",
            " 97%|█████████▋| 3210/3298 [37:50<00:59,  1.49it/s]\u001b[A\n",
            " 97%|█████████▋| 3211/3298 [37:50<01:01,  1.41it/s]\u001b[A\n",
            " 97%|█████████▋| 3212/3298 [37:51<01:02,  1.37it/s]\u001b[A\n",
            " 97%|█████████▋| 3213/3298 [37:52<00:59,  1.42it/s]\u001b[A\n",
            " 97%|█████████▋| 3214/3298 [37:53<01:01,  1.36it/s]\u001b[A\n",
            " 97%|█████████▋| 3215/3298 [37:53<00:59,  1.41it/s]\u001b[A\n",
            " 98%|█████████▊| 3216/3298 [37:54<00:57,  1.44it/s]\u001b[A\n",
            " 98%|█████████▊| 3217/3298 [37:55<00:58,  1.38it/s]\u001b[A\n",
            " 98%|█████████▊| 3218/3298 [37:56<00:59,  1.34it/s]\u001b[A\n",
            " 98%|█████████▊| 3219/3298 [37:56<00:56,  1.39it/s]\u001b[A\n",
            " 98%|█████████▊| 3220/3298 [37:57<00:57,  1.35it/s]\u001b[A\n",
            " 98%|█████████▊| 3221/3298 [37:58<00:58,  1.33it/s]\u001b[A\n",
            " 98%|█████████▊| 3222/3298 [37:58<00:55,  1.37it/s]\u001b[A\n",
            " 98%|█████████▊| 3223/3298 [37:59<00:52,  1.42it/s]\u001b[A\n",
            " 98%|█████████▊| 3224/3298 [38:00<00:50,  1.46it/s]\u001b[A\n",
            " 98%|█████████▊| 3225/3298 [38:00<00:49,  1.47it/s]\u001b[A\n",
            " 98%|█████████▊| 3226/3298 [38:01<00:48,  1.49it/s]\u001b[A\n",
            " 98%|█████████▊| 3227/3298 [38:02<00:49,  1.42it/s]\u001b[A\n",
            " 98%|█████████▊| 3228/3298 [38:02<00:48,  1.45it/s]\u001b[A\n",
            " 98%|█████████▊| 3229/3298 [38:03<00:43,  1.58it/s]\u001b[A\n",
            " 98%|█████████▊| 3230/3298 [38:04<00:43,  1.57it/s]\u001b[A\n",
            " 98%|█████████▊| 3231/3298 [38:04<00:39,  1.68it/s]\u001b[A\n",
            " 98%|█████████▊| 3232/3298 [38:05<00:40,  1.64it/s]\u001b[A\n",
            " 98%|█████████▊| 3233/3298 [38:05<00:40,  1.62it/s]\u001b[A\n",
            " 98%|█████████▊| 3234/3298 [38:06<00:40,  1.60it/s]\u001b[A\n",
            " 98%|█████████▊| 3235/3298 [38:07<00:39,  1.58it/s]\u001b[A\n",
            " 98%|█████████▊| 3236/3298 [38:08<00:42,  1.47it/s]\u001b[A\n",
            " 98%|█████████▊| 3237/3298 [38:08<00:40,  1.50it/s]\u001b[A\n",
            " 98%|█████████▊| 3238/3298 [38:09<00:39,  1.51it/s]\u001b[A\n",
            " 98%|█████████▊| 3239/3298 [38:09<00:38,  1.53it/s]\u001b[A\n",
            " 98%|█████████▊| 3240/3298 [38:10<00:38,  1.53it/s]\u001b[A\n",
            " 98%|█████████▊| 3241/3298 [38:11<00:36,  1.54it/s]\u001b[A\n",
            " 98%|█████████▊| 3242/3298 [38:11<00:36,  1.54it/s]\u001b[A\n",
            " 98%|█████████▊| 3243/3298 [38:12<00:35,  1.54it/s]\u001b[A\n",
            " 98%|█████████▊| 3244/3298 [38:13<00:35,  1.54it/s]\u001b[A\n",
            " 98%|█████████▊| 3245/3298 [38:13<00:36,  1.45it/s]\u001b[A\n",
            " 98%|█████████▊| 3246/3298 [38:14<00:35,  1.48it/s]\u001b[A\n",
            " 98%|█████████▊| 3247/3298 [38:15<00:34,  1.49it/s]\u001b[A\n",
            " 98%|█████████▊| 3248/3298 [38:15<00:33,  1.50it/s]\u001b[A\n",
            " 99%|█████████▊| 3249/3298 [38:16<00:30,  1.60it/s]\u001b[A\n",
            " 99%|█████████▊| 3250/3298 [38:16<00:28,  1.69it/s]\u001b[A\n",
            " 99%|█████████▊| 3251/3298 [38:17<00:26,  1.76it/s]\u001b[A\n",
            " 99%|█████████▊| 3252/3298 [38:18<00:29,  1.57it/s]\u001b[A\n",
            " 99%|█████████▊| 3253/3298 [38:18<00:28,  1.55it/s]\u001b[A\n",
            " 99%|█████████▊| 3254/3298 [38:19<00:26,  1.66it/s]\u001b[A\n",
            " 99%|█████████▊| 3255/3298 [38:19<00:24,  1.73it/s]\u001b[A\n",
            " 99%|█████████▊| 3256/3298 [38:20<00:25,  1.68it/s]\u001b[A\n",
            " 99%|█████████▉| 3257/3298 [38:21<00:25,  1.63it/s]\u001b[A\n",
            " 99%|█████████▉| 3258/3298 [38:21<00:24,  1.61it/s]\u001b[A\n",
            " 99%|█████████▉| 3259/3298 [38:22<00:26,  1.50it/s]\u001b[A\n",
            " 99%|█████████▉| 3260/3298 [38:23<00:26,  1.44it/s]\u001b[A\n",
            " 99%|█████████▉| 3261/3298 [38:24<00:25,  1.47it/s]\u001b[A\n",
            " 99%|█████████▉| 3262/3298 [38:24<00:24,  1.49it/s]\u001b[A\n",
            " 99%|█████████▉| 3263/3298 [38:25<00:24,  1.43it/s]\u001b[A\n",
            " 99%|█████████▉| 3264/3298 [38:26<00:24,  1.38it/s]\u001b[A\n",
            " 99%|█████████▉| 3265/3298 [38:26<00:23,  1.43it/s]\u001b[A\n",
            " 99%|█████████▉| 3266/3298 [38:27<00:21,  1.46it/s]\u001b[A\n",
            " 99%|█████████▉| 3267/3298 [38:28<00:20,  1.48it/s]\u001b[A\n",
            " 99%|█████████▉| 3268/3298 [38:28<00:20,  1.49it/s]\u001b[A\n",
            " 99%|█████████▉| 3269/3298 [38:29<00:20,  1.43it/s]\u001b[A\n",
            " 99%|█████████▉| 3270/3298 [38:30<00:19,  1.47it/s]\u001b[A\n",
            " 99%|█████████▉| 3271/3298 [38:30<00:17,  1.58it/s]\u001b[A\n",
            " 99%|█████████▉| 3272/3298 [38:31<00:15,  1.67it/s]\u001b[A\n",
            " 99%|█████████▉| 3273/3298 [38:31<00:14,  1.75it/s]\u001b[A\n",
            " 99%|█████████▉| 3274/3298 [38:32<00:15,  1.58it/s]\u001b[A\n",
            " 99%|█████████▉| 3275/3298 [38:33<00:15,  1.48it/s]\u001b[A\n",
            " 99%|█████████▉| 3276/3298 [38:34<00:15,  1.40it/s]\u001b[A\n",
            " 99%|█████████▉| 3277/3298 [38:34<00:14,  1.45it/s]\u001b[A\n",
            " 99%|█████████▉| 3278/3298 [38:35<00:14,  1.39it/s]\u001b[A\n",
            " 99%|█████████▉| 3279/3298 [38:36<00:13,  1.44it/s]\u001b[A\n",
            " 99%|█████████▉| 3280/3298 [38:36<00:12,  1.47it/s]\u001b[A\n",
            " 99%|█████████▉| 3281/3298 [38:37<00:11,  1.50it/s]\u001b[A\n",
            "100%|█████████▉| 3282/3298 [38:38<00:10,  1.52it/s]\u001b[A\n",
            "100%|█████████▉| 3283/3298 [38:38<00:09,  1.53it/s]\u001b[A\n",
            "100%|█████████▉| 3284/3298 [38:39<00:09,  1.45it/s]\u001b[A\n",
            "100%|█████████▉| 3285/3298 [38:40<00:09,  1.39it/s]\u001b[A\n",
            "100%|█████████▉| 3286/3298 [38:40<00:08,  1.43it/s]\u001b[A\n",
            "100%|█████████▉| 3287/3298 [38:41<00:07,  1.46it/s]\u001b[A\n",
            "100%|█████████▉| 3288/3298 [38:42<00:06,  1.58it/s]\u001b[A\n",
            "100%|█████████▉| 3289/3298 [38:42<00:05,  1.67it/s]\u001b[A\n",
            "100%|█████████▉| 3290/3298 [38:43<00:04,  1.75it/s]\u001b[A\n",
            "100%|█████████▉| 3291/3298 [38:43<00:04,  1.69it/s]\u001b[A\n",
            "100%|█████████▉| 3292/3298 [38:44<00:03,  1.66it/s]\u001b[A\n",
            "100%|█████████▉| 3293/3298 [38:45<00:03,  1.62it/s]\u001b[A\n",
            "100%|█████████▉| 3294/3298 [38:45<00:02,  1.70it/s]\u001b[A\n",
            "100%|█████████▉| 3295/3298 [38:46<00:01,  1.65it/s]\u001b[A\n",
            "100%|█████████▉| 3296/3298 [38:46<00:01,  1.60it/s]\u001b[A\n",
            "100%|█████████▉| 3297/3298 [38:47<00:00,  1.58it/s]\u001b[A\n",
            "100%|██████████| 3298/3298 [38:48<00:00,  1.47it/s]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "semantic_similarity1 function took 2328.5277 (s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMlPYHkDg2no",
        "colab_type": "code",
        "outputId": "217a8f66-69a0-42bf-c393-91c4df3f7cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "evaluation(root_path + 'reff.csv', root_path + 'avg_cosine_new_results.csv', 3298, 2737, pr=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Positive Rate: 0.00 %\n",
            "Precision: 0.79 %\n",
            "Recall: 0.48 %\n",
            "F1-Measure: 0.60 %\n",
            "Predicted Positive Condition Rate (PPCR): 0.01 %\n",
            "Balanced Accuracy: 50.24 %\n",
            "Matthews Correlation Coefficient (MCC): 61.47 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(721, 187, 9024924, 794, 1515, 9025111, 9026626)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TQg2bQSsKxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import auc\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "figsize(10, 8)\n",
        "\n",
        "results = pd.DataFrame({'threshold': [],\n",
        "                        'tp': [],\n",
        "                        'fp': [],\n",
        "                        'tn': []\n",
        "                       })\n",
        "roc = pd.DataFrame({'threshold': [],\n",
        "                        'tp': [],\n",
        "                        'fp': [],\n",
        "                        'tn': [],\n",
        "                        'fn': []\n",
        "                       })\n",
        "#sns.heatmap(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRpanTisLSrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results.at[0] = [0,2,965.48]+[777]\n",
        "results.at[1] = [0.1,2,5,4]\n",
        "results.at[2] = [0,7,5,4]\n",
        "results.at[3] = [0,6,8]+[777]\n",
        "results.at[4] = [0.1,3,5,4]\n",
        "results.at[5] = [0.2,2,5,4]\n",
        "results.at[6] = [0,2,958]+[777]\n",
        "results.at[7] = [0.1,2,5,4]\n",
        "results.at[8] = [0.2,2,5,4]\n",
        "print(results['fp'])\n",
        "# qq = pd.DataFrame({'tp': [], 'fp': []})\n",
        "\n",
        "# qq = qq.append({'tp': 23, 'fp': 29}, ignore_index=True)\n",
        "# #qq = qq.append({'fp': 29}, ignore_index=True)\n",
        "# for d,g in zip(results['tp'],results['fp']): \n",
        "#     qq = qq.append({'tp': d, 'fp': g}, ignore_index=True)\n",
        "# ss = results['tp']\n",
        "# qq = qq.append(ss, ignore_index=True)\n",
        "\n",
        "ss = results[(results['threshold']==min(results['threshold'])) & (results['fp'] < 10)]['tp']\n",
        "results['tp'] = [1,2,3,4,5,6,7,8,9]\n",
        "# ss.loc[ss.index.max()+1] = 14555\n",
        "# for a,x in enumerate(results.iterrows()):\n",
        "#     ss = x[1]\n",
        "#     roc.at[a] = ss + [89]\n",
        "print(results)\n",
        "# qq = qq.sort_values(by=['tp'])\n",
        "# print(qq)\n",
        "# roc.at[0] = [89] + ss\n",
        "# roc.at[1] = ss + [83434]\n",
        "# roc.at[2] = ss + [234]\n",
        "# print(roc)\n",
        "#thresholds = [(round(t,1)) for t in np.arange(0,1.1,0.1)]\n",
        "#thresholds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Jms_bo0Ove",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "d1 = {\n",
        "         'Code': [1, 2, 3],\n",
        "         'Name': ['Company1', 'Company2', 'Company3'],\n",
        "         #'Value': [200, 300, 400],\n",
        "\n",
        "    }\n",
        "df1 = pd.DataFrame(d1, columns= ['Code','Name','Value'])\n",
        "\n",
        "d2 = {\n",
        "         'Code': [2],\n",
        "         'Name': ['Company2'],\n",
        "         #'Value': [1000],\n",
        "    }\n",
        "\n",
        "df2 = pd.DataFrame(d2, columns= ['Code','Name','Value'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY2WerS90RbP",
        "colab_type": "code",
        "outputId": "32a4ce96-297a-4b4e-dbd4-45530301c955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(pd.concat([df1,df2]).drop_duplicates(['Code','Name'],keep='last', inplace=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Code      Name  Value\n",
            "0     1  Company1    200\n",
            "2     3  Company3    400\n",
            "0     2  Company2   1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwEsz2e9KwQk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from shorttext.metrics.dynprog import damerau_levenshtein, longest_common_prefix, similarity, soft_jaccard_score\n",
        "#print(jaccardscore_sents('foot interosseous muscle', 'hand interosseous muscle',model0)) # not working\n",
        "#print(jaccardscore_sents('foot interosseous muscle', 'foot interosseus muscle',model0))\n",
        "# print(damerau_levenshtein('foot interosseous muscle', 'hand interosseous muscle'))\n",
        "# print(damerau_levenshtein('foot interosseous muscle', 'foot interosseus muscle'))\n",
        "# print(similarity('foot interosseous muscle', 'hand interosseous muscle'))\n",
        "# print(similarity('foot interosseous muscle', 'foot interosseus muscle'))\n",
        "# print(word_mover_distance(['foot', 'interosseous', 'muscle'],['hand', 'interosseous', 'muscle'],model0))\n",
        "# print(word_mover_distance(['foot', 'interosseous', 'muscle'],['foot', 'interosseus', 'muscle'],model0))\n",
        "# print(fuzz.token_sort_ratio('special sense organ system', 'sensory organ system'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIfZ1fXtVeTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "cm = np.array([[1,2],[3,4]])\n",
        "confusion_matrix(cm, ['Not-Aligned','Aligned'], '---')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nYIWhR9LZ_H",
        "colab_type": "code",
        "outputId": "b49bad3c-a2a3-4c83-b918-c22aac52aca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from gensim.corpora import Dictionary\n",
        "corpus = [[\"this\", \"is\",\"just\",\"lip\", \"sparta\"], [\"just\",\"sparta\" ,\"joking\"],[\"sparta\"]]\n",
        "dct = Dictionary(corpus)\n",
        "x = set(dct.values())\n",
        "print(x - set(['this']))\n",
        "for i in x:\n",
        "    if i=='lip':\n",
        "        print('True')\n",
        "        print(model0.wv['jo'])\n",
        "    else:\n",
        "        print('False')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'sparta', 'just', 'joking', 'is', 'lip'}\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "[ 1.75446063e-01  6.62247911e-02  2.42915619e-02  2.93574072e-02\n",
            " -5.13777658e-02 -2.86883619e-02  9.51256976e-02  4.47030924e-02\n",
            "  9.30846334e-02 -2.81733777e-02 -2.86857206e-02 -3.50415483e-02\n",
            "  9.08759087e-02  1.75501760e-02  5.24480455e-02 -7.24539347e-03\n",
            " -4.12286036e-02 -7.29398355e-02 -8.63622129e-02  4.17500362e-02\n",
            "  4.44314145e-02  1.09633878e-02  1.21694371e-01 -7.42075145e-02\n",
            "  3.49087864e-02 -9.12066922e-02 -1.97975084e-01  7.36859962e-02\n",
            " -3.98806818e-02  1.70220677e-02  3.20045352e-02  4.27902341e-02\n",
            " -3.46376337e-02  4.15540747e-02 -1.33130267e-01  4.79753762e-02\n",
            " -2.78375167e-02  2.48992466e-03 -1.26105160e-01  1.20157741e-01\n",
            "  8.70807618e-02  4.35581245e-02 -4.73390073e-02  4.99032140e-02\n",
            " -4.80468906e-02  6.29712194e-02 -8.04155618e-02 -9.42437053e-02\n",
            "  1.16951421e-01  7.90290236e-02  1.14991693e-02  1.48564884e-02\n",
            "  1.31280767e-02  4.27609012e-02  2.64171176e-02  4.55343118e-03\n",
            " -4.51924950e-02 -8.81277211e-03 -8.98446143e-03  3.55168171e-02\n",
            "  6.65187687e-02 -1.33267674e-03  1.42664174e-02 -4.75725014e-04\n",
            " -7.52808452e-02 -8.59350786e-02  2.49932967e-02 -1.66871339e-01\n",
            "  3.12723778e-02  7.07085710e-03  6.69191480e-02  5.44266216e-02\n",
            "  6.83009252e-02 -5.13153411e-02  3.53364609e-02  3.99143212e-02\n",
            " -1.07199989e-01 -1.06775789e-02  3.46955322e-02  4.39690165e-02\n",
            "  1.84835009e-02 -1.99444830e-01  9.37216356e-03 -3.51973549e-02\n",
            " -2.10367236e-02 -1.01906769e-01 -1.20083215e-02 -2.83319261e-02\n",
            " -1.37460399e-02  3.74533981e-02  1.22244656e-02  1.69051380e-03\n",
            "  5.48727103e-02  7.96742830e-03  3.96118052e-02  6.25912920e-02\n",
            " -9.48699638e-02 -1.61165395e-03 -3.18916887e-02  4.11703363e-02\n",
            "  9.13929269e-02  6.96509406e-02  7.72970319e-02 -8.81878287e-02\n",
            " -4.81703952e-02 -1.10894367e-01  8.44744891e-02  3.28876525e-02\n",
            "  1.01291994e-03 -1.07445158e-01 -1.09072499e-01  4.09977175e-02\n",
            "  6.66515827e-02  6.98163435e-02 -2.60649640e-02 -7.30433986e-02\n",
            " -2.54466515e-02 -5.05027883e-02 -5.46559319e-02 -1.18971258e-01\n",
            "  4.28383015e-02  2.16528289e-02  3.82808819e-02 -1.68806940e-01\n",
            " -2.24791802e-02  7.98404869e-03 -3.77300195e-02  5.41223325e-02\n",
            " -5.03075868e-02  8.39486122e-02  3.51409502e-02 -1.09729804e-01\n",
            "  5.49825802e-02  4.04865146e-02 -7.31720701e-02 -5.23618236e-02\n",
            " -1.28896385e-02 -4.13484983e-02 -7.60113746e-02 -2.83165067e-03\n",
            "  1.24403238e-01 -2.96231396e-02  1.37303531e-01  5.99940680e-02\n",
            "  1.32496573e-03  8.26257019e-05  7.96353370e-02  1.22847915e-01\n",
            " -1.10969674e-02  2.30379198e-02  2.18950994e-02  1.60957798e-02\n",
            " -5.77043891e-02  1.76825240e-01 -7.13998824e-02  8.98574293e-02\n",
            " -1.03415102e-01 -3.06114350e-02 -1.29615664e-02  2.96290964e-02\n",
            "  2.20764894e-02  9.47302021e-03 -2.85334755e-02  1.44052356e-01\n",
            "  3.31366919e-02  8.55817050e-02  2.21994109e-02 -4.92119044e-02\n",
            " -4.34152223e-02 -9.17431712e-02 -1.18080024e-02  2.80558206e-02\n",
            " -6.53943866e-02  3.47560272e-02 -4.83288206e-02 -4.81641069e-02\n",
            "  4.35038581e-02  1.08071014e-01  6.49877340e-02  1.25978902e-01\n",
            " -4.16001640e-02  2.06598341e-02 -6.22271560e-02  4.83222976e-02\n",
            "  1.66701704e-01  4.41910326e-02 -5.10041565e-02 -3.88893089e-03\n",
            " -1.18921036e-02  4.07677032e-02  1.34271741e-01 -3.90048027e-02\n",
            " -1.19811639e-01  9.36050788e-02 -1.08485660e-02  1.73829183e-01\n",
            " -8.60728398e-02 -8.18123221e-02 -1.56109139e-01  4.13938724e-02]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHffHgD6CFU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import wmd\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.add_pipe(wmd.WMD.SpacySimilarityHook(nlp), last=True)\n",
        "doc1 = nlp(\"Politician speaks to the media in Illinois.\")\n",
        "doc2 = nlp(\"The president greets the press in Chicago.\")\n",
        "print(doc1.similarity(doc2))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}